======= BOOTSTRAP DOCKERFILE =======>
#
# Copyright (c) 2018-2023 Red Hat, Inc.
# This program and the accompanying materials are made
# available under the terms of the Eclipse Public License 2.0
# which is available at https://www.eclipse.org/legal/epl-2.0/
#
# SPDX-License-Identifier: EPL-2.0
#
# Contributors:
#   Red Hat, Inc. - initial API and implementation
#   IBM Corporation - implementation
#

# Builder: check meta.yamls and create index.json
# https://registry.access.redhat.com/ubi8/python-38
FROM registry.access.redhat.com/ubi8/python-38:1-131 as builder
#FROM registry-proxy.engineering.redhat.com/ubi8/python-38:1 as builder
USER 0

ARG BOOTSTRAP=true
ENV BOOTSTRAP=${BOOTSTRAP}
# if not defined or string is null, allow all registries/tags in list_referenced_images
# otherwise restrict to only those space-separated registries/tags; if others found, build will fail
# useful for failing build if quay images in an RC, or wrong devspaces image tag (3.2 in 3.1 build)
ARG ALLOWED_REGISTRIES=""
ENV ALLOWED_REGISTRIES=${ALLOWED_REGISTRIES}
ARG ALLOWED_TAGS=""
ENV ALLOWED_TAGS=${ALLOWED_TAGS}

COPY ./build/dockerfiles/content_sets_rhel8.repo /etc/yum.repos.d/
COPY ./build/dockerfiles/rhel.install.sh /tmp
RUN /tmp/rhel.install.sh && rm -f /tmp/rhel.install.sh

COPY ./build/scripts ./versions.json /build/
COPY ./build/scripts/clone_and_zip.sh /build/build/scripts/
COPY ./VERSION /
COPY ./devfiles /build/devfiles
WORKDIR /build/

RUN ./generate_devworkspace_templates.sh
RUN chmod -R g+rwX /build/resources

# validate devfile content
RUN ./check_referenced_images.sh devfiles --registries "${ALLOWED_REGISTRIES}" --tags "${ALLOWED_TAGS}"
RUN ./check_mandatory_fields.sh devfiles

# Cache projects in DS 
COPY ./build/dockerfiles/rhel.cache_projects.sh /tmp/ 
RUN /tmp/rhel.cache_projects.sh /build/ && rm -rf /tmp/rhel.cache_projects.sh /tmp/resources.tgz 

# don't do swaps, or we end up with missing content if built on s390x or ppc64le worker
# RUN ./swap_yamlfiles.sh devfiles
# RUN ./swap_images.sh devfiles
RUN ./index.sh > /build/devfiles/index.json && \
    ./list_referenced_images.sh devfiles > /build/devfiles/external_images.txt && \
    ./list_referenced_images_by_file.sh devfiles > /build/devfiles/external_images_by_devfile.txt && \
    chmod -R g+rwX /build/devfiles

<======= BOOTSTRAP DOCKERFILE =======
======= START BOOTSTRAP BUILD =======>
STEP 1/23: FROM registry.access.redhat.com/ubi8/python-38:1-131 AS builder
STEP 2/23: USER 0
--> 65dc24c7dc7e
STEP 3/23: ARG BOOTSTRAP=true
--> b72fb07a6de6
STEP 4/23: ENV BOOTSTRAP=${BOOTSTRAP}
--> 186690d62d6f
STEP 5/23: ARG ALLOWED_REGISTRIES=""
--> 6a61322aa5c0
STEP 6/23: ENV ALLOWED_REGISTRIES=${ALLOWED_REGISTRIES}
--> fef1d806d87d
STEP 7/23: ARG ALLOWED_TAGS=""
--> ea4a8fd527d6
STEP 8/23: ENV ALLOWED_TAGS=${ALLOWED_TAGS}
--> ac1fee2ca5b2
STEP 9/23: COPY ./build/dockerfiles/content_sets_rhel8.repo /etc/yum.repos.d/
--> 3a0dcad69873
STEP 10/23: COPY ./build/dockerfiles/rhel.install.sh /tmp
--> 7bf13d569824
STEP 11/23: RUN /tmp/rhel.install.sh && rm -f /tmp/rhel.install.sh

Upgraded:
  bash-4.4.20-5.el8.x86_64             chkconfig-1.19.2-1.el8.x86_64           
  dnf-4.7.0-20.el8.noarch              dnf-data-4.7.0-20.el8.noarch            
  findutils-1:4.6.0-22.el8.x86_64      git-2.43.5-1.el8_10.x86_64              
  git-core-2.43.5-1.el8_10.x86_64      git-core-doc-2.43.5-1.el8_10.noarch     
  perl-Git-2.43.5-1.el8_10.noarch      python3-dnf-4.7.0-20.el8.noarch         
  wget-1.19.5-12.el8_10.x86_64         yum-4.7.0-20.el8.noarch                 
Installed:
  containers-common-2:1-82.module+el8.10.0+22202+761b9a65.x86_64                
  criu-3.18-5.module+el8.10.0+22202+761b9a65.x86_64                             
  fuse-common-3.3.0-19.el8.x86_64                                               
  fuse-overlayfs-1.13-1.module+el8.10.0+22202+761b9a65.x86_64                   
  fuse3-3.3.0-19.el8.x86_64                                                     
  fuse3-libs-3.3.0-19.el8.x86_64                                                
  jq-1.6-9.el8_10.x86_64                                                        
  kmod-25-20.el8.x86_64                                                         
  libnet-1.1.6-15.el8.x86_64                                                    
  libslirp-4.4.0-2.module+el8.10.0+22202+761b9a65.x86_64                        
  mpdecimal-2.5.1-3.el8.x86_64                                                  
  oniguruma-6.8.2-3.el8.x86_64                                                  
  protobuf-c-1.3.0-8.el8.x86_64                                                 
  python3.11-3.11.9-2.el8_10.x86_64                                             
  python3.11-devel-3.11.9-2.el8_10.x86_64                                       
  python3.11-libs-3.11.9-2.el8_10.x86_64                                        
  python3.11-pip-22.3.1-5.el8.noarch                                            
  python3.11-pip-wheel-22.3.1-5.el8.noarch                                      
  python3.11-setuptools-65.5.1-2.el8.noarch                                     
  python3.11-setuptools-wheel-65.5.1-2.el8.noarch                               
  runc-1:1.1.12-4.module+el8.10.0+22202+761b9a65.x86_64                         
  skopeo-2:1.14.5-3.module+el8.10.0+22202+761b9a65.x86_64                       
  slirp4netns-1.2.3-1.module+el8.10.0+22202+761b9a65.x86_64                     

Collecting yq
  Downloading yq-3.4.3-py3-none-any.whl (18 kB)
Collecting argcomplete
  Downloading argcomplete-3.5.0-py3-none-any.whl (43 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.5/43.5 kB 6.0 MB/s eta 0:00:00
Requirement already satisfied: pip in /usr/lib/python3.11/site-packages (22.3.1)
Collecting pip
  Downloading pip-24.2-py3-none-any.whl (1.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 53.0 MB/s eta 0:00:00
Collecting PyYAML>=5.3.1
  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 763.0/763.0 kB 528.5 MB/s eta 0:00:00
Collecting xmltodict>=0.11.0
  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)
Collecting tomlkit>=0.11.6
  Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)
Installing collected packages: xmltodict, tomlkit, PyYAML, pip, argcomplete, yq
Successfully installed PyYAML-6.0.2 argcomplete-3.5.0 pip-24.2 tomlkit-0.13.2 xmltodict-0.13.0 yq-3.4.3
python: Python 3.8.16
yq: yq 3.4.3
jq: jq-1.6
--> 59ea1037657d
STEP 12/23: COPY ./build/scripts ./versions.json /build/
--> d8f1ae254a89
STEP 13/23: COPY ./build/scripts/clone_and_zip.sh /build/build/scripts/
--> ef121cee2468
STEP 14/23: COPY ./VERSION /
--> 9a21729481d5
STEP 15/23: COPY ./devfiles /build/devfiles
--> ecd2d964e15b
STEP 16/23: WORKDIR /build/
--> e7187d5334e6
STEP 17/23: RUN ./generate_devworkspace_templates.sh
+ @eclipse-che/che-devworkspace-generator@0.0.1-99986b8
added 31 packages from 83 contributors and audited 31 packages in 3.575s

1 package is looking for funding
  run `npm fund` for details

found 1 moderate severity vulnerability
  run `npm audit fix` to fix them, or `npm audit` for details
DevWorkspace che-code-ansible-demo was generated.
DevWorkspace che-idea-ansible-demo was generated.
DevWorkspace che-code-java-lombok was generated.
DevWorkspace che-idea-java-lombok was generated.
DevWorkspace che-code-quarkus-quickstart was generated.
DevWorkspace che-idea-quarkus-quickstart was generated.
DevWorkspace che-code-nodejs-mongodb was generated.
DevWorkspace che-idea-nodejs-mongodb was generated.
DevWorkspace che-code-nodejs-web-app was generated.
DevWorkspace che-idea-nodejs-web-app was generated.
DevWorkspace che-code-python-hello-world was generated.
DevWorkspace che-idea-python-hello-world was generated.
DevWorkspace che-code-cpp was generated.
DevWorkspace che-idea-cpp was generated.
DevWorkspace che-code-dotnet was generated.
DevWorkspace che-idea-dotnet was generated.
DevWorkspace che-code-golang was generated.
DevWorkspace che-idea-golang was generated.
DevWorkspace che-code-php-hello-world was generated.
DevWorkspace che-idea-php-hello-world was generated.
--> 95b03acf5966
STEP 18/23: RUN chmod -R g+rwX /build/resources
--> b72f3c617cf6
STEP 19/23: RUN ./check_referenced_images.sh devfiles --registries "${ALLOWED_REGISTRIES}" --tags "${ALLOWED_TAGS}"
 = ghcr.io/ansible/ansible-workspace-env-reference@sha256:03d7f0fe6caaae62ff2266906b63d67ebd9cf6e4a056c7c0a0c1320e6cfbebce PASS
 + registry.redhat.io/devspaces/code-rhel8:3.16 PASS - registry.redhat.io allowed
 + registry.redhat.io/devspaces/idea-rhel8:3.16 PASS - registry.redhat.io allowed
 + registry.redhat.io/devspaces/udi-rhel8:3.16 PASS - registry.redhat.io allowed
 + registry.redhat.io/rhscl/mongodb-36-rhel7:1-50 PASS - registry.redhat.io allowed
 = ghcr.io/ansible/ansible-workspace-env-reference@sha256:03d7f0fe6caaae62ff2266906b63d67ebd9cf6e4a056c7c0a0c1320e6cfbebce PASS
 + registry.redhat.io/devspaces/code-rhel8:3.16 PASS - 3.16 allowed
 + registry.redhat.io/devspaces/idea-rhel8:3.16 PASS - 3.16 allowed
 + registry.redhat.io/devspaces/udi-rhel8:3.16 PASS - 3.16 allowed
 = registry.redhat.io/rhscl/mongodb-36-rhel7:1-50 PASS
--> 920c879c5411
STEP 20/23: RUN ./check_mandatory_fields.sh devfiles
Checking devfile 'devfiles/TP__cpp__c-plus-plus/meta.yaml'
Checking devfile 'devfiles/TP__dotnet__dotnet-web-simple/meta.yaml'
Checking devfile 'devfiles/TP__go__golang-health-check/meta.yaml'
Checking devfile 'devfiles/TP__php__php-hello-world/meta.yaml'
Checking devfile 'devfiles/ansible__ansible-demo/meta.yaml'
Checking devfile 'devfiles/java-maven-lombok__lombok-project-sample/meta.yaml'
Checking devfile 'devfiles/java-maven-quarkus__quarkus-quickstarts/meta.yaml'
Checking devfile 'devfiles/nodejs__nodejs-mongodb-sample/meta.yaml'
Checking devfile 'devfiles/nodejs__web-nodejs-sample/meta.yaml'
Checking devfile 'devfiles/python__python-hello-world/meta.yaml'
--> afa6fed70da6
STEP 21/23: COPY ./build/dockerfiles/rhel.cache_projects.sh /tmp/ 
--> 91554abefdb1
STEP 22/23: RUN /tmp/rhel.cache_projects.sh /build/ && rm -rf /tmp/rhel.cache_projects.sh /tmp/resources.tgz 
--> 8416468124f3
STEP 23/23: RUN ./index.sh > /build/devfiles/index.json &&     ./list_referenced_images.sh devfiles > /build/devfiles/external_images.txt &&     ./list_referenced_images_by_file.sh devfiles > /build/devfiles/external_images_by_devfile.txt &&     chmod -R g+rwX /build/devfiles
COMMIT devfileregistry:tmp
--> 5b78eabb2c11
Successfully tagged localhost/devfileregistry:tmp
5b78eabb2c11a83f300202235497515cceb40000f675e7ee5aadbc7ef2c93fcb
<======= END BOOTSTRAP BUILD =======
Downloading root-local.tgz from https://pkgs.devel.redhat.com/repo/
Downloading resources.tgz from https://pkgs.devel.redhat.com/repo/
DIFF START *****
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/bin/activate-global-python-argcomplete /tmp/tmp.vSyF58mbqy/bin/activate-global-python-argcomplete
--- /tmp/tmp.PTAN8QOIRy/bin/activate-global-python-argcomplete	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/bin/activate-global-python-argcomplete	2024-08-15 06:46:07.158821873 -0400
@@ -1,154 +1,8 @@
 #!/usr/bin/python3.11
-# PYTHON_ARGCOMPLETE_OK
-
-# Copyright 2012-2023, Andrey Kislyuk and argcomplete contributors.
-# Licensed under the Apache License. See https://github.com/kislyuk/argcomplete for more info.
-
-"""
-Activate the generic bash-completion script or zsh completion autoload function for the argcomplete module.
-"""
-
-import argparse
-import os
-import shutil
-import site
-import subprocess
+# -*- coding: utf-8 -*-
+import re
 import sys
-
-import argcomplete
-
-zsh_shellcode = """
-# Begin added by argcomplete
-fpath=( {zsh_fpath} "${{fpath[@]}}" )
-# End added by argcomplete
-"""
-
-bash_shellcode = """
-# Begin added by argcomplete
-source "{activator}"
-# End added by argcomplete
-"""
-
-
-def get_local_dir():
-    try:
-        return subprocess.check_output(["brew", "--prefix"]).decode().strip()
-    except (FileNotFoundError, subprocess.CalledProcessError):
-        return "/usr/local"
-
-
-def get_zsh_system_dir():
-    return f"{get_local_dir()}/share/zsh/site-functions"
-
-
-def get_bash_system_dir():
-    if "BASH_COMPLETION_COMPAT_DIR" in os.environ:
-        return os.environ["BASH_COMPLETION_COMPAT_DIR"]
-    elif sys.platform == "darwin":
-        return f"{get_local_dir()}/etc/bash_completion.d"  # created by homebrew
-    else:
-        return "/etc/bash_completion.d"  # created by bash-completion
-
-
-def get_activator_dir():
-    return os.path.join(os.path.abspath(os.path.dirname(argcomplete.__file__)), "bash_completion.d")
-
-
-def get_activator_path():
-    return os.path.join(get_activator_dir(), "_python-argcomplete")
-
-
-def install_to_destination(dest):
-    activator = get_activator_path()
-    if dest == "-":
-        with open(activator) as fh:
-            sys.stdout.write(fh.read())
-        return
-    destdir = os.path.dirname(dest)
-    if not os.path.exists(destdir):
-        try:
-            os.makedirs(destdir, exist_ok=True)
-        except Exception as e:
-            parser.error(f"path {destdir} does not exist and could not be created: {e}")
-    try:
-        print(f"Installing {activator} to {dest}...", file=sys.stderr)
-        shutil.copy(activator, dest)
-        print("Installed.", file=sys.stderr)
-    except Exception as e:
-        parser.error(
-            f"while installing to {dest}: {e}. Please run this command using sudo, or see --help for more options."
-        )
-
-
-def get_consent():
-    if args.yes is True:
-        return True
-    while True:
-        res = input("OK to proceed? [y/n] ")
-        if res.lower() not in {"y", "n", "yes", "no"}:
-            print('Please answer "yes" or "no".', file=sys.stderr)
-        elif res.lower() in {"y", "yes"}:
-            return True
-        else:
-            return False
-
-
-def append_to_config_file(path, shellcode):
-    if os.path.exists(path):
-        with open(path, 'r') as fh:
-            if shellcode in fh.read():
-                print(f"The code already exists in the file {path}.", file=sys.stderr)
-                return
-        print(f"argcomplete needs to append to the file {path}. The following code will be appended:", file=sys.stderr)
-        for line in shellcode.splitlines():
-            print(">", line, file=sys.stderr)
-        if not get_consent():
-            print("Not added.", file=sys.stderr)
-            return
-    print(f"Adding shellcode to {path}...", file=sys.stderr)
-    with open(path, "a") as fh:
-        fh.write(shellcode)
-    print("Added.", file=sys.stderr)
-
-
-def link_user_rcfiles():
-    # TODO: warn if running as superuser
-    zsh_rcfile = os.path.join(os.path.expanduser(os.environ.get("ZDOTDIR", "~")), ".zshenv")
-    append_to_config_file(zsh_rcfile, zsh_shellcode.format(zsh_fpath=get_activator_dir()))
-
-    bash_completion_user_file = os.path.expanduser("~/.bash_completion")
-    append_to_config_file(bash_completion_user_file, bash_shellcode.format(activator=get_activator_path()))
-
-
-parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)
-parser.add_argument("-y", "--yes", help="automatically answer yes for all questions", action="store_true")
-parser.add_argument("--dest", help='Specify the shell completion modules directory to install into, or "-" for stdout')
-parser.add_argument("--user", help="Install into user directory", action="store_true")
-argcomplete.autocomplete(parser)
-args = parser.parse_args()
-destinations = []
-
-if args.dest:
-    if args.dest != "-" and not os.path.exists(args.dest):
-        parser.error(f"directory {args.dest} was specified via --dest, but it does not exist")
-    destinations.append(args.dest)
-elif site.ENABLE_USER_SITE and site.USER_SITE in argcomplete.__file__:
-    print(
-        "Argcomplete was installed in the user site local directory. Defaulting to user installation.", file=sys.stderr
-    )
-    link_user_rcfiles()
-elif sys.prefix != sys.base_prefix:
-    print("Argcomplete was installed in a virtual environment. Defaulting to user installation.", file=sys.stderr)
-    link_user_rcfiles()
-elif args.user:
-    link_user_rcfiles()
-else:
-    print("Defaulting to system-wide installation.", file=sys.stderr)
-    destinations.append(f"{get_zsh_system_dir()}/_python-argcomplete")
-    destinations.append(f"{get_bash_system_dir()}/python-argcomplete")
-
-for destination in destinations:
-    install_to_destination(destination)
-
-if args.dest is None:
-    print("Please restart your shell or source the installed file to activate it.", file=sys.stderr)
+from argcomplete.scripts.activate_global_python_argcomplete import main
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/bin/python-argcomplete-check-easy-install-script /tmp/tmp.vSyF58mbqy/bin/python-argcomplete-check-easy-install-script
--- /tmp/tmp.PTAN8QOIRy/bin/python-argcomplete-check-easy-install-script	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/bin/python-argcomplete-check-easy-install-script	2024-08-15 06:46:07.159821873 -0400
@@ -1,63 +1,8 @@
 #!/usr/bin/python3.11
-
-# Copyright 2012-2023, Andrey Kislyuk and argcomplete contributors.
-# Licensed under the Apache License. See https://github.com/kislyuk/argcomplete for more info.
-
-"""
-This script is part of the Python argcomplete package (https://github.com/kislyuk/argcomplete).
-It is used to check if an EASY-INSTALL-SCRIPT wrapper redirects to a script that contains the string
-"PYTHON_ARGCOMPLETE_OK". If you have enabled global completion in argcomplete, the completion hook will run it every
-time you press <TAB> in your shell.
-
-Usage:
-    python-argcomplete-check-easy-install-script <input executable file>
-"""
-
+# -*- coding: utf-8 -*-
+import re
 import sys
-
-if len(sys.argv) != 2:
-    sys.exit(__doc__)
-
-sys.tracebacklimit = 0
-
-with open(sys.argv[1]) as fh:
-    line1, head = fh.read(1024).split("\n", 1)[:2]
-    if line1.startswith("#") and ("py" in line1 or "Py" in line1):
-        import re
-
-        lines = head.split("\n", 12)
-        for line in lines:
-            if line.startswith("# EASY-INSTALL-SCRIPT"):
-                import pkg_resources
-
-                dist, script = re.match("# EASY-INSTALL-SCRIPT: '(.+)','(.+)'", line).groups()
-                if "PYTHON_ARGCOMPLETE_OK" in pkg_resources.get_distribution(dist).get_metadata("scripts/" + script):
-                    exit(0)
-            elif line.startswith("# EASY-INSTALL-ENTRY-SCRIPT"):
-                dist, group, name = re.match("# EASY-INSTALL-ENTRY-SCRIPT: '(.+)','(.+)','(.+)'", line).groups()
-                import pkgutil
-
-                import pkg_resources
-
-                module_name = pkg_resources.get_distribution(dist).get_entry_info(group, name).module_name
-                with open(pkgutil.get_loader(module_name).get_filename()) as mod_fh:
-                    if "PYTHON_ARGCOMPLETE_OK" in mod_fh.read(1024):
-                        exit(0)
-            elif line.startswith("# EASY-INSTALL-DEV-SCRIPT"):
-                for line2 in lines:
-                    if line2.startswith("__file__"):
-                        filename = re.match("__file__ = '(.+)'", line2).group(1)
-                        with open(filename) as mod_fh:
-                            if "PYTHON_ARGCOMPLETE_OK" in mod_fh.read(1024):
-                                exit(0)
-            elif line.startswith("# PBR Generated"):
-                module = re.search("from (.*) import", head).groups()[0]
-                import pkgutil
-
-                import pkg_resources
-
-                with open(pkgutil.get_loader(module).get_filename()) as mod_fh:
-                    if "PYTHON_ARGCOMPLETE_OK" in mod_fh.read(1024):
-                        exit(0)
-
-exit(1)
+from argcomplete.scripts.python_argcomplete_check_easy_install_script import main
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/bin/register-python-argcomplete /tmp/tmp.vSyF58mbqy/bin/register-python-argcomplete
--- /tmp/tmp.PTAN8QOIRy/bin/register-python-argcomplete	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/bin/register-python-argcomplete	2024-08-15 06:46:07.159821873 -0400
@@ -1,71 +1,8 @@
 #!/usr/bin/python3.11
-# PYTHON_ARGCOMPLETE_OK
-
-# Copyright 2012-2023, Andrey Kislyuk and argcomplete contributors.
-# Licensed under the Apache License. See https://github.com/kislyuk/argcomplete for more info.
-
-"""
-Register a Python executable for use with the argcomplete module.
-
-To perform the registration, source the output of this script in your bash shell
-(quote the output to avoid interpolation).
-
-Example:
-
-    $ eval "$(register-python-argcomplete my-favorite-script.py)"
-
-For Tcsh
-
-    $ eval `register-python-argcomplete --shell tcsh my-favorite-script.py`
-
-For Fish
-
-    $ register-python-argcomplete --shell fish my-favourite-script.py > ~/.config/fish/my-favourite-script.py.fish
-"""
-
-import argparse
+# -*- coding: utf-8 -*-
+import re
 import sys
-
-import argcomplete
-
-parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)
-
-parser.add_argument(
-    "--no-defaults",
-    dest="use_defaults",
-    action="store_false",
-    default=True,
-    help="when no matches are generated, do not fallback to readline's default completion (affects bash only)",
-)
-parser.add_argument(
-    "--complete-arguments",
-    nargs=argparse.REMAINDER,
-    help="arguments to call complete with; use of this option discards default options (affects bash only)",
-)
-parser.add_argument(
-    "-s",
-    "--shell",
-    choices=("bash", "zsh", "tcsh", "fish", "powershell"),
-    default="bash",
-    help="output code for the specified shell",
-)
-parser.add_argument(
-    "-e", "--external-argcomplete-script", help="external argcomplete script for auto completion of the executable"
-)
-
-parser.add_argument("executable", nargs="+", help="executable to completed (when invoked by exactly this name)")
-
-argcomplete.autocomplete(parser)
-
-if len(sys.argv) == 1:
-    parser.print_help()
-    sys.exit(1)
-
-args = parser.parse_args()
-
-
-sys.stdout.write(
-    argcomplete.shellcode(
-        args.executable, args.use_defaults, args.shell, args.complete_arguments, args.external_argcomplete_script
-    )
-)
+from argcomplete.scripts.register_python_argcomplete import main
+if __name__ == '__main__':
+    sys.argv[0] = re.sub(r'(-script\.pyw|\.exe)?$', '', sys.argv[0])
+    sys.exit(main())
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/argcomplete/bash_completion.d/_python-argcomplete /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/argcomplete/bash_completion.d/_python-argcomplete
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/argcomplete/bash_completion.d/_python-argcomplete	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/argcomplete/bash_completion.d/_python-argcomplete	2024-08-15 06:46:07.163821873 -0400
@@ -1,5 +1,6 @@
 #compdef -default-
 
+# argcomplete global completion loader for zsh and bash
 # Copyright 2012-2023, Andrey Kislyuk and argcomplete contributors.
 # Licensed under the Apache License. See https://github.com/kislyuk/argcomplete for more info.
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/argcomplete/completers.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/argcomplete/completers.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/argcomplete/completers.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/argcomplete/completers.py	2024-08-15 06:46:07.162821873 -0400
@@ -22,7 +22,7 @@
 
     def __call__(
         self, *, prefix: str, action: argparse.Action, parser: argparse.ArgumentParser, parsed_args: argparse.Namespace
-    ):
+    ) -> None:
         raise NotImplementedError("This method should be implemented by a subclass.")
 
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/argcomplete/finders.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/argcomplete/finders.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/argcomplete/finders.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/argcomplete/finders.py	2024-08-15 06:46:07.162821873 -0400
@@ -7,10 +7,10 @@
 import os
 import sys
 from collections.abc import Mapping
-from typing import Callable, Dict, List, Optional, Sequence, Union
+from typing import Callable, Dict, List, Optional, Sequence, TextIO, Union
 
 from . import io as _io
-from .completers import ChoicesCompleter, FilesCompleter, SuppressCompleter
+from .completers import BaseCompleter, ChoicesCompleter, FilesCompleter, SuppressCompleter
 from .io import debug, mute_stderr
 from .lexers import split_line
 from .packages._argparse import IntrospectiveArgumentParser, action_is_greedy, action_is_open, action_is_satisfied
@@ -66,13 +66,13 @@
         argument_parser: argparse.ArgumentParser,
         always_complete_options: Union[bool, str] = True,
         exit_method: Callable = os._exit,
-        output_stream=None,
+        output_stream: Optional[TextIO] = None,
         exclude: Optional[Sequence[str]] = None,
         validator: Optional[Callable] = None,
         print_suppressed: bool = False,
         append_space: Optional[bool] = None,
-        default_completer=FilesCompleter(),
-    ):
+        default_completer: BaseCompleter = FilesCompleter(),
+    ) -> None:
         """
         :param argument_parser: The argument parser to autocomplete on
         :param always_complete_options:
@@ -132,6 +132,8 @@
                 debug("Unable to open fd 8 for writing, quitting")
                 exit_method(1)
 
+        assert output_stream is not None
+
         ifs = os.environ.get("_ARGCOMPLETE_IFS", "\013")
         if len(ifs) != 1:
             debug("Invalid value for IFS, quitting [{v}]".format(v=ifs))
Only in /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/argcomplete: scripts
Only in /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages: argcomplete-3.4.0.dist-info
Only in /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages: argcomplete-3.5.0.dist-info
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/__init__.py	2024-08-15 06:46:07.183821873 -0400
@@ -1,6 +1,6 @@
 from typing import List, Optional
 
-__version__ = "24.1.2"
+__version__ = "24.2"
 
 
 def main(args: Optional[List[str]] = None) -> int:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/build_env.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/build_env.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/build_env.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/build_env.py	2024-08-15 06:46:07.190821873 -0400
@@ -12,7 +12,6 @@
 from typing import TYPE_CHECKING, Iterable, List, Optional, Set, Tuple, Type, Union
 
 from pip._vendor.certifi import where
-from pip._vendor.packaging.requirements import Requirement
 from pip._vendor.packaging.version import Version
 
 from pip import __file__ as pip_location
@@ -20,6 +19,7 @@
 from pip._internal.locations import get_platlib, get_purelib, get_scheme
 from pip._internal.metadata import get_default_environment, get_environment
 from pip._internal.utils.logging import VERBOSE
+from pip._internal.utils.packaging import get_requirement
 from pip._internal.utils.subprocess import call_subprocess
 from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
 
@@ -184,7 +184,7 @@
                 else get_default_environment()
             )
             for req_str in reqs:
-                req = Requirement(req_str)
+                req = get_requirement(req_str)
                 # We're explicitly evaluating with an empty extra value, since build
                 # environments are not provided any mechanism to select specific extras.
                 if req.marker is not None and not req.marker.evaluate({"extra": ""}):
@@ -241,6 +241,7 @@
             "--prefix",
             prefix.path,
             "--no-warn-script-location",
+            "--disable-pip-version-check",
         ]
         if logger.getEffectiveLevel() <= logging.DEBUG:
             args.append("-vv")
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/cli/base_command.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/cli/base_command.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/cli/base_command.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/cli/base_command.py	2024-08-15 06:46:07.184821873 -0400
@@ -1,6 +1,5 @@
 """Base Command class, and related routines"""
 
-import functools
 import logging
 import logging.config
 import optparse
@@ -8,8 +7,9 @@
 import sys
 import traceback
 from optparse import Values
-from typing import Any, Callable, List, Optional, Tuple
+from typing import List, Optional, Tuple
 
+from pip._vendor.rich import reconfigure
 from pip._vendor.rich import traceback as rich_traceback
 
 from pip._internal.cli import cmdoptions
@@ -90,6 +90,63 @@
     def run(self, options: Values, args: List[str]) -> int:
         raise NotImplementedError
 
+    def _run_wrapper(self, level_number: int, options: Values, args: List[str]) -> int:
+        def _inner_run() -> int:
+            try:
+                return self.run(options, args)
+            finally:
+                self.handle_pip_version_check(options)
+
+        if options.debug_mode:
+            rich_traceback.install(show_locals=True)
+            return _inner_run()
+
+        try:
+            status = _inner_run()
+            assert isinstance(status, int)
+            return status
+        except DiagnosticPipError as exc:
+            logger.error("%s", exc, extra={"rich": True})
+            logger.debug("Exception information:", exc_info=True)
+
+            return ERROR
+        except PreviousBuildDirError as exc:
+            logger.critical(str(exc))
+            logger.debug("Exception information:", exc_info=True)
+
+            return PREVIOUS_BUILD_DIR_ERROR
+        except (
+            InstallationError,
+            BadCommand,
+            NetworkConnectionError,
+        ) as exc:
+            logger.critical(str(exc))
+            logger.debug("Exception information:", exc_info=True)
+
+            return ERROR
+        except CommandError as exc:
+            logger.critical("%s", exc)
+            logger.debug("Exception information:", exc_info=True)
+
+            return ERROR
+        except BrokenStdoutLoggingError:
+            # Bypass our logger and write any remaining messages to
+            # stderr because stdout no longer works.
+            print("ERROR: Pipe to stdout was broken", file=sys.stderr)
+            if level_number <= logging.DEBUG:
+                traceback.print_exc(file=sys.stderr)
+
+            return ERROR
+        except KeyboardInterrupt:
+            logger.critical("Operation cancelled by user")
+            logger.debug("Exception information:", exc_info=True)
+
+            return ERROR
+        except BaseException:
+            logger.critical("Exception:", exc_info=True)
+
+            return UNKNOWN_ERROR
+
     def parse_args(self, args: List[str]) -> Tuple[Values, List[str]]:
         # factored out for testability
         return self.parser.parse_args(args)
@@ -115,6 +172,7 @@
         # Set verbosity so that it can be used elsewhere.
         self.verbosity = options.verbose - options.quiet
 
+        reconfigure(no_color=options.no_color)
         level_number = setup_logging(
             verbosity=self.verbosity,
             no_color=options.no_color,
@@ -170,65 +228,4 @@
                 )
                 options.cache_dir = None
 
-        def intercepts_unhandled_exc(
-            run_func: Callable[..., int]
-        ) -> Callable[..., int]:
-            @functools.wraps(run_func)
-            def exc_logging_wrapper(*args: Any) -> int:
-                try:
-                    status = run_func(*args)
-                    assert isinstance(status, int)
-                    return status
-                except DiagnosticPipError as exc:
-                    logger.error("%s", exc, extra={"rich": True})
-                    logger.debug("Exception information:", exc_info=True)
-
-                    return ERROR
-                except PreviousBuildDirError as exc:
-                    logger.critical(str(exc))
-                    logger.debug("Exception information:", exc_info=True)
-
-                    return PREVIOUS_BUILD_DIR_ERROR
-                except (
-                    InstallationError,
-                    BadCommand,
-                    NetworkConnectionError,
-                ) as exc:
-                    logger.critical(str(exc))
-                    logger.debug("Exception information:", exc_info=True)
-
-                    return ERROR
-                except CommandError as exc:
-                    logger.critical("%s", exc)
-                    logger.debug("Exception information:", exc_info=True)
-
-                    return ERROR
-                except BrokenStdoutLoggingError:
-                    # Bypass our logger and write any remaining messages to
-                    # stderr because stdout no longer works.
-                    print("ERROR: Pipe to stdout was broken", file=sys.stderr)
-                    if level_number <= logging.DEBUG:
-                        traceback.print_exc(file=sys.stderr)
-
-                    return ERROR
-                except KeyboardInterrupt:
-                    logger.critical("Operation cancelled by user")
-                    logger.debug("Exception information:", exc_info=True)
-
-                    return ERROR
-                except BaseException:
-                    logger.critical("Exception:", exc_info=True)
-
-                    return UNKNOWN_ERROR
-
-            return exc_logging_wrapper
-
-        try:
-            if not options.debug_mode:
-                run = intercepts_unhandled_exc(self.run)
-            else:
-                run = self.run
-                rich_traceback.install(show_locals=True)
-            return run(options, args)
-        finally:
-            self.handle_pip_version_check(options)
+        return self._run_wrapper(level_number, options, args)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/cli/cmdoptions.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/cli/cmdoptions.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/cli/cmdoptions.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/cli/cmdoptions.py	2024-08-15 06:46:07.184821873 -0400
@@ -996,6 +996,7 @@
 
 # Features that are now always on. A warning is printed if they are used.
 ALWAYS_ENABLED_FEATURES = [
+    "truststore",  # always on since 24.2
     "no-binary-enable-wheel-cache",  # always on since 23.1
 ]
 
@@ -1008,7 +1009,6 @@
     default=[],
     choices=[
         "fast-deps",
-        "truststore",
     ]
     + ALWAYS_ENABLED_FEATURES,
     help="Enable new functionality, that may be backward incompatible.",
@@ -1023,6 +1023,7 @@
     default=[],
     choices=[
         "legacy-resolver",
+        "legacy-certs",
     ],
     help=("Enable deprecated functionality, that will be removed in the future."),
 )
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/cli/index_command.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/cli/index_command.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/cli/index_command.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/cli/index_command.py	2024-08-15 06:46:07.184821873 -0400
@@ -12,9 +12,10 @@
 from optparse import Values
 from typing import TYPE_CHECKING, List, Optional
 
+from pip._vendor import certifi
+
 from pip._internal.cli.base_command import Command
 from pip._internal.cli.command_context import CommandContextMixIn
-from pip._internal.exceptions import CommandError
 
 if TYPE_CHECKING:
     from ssl import SSLContext
@@ -26,7 +27,8 @@
 
 def _create_truststore_ssl_context() -> Optional["SSLContext"]:
     if sys.version_info < (3, 10):
-        raise CommandError("The truststore feature is only available for Python 3.10+")
+        logger.debug("Disabling truststore because Python version isn't 3.10+")
+        return None
 
     try:
         import ssl
@@ -36,10 +38,13 @@
 
     try:
         from pip._vendor import truststore
-    except ImportError as e:
-        raise CommandError(f"The truststore feature is unavailable: {e}")
+    except ImportError:
+        logger.warning("Disabling truststore because platform isn't supported")
+        return None
 
-    return truststore.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
+    ctx = truststore.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
+    ctx.load_verify_locations(certifi.where())
+    return ctx
 
 
 class SessionCommandMixin(CommandContextMixIn):
@@ -80,20 +85,14 @@
         options: Values,
         retries: Optional[int] = None,
         timeout: Optional[int] = None,
-        fallback_to_certifi: bool = False,
     ) -> "PipSession":
         from pip._internal.network.session import PipSession
 
         cache_dir = options.cache_dir
         assert not cache_dir or os.path.isabs(cache_dir)
 
-        if "truststore" in options.features_enabled:
-            try:
-                ssl_context = _create_truststore_ssl_context()
-            except Exception:
-                if not fallback_to_certifi:
-                    raise
-                ssl_context = None
+        if "legacy-certs" not in options.deprecated_features_enabled:
+            ssl_context = _create_truststore_ssl_context()
         else:
             ssl_context = None
 
@@ -157,16 +156,15 @@
         if options.disable_pip_version_check or options.no_index:
             return
 
-        # Otherwise, check if we're using the latest version of pip available.
-        session = self._build_session(
-            options,
-            retries=0,
-            timeout=min(5, options.timeout),
-            # This is set to ensure the function does not fail when truststore is
-            # specified in use-feature but cannot be loaded. This usually raises a
-            # CommandError and shows a nice user-facing error, but this function is not
-            # called in that try-except block.
-            fallback_to_certifi=True,
-        )
-        with session:
-            _pip_self_version_check(session, options)
+        try:
+            # Otherwise, check if we're using the latest version of pip available.
+            session = self._build_session(
+                options,
+                retries=0,
+                timeout=min(5, options.timeout),
+            )
+            with session:
+                _pip_self_version_check(session, options)
+        except Exception:
+            logger.warning("There was an error checking the latest version of pip.")
+            logger.debug("See below for error", exc_info=True)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/cli/progress_bars.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/cli/progress_bars.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/cli/progress_bars.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/cli/progress_bars.py	2024-08-15 06:46:07.184821873 -0400
@@ -49,7 +49,7 @@
             TimeRemainingColumn(),
         )
 
-    progress = Progress(*columns, refresh_per_second=30)
+    progress = Progress(*columns, refresh_per_second=5)
     task_id = progress.add_task(" " * (get_indentation() + 2), total=total)
     with progress:
         for chunk in iterable:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/commands/check.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/commands/check.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/commands/check.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/commands/check.py	2024-08-15 06:46:07.186821873 -0400
@@ -4,10 +4,13 @@
 
 from pip._internal.cli.base_command import Command
 from pip._internal.cli.status_codes import ERROR, SUCCESS
+from pip._internal.metadata import get_default_environment
 from pip._internal.operations.check import (
     check_package_set,
+    check_unsupported,
     create_package_set_from_installed,
 )
+from pip._internal.utils.compatibility_tags import get_supported
 from pip._internal.utils.misc import write_output
 
 logger = logging.getLogger(__name__)
@@ -16,12 +19,19 @@
 class CheckCommand(Command):
     """Verify installed packages have compatible dependencies."""
 
+    ignore_require_venv = True
     usage = """
       %prog [options]"""
 
     def run(self, options: Values, args: List[str]) -> int:
         package_set, parsing_probs = create_package_set_from_installed()
         missing, conflicting = check_package_set(package_set)
+        unsupported = list(
+            check_unsupported(
+                get_default_environment().iter_installed_distributions(),
+                get_supported(),
+            )
+        )
 
         for project_name in missing:
             version = package_set[project_name].version
@@ -44,8 +54,13 @@
                     dep_name,
                     dep_version,
                 )
-
-        if missing or conflicting or parsing_probs:
+        for package in unsupported:
+            write_output(
+                "%s %s is not supported on this platform",
+                package.raw_name,
+                package.version,
+            )
+        if missing or conflicting or parsing_probs or unsupported:
             return ERROR
         else:
             write_output("No broken requirements found.")
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/commands/freeze.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/commands/freeze.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/commands/freeze.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/commands/freeze.py	2024-08-15 06:46:07.186821873 -0400
@@ -29,6 +29,7 @@
     packages are listed in a case-insensitive sorted order.
     """
 
+    ignore_require_venv = True
     usage = """
       %prog [options]"""
     log_streams = ("ext://sys.stderr", "ext://sys.stderr")
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/commands/install.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/commands/install.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/commands/install.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/commands/install.py	2024-08-15 06:46:07.186821873 -0400
@@ -7,6 +7,7 @@
 from optparse import SUPPRESS_HELP, Values
 from typing import List, Optional
 
+from pip._vendor.packaging.utils import canonicalize_name
 from pip._vendor.rich import print_json
 
 from pip._internal.cache import WheelCache
@@ -370,6 +371,7 @@
                 force_reinstall=options.force_reinstall,
                 upgrade_strategy=upgrade_strategy,
                 use_pep517=options.use_pep517,
+                py_version_info=options.python_version,
             )
 
             self.trace_basic_info(finder)
@@ -472,17 +474,21 @@
             )
             env = get_environment(lib_locations)
 
+            # Display a summary of installed packages, with extra care to
+            # display a package name as it was requested by the user.
             installed.sort(key=operator.attrgetter("name"))
-            items = []
-            for result in installed:
-                item = result.name
-                try:
-                    installed_dist = env.get_distribution(item)
-                    if installed_dist is not None:
-                        item = f"{item}-{installed_dist.version}"
-                except Exception:
-                    pass
-                items.append(item)
+            summary = []
+            installed_versions = {}
+            for distribution in env.iter_all_distributions():
+                installed_versions[distribution.canonical_name] = distribution.version
+            for package in installed:
+                display_name = package.name
+                version = installed_versions.get(canonicalize_name(display_name), None)
+                if version:
+                    text = f"{display_name}-{version}"
+                else:
+                    text = display_name
+                summary.append(text)
 
             if conflicts is not None:
                 self._warn_about_conflicts(
@@ -490,7 +496,7 @@
                     resolver_variant=self.determine_resolver_variant(options),
                 )
 
-            installed_desc = " ".join(items)
+            installed_desc = " ".join(summary)
             if installed_desc:
                 write_output(
                     "Successfully installed %s",
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/index/package_finder.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/index/package_finder.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/index/package_finder.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/index/package_finder.py	2024-08-15 06:46:07.187821873 -0400
@@ -452,24 +452,23 @@
         # Using None infers from the specifier instead.
         allow_prereleases = self._allow_all_prereleases or None
         specifier = self._specifier
-        versions = {
-            str(v)
-            for v in specifier.filter(
-                # We turn the version object into a str here because otherwise
-                # when we're debundled but setuptools isn't, Python will see
-                # packaging.version.Version and
-                # pkg_resources._vendor.packaging.version.Version as different
-                # types. This way we'll use a str as a common data interchange
-                # format. If we stop using the pkg_resources provided specifier
-                # and start using our own, we can drop the cast to str().
-                (str(c.version) for c in candidates),
+
+        # We turn the version object into a str here because otherwise
+        # when we're debundled but setuptools isn't, Python will see
+        # packaging.version.Version and
+        # pkg_resources._vendor.packaging.version.Version as different
+        # types. This way we'll use a str as a common data interchange
+        # format. If we stop using the pkg_resources provided specifier
+        # and start using our own, we can drop the cast to str().
+        candidates_and_versions = [(c, str(c.version)) for c in candidates]
+        versions = set(
+            specifier.filter(
+                (v for _, v in candidates_and_versions),
                 prereleases=allow_prereleases,
             )
-        }
-
-        # Again, converting version to str to deal with debundling.
-        applicable_candidates = [c for c in candidates if str(c.version) in versions]
+        )
 
+        applicable_candidates = [c for c, v in candidates_and_versions if v in versions]
         filtered_applicable_candidates = filter_unallowed_hashes(
             candidates=applicable_candidates,
             hashes=self._hashes,
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_compat.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_compat.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_compat.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_compat.py	2024-08-15 06:46:07.189821873 -0400
@@ -1,5 +1,8 @@
 import importlib.metadata
-from typing import Any, Optional, Protocol, cast
+import os
+from typing import Any, Optional, Protocol, Tuple, cast
+
+from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
 
 
 class BadMetadata(ValueError):
@@ -43,13 +46,40 @@
     return getattr(d, "_path", None)
 
 
-def get_dist_name(dist: importlib.metadata.Distribution) -> str:
-    """Get the distribution's project name.
+def parse_name_and_version_from_info_directory(
+    dist: importlib.metadata.Distribution,
+) -> Tuple[Optional[str], Optional[str]]:
+    """Get a name and version from the metadata directory name.
+
+    This is much faster than reading distribution metadata.
+    """
+    info_location = get_info_location(dist)
+    if info_location is None:
+        return None, None
+
+    stem, suffix = os.path.splitext(info_location.name)
+    if suffix == ".dist-info":
+        name, sep, version = stem.partition("-")
+        if sep:
+            return name, version
+
+    if suffix == ".egg-info":
+        name = stem.split("-", 1)[0]
+        return name, None
+
+    return None, None
+
+
+def get_dist_canonical_name(dist: importlib.metadata.Distribution) -> NormalizedName:
+    """Get the distribution's normalized name.
 
     The ``name`` attribute is only available in Python 3.10 or later. We are
     targeting exactly that, but Mypy does not know this.
     """
+    if name := parse_name_and_version_from_info_directory(dist)[0]:
+        return canonicalize_name(name)
+
     name = cast(Any, dist).name
     if not isinstance(name, str):
         raise BadMetadata(dist, reason="invalid metadata entry 'name'")
-    return name
+    return canonicalize_name(name)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_dists.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_dists.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_dists.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_dists.py	2024-08-15 06:46:07.189821873 -0400
@@ -1,6 +1,5 @@
 import email.message
 import importlib.metadata
-import os
 import pathlib
 import zipfile
 from typing import (
@@ -27,10 +26,15 @@
     Wheel,
 )
 from pip._internal.utils.misc import normalize_path
+from pip._internal.utils.packaging import get_requirement
 from pip._internal.utils.temp_dir import TempDirectory
 from pip._internal.utils.wheel import parse_wheel, read_wheel_metadata_file
 
-from ._compat import BasePath, get_dist_name
+from ._compat import (
+    BasePath,
+    get_dist_canonical_name,
+    parse_name_and_version_from_info_directory,
+)
 
 
 class WheelDistribution(importlib.metadata.Distribution):
@@ -153,25 +157,14 @@
             return None
         return normalize_path(str(self._installed_location))
 
-    def _get_dist_name_from_location(self) -> Optional[str]:
-        """Try to get the name from the metadata directory name.
-
-        This is much faster than reading metadata.
-        """
-        if self._info_location is None:
-            return None
-        stem, suffix = os.path.splitext(self._info_location.name)
-        if suffix not in (".dist-info", ".egg-info"):
-            return None
-        return stem.split("-", 1)[0]
-
     @property
     def canonical_name(self) -> NormalizedName:
-        name = self._get_dist_name_from_location() or get_dist_name(self._dist)
-        return canonicalize_name(name)
+        return get_dist_canonical_name(self._dist)
 
     @property
     def version(self) -> Version:
+        if version := parse_name_and_version_from_info_directory(self._dist)[1]:
+            return parse_version(version)
         return parse_version(self._dist.version)
 
     @property
@@ -219,7 +212,7 @@
         for req_string in self.metadata.get_all("Requires-Dist", []):
             # strip() because email.message.Message.get_all() may return a leading \n
             # in case a long header was wrapped.
-            req = Requirement(req_string.strip())
+            req = get_requirement(req_string.strip())
             if not req.marker:
                 yield req
             elif not extras and req.marker.evaluate({"extra": ""}):
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_envs.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_envs.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_envs.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/metadata/importlib/_envs.py	2024-08-15 06:46:07.189821873 -0400
@@ -15,7 +15,7 @@
 from pip._internal.utils.deprecation import deprecated
 from pip._internal.utils.filetypes import WHEEL_EXTENSION
 
-from ._compat import BadMetadata, BasePath, get_dist_name, get_info_location
+from ._compat import BadMetadata, BasePath, get_dist_canonical_name, get_info_location
 from ._dists import Distribution
 
 logger = logging.getLogger(__name__)
@@ -61,14 +61,13 @@
         for dist in importlib.metadata.distributions(path=[location]):
             info_location = get_info_location(dist)
             try:
-                raw_name = get_dist_name(dist)
+                name = get_dist_canonical_name(dist)
             except BadMetadata as e:
                 logger.warning("Skipping %s due to %s", info_location, e.reason)
                 continue
-            normalized_name = canonicalize_name(raw_name)
-            if normalized_name in self._found_names:
+            if name in self._found_names:
                 continue
-            self._found_names.add(normalized_name)
+            self._found_names.add(name)
             yield dist, info_location
 
     def find(self, location: str) -> Iterator[BaseDistribution]:
@@ -181,9 +180,10 @@
             yield from finder.find_linked(location)
 
     def get_distribution(self, name: str) -> Optional[BaseDistribution]:
+        canonical_name = canonicalize_name(name)
         matches = (
             distribution
             for distribution in self.iter_all_distributions()
-            if distribution.canonical_name == canonicalize_name(name)
+            if distribution.canonical_name == canonical_name
         )
         return next(matches, None)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/network/auth.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/network/auth.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/network/auth.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/network/auth.py	2024-08-15 06:46:07.184821873 -0400
@@ -271,6 +271,10 @@
         try:
             return self.keyring_provider.get_auth_info(url, username)
         except Exception as exc:
+            # Log the full exception (with stacktrace) at debug, so it'll only
+            # show up when running in verbose mode.
+            logger.debug("Keyring is skipped due to an exception", exc_info=True)
+            # Always log a shortened version of the exception.
             logger.warning(
                 "Keyring is skipped due to an exception: %s",
                 str(exc),
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/network/download.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/network/download.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/network/download.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/network/download.py	2024-08-15 06:46:07.185821873 -0400
@@ -7,7 +7,7 @@
 import os
 from typing import Iterable, Optional, Tuple
 
-from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response
+from pip._vendor.requests.models import Response
 
 from pip._internal.cli.progress_bars import get_download_progress_renderer
 from pip._internal.exceptions import NetworkConnectionError
@@ -56,12 +56,12 @@
         show_progress = False
     elif not total_length:
         show_progress = True
-    elif total_length > (40 * 1000):
+    elif total_length > (512 * 1024):
         show_progress = True
     else:
         show_progress = False
 
-    chunks = response_chunks(resp, CONTENT_CHUNK_SIZE)
+    chunks = response_chunks(resp)
 
     if not show_progress:
         return chunks
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/network/utils.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/network/utils.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/network/utils.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/network/utils.py	2024-08-15 06:46:07.185821873 -0400
@@ -1,6 +1,6 @@
 from typing import Dict, Generator
 
-from pip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response
+from pip._vendor.requests.models import Response
 
 from pip._internal.exceptions import NetworkConnectionError
 
@@ -25,6 +25,8 @@
 # possible to make this work.
 HEADERS: Dict[str, str] = {"Accept-Encoding": "identity"}
 
+DOWNLOAD_CHUNK_SIZE = 256 * 1024
+
 
 def raise_for_status(resp: Response) -> None:
     http_error_msg = ""
@@ -55,7 +57,7 @@
 
 
 def response_chunks(
-    response: Response, chunk_size: int = CONTENT_CHUNK_SIZE
+    response: Response, chunk_size: int = DOWNLOAD_CHUNK_SIZE
 ) -> Generator[bytes, None, None]:
     """Given a requests Response, provide the data chunks."""
     try:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/operations/check.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/operations/check.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/operations/check.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/operations/check.py	2024-08-15 06:46:07.185821873 -0400
@@ -2,14 +2,30 @@
 """
 
 import logging
-from typing import Callable, Dict, List, NamedTuple, Optional, Set, Tuple
+from contextlib import suppress
+from email.parser import Parser
+from functools import reduce
+from typing import (
+    Callable,
+    Dict,
+    FrozenSet,
+    Generator,
+    Iterable,
+    List,
+    NamedTuple,
+    Optional,
+    Set,
+    Tuple,
+)
 
 from pip._vendor.packaging.requirements import Requirement
+from pip._vendor.packaging.tags import Tag, parse_tag
 from pip._vendor.packaging.utils import NormalizedName, canonicalize_name
 from pip._vendor.packaging.version import Version
 
 from pip._internal.distributions import make_distribution_for_install_requirement
 from pip._internal.metadata import get_default_environment
+from pip._internal.metadata.base import BaseDistribution
 from pip._internal.req.req_install import InstallRequirement
 
 logger = logging.getLogger(__name__)
@@ -113,6 +129,22 @@
     )
 
 
+def check_unsupported(
+    packages: Iterable[BaseDistribution],
+    supported_tags: Iterable[Tag],
+) -> Generator[BaseDistribution, None, None]:
+    for p in packages:
+        with suppress(FileNotFoundError):
+            wheel_file = p.read_text("WHEEL")
+            wheel_tags: FrozenSet[Tag] = reduce(
+                frozenset.union,
+                map(parse_tag, Parser().parsestr(wheel_file).get_all("Tag", [])),
+                frozenset(),
+            )
+            if wheel_tags.isdisjoint(supported_tags):
+                yield p
+
+
 def _simulate_installation_of(
     to_install: List[InstallRequirement], package_set: PackageSet
 ) -> Set[NormalizedName]:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/operations/install/wheel.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/operations/install/wheel.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/operations/install/wheel.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/operations/install/wheel.py	2024-08-15 06:46:07.186821873 -0400
@@ -358,12 +358,6 @@
         return self._zip_file.getinfo(self.src_record_path)
 
     def save(self) -> None:
-        # directory creation is lazy and after file filtering
-        # to ensure we don't install empty dirs; empty dirs can't be
-        # uninstalled.
-        parent_dir = os.path.dirname(self.dest_path)
-        ensure_dir(parent_dir)
-
         # When we open the output file below, any existing file is truncated
         # before we start writing the new contents. This is fine in most
         # cases, but can cause a segfault if pip has loaded a shared
@@ -377,9 +371,13 @@
 
         zipinfo = self._getinfo()
 
-        with self._zip_file.open(zipinfo) as f:
-            with open(self.dest_path, "wb") as dest:
-                shutil.copyfileobj(f, dest)
+        # optimization: the file is created by open(),
+        # skip the decompression when there is 0 bytes to decompress.
+        with open(self.dest_path, "wb") as dest:
+            if zipinfo.file_size > 0:
+                with self._zip_file.open(zipinfo) as f:
+                    blocksize = min(zipinfo.file_size, 1024 * 1024)
+                    shutil.copyfileobj(f, dest, blocksize)
 
         if zip_item_is_executable(zipinfo):
             set_extracted_file_to_default_mode_plus_executable(self.dest_path)
@@ -421,7 +419,7 @@
         return super().make(specification, options)
 
 
-def _install_wheel(
+def _install_wheel(  # noqa: C901, PLR0915 function is too long
     name: str,
     wheel_zip: ZipFile,
     wheel_path: str,
@@ -580,7 +578,15 @@
     script_scheme_files = map(ScriptFile, script_scheme_files)
     files = chain(files, script_scheme_files)
 
+    existing_parents = set()
     for file in files:
+        # directory creation is lazy and after file filtering
+        # to ensure we don't install empty dirs; empty dirs can't be
+        # uninstalled.
+        parent_dir = os.path.dirname(file.dest_path)
+        if parent_dir not in existing_parents:
+            ensure_dir(parent_dir)
+            existing_parents.add(parent_dir)
         file.save()
         record_installed(file.src_record_path, file.dest_path, file.changed)
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/pyproject.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/pyproject.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/pyproject.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/pyproject.py	2024-08-15 06:46:07.190821873 -0400
@@ -1,16 +1,22 @@
 import importlib.util
 import os
+import sys
 from collections import namedtuple
 from typing import Any, List, Optional
 
-from pip._vendor import tomli
-from pip._vendor.packaging.requirements import InvalidRequirement, Requirement
+if sys.version_info >= (3, 11):
+    import tomllib
+else:
+    from pip._vendor import tomli as tomllib
+
+from pip._vendor.packaging.requirements import InvalidRequirement
 
 from pip._internal.exceptions import (
     InstallationError,
     InvalidPyProjectBuildRequires,
     MissingPyProjectBuildRequires,
 )
+from pip._internal.utils.packaging import get_requirement
 
 
 def _is_list_of_str(obj: Any) -> bool:
@@ -61,7 +67,7 @@
 
     if has_pyproject:
         with open(pyproject_toml, encoding="utf-8") as f:
-            pp_toml = tomli.loads(f.read())
+            pp_toml = tomllib.loads(f.read())
         build_system = pp_toml.get("build-system")
     else:
         build_system = None
@@ -151,7 +157,7 @@
     # Each requirement must be valid as per PEP 508
     for requirement in requires:
         try:
-            Requirement(requirement)
+            get_requirement(requirement)
         except InvalidRequirement as error:
             raise InvalidPyProjectBuildRequires(
                 package=req_name,
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/req/constructors.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/req/constructors.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/req/constructors.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/req/constructors.py	2024-08-15 06:46:07.187821873 -0400
@@ -81,7 +81,7 @@
         pre is not None and post is not None
     ), f"regex group selection for requirement {req} failed, this should never happen"
     extras: str = "[%s]" % ",".join(sorted(new_extras)) if new_extras else ""
-    return Requirement(f"{pre}{extras}{post}")
+    return get_requirement(f"{pre}{extras}{post}")
 
 
 def parse_editable(editable_req: str) -> Tuple[Optional[str], str, Set[str]]:
@@ -163,7 +163,7 @@
             # If there is a line continuation, drop it, and append the next line.
             if line.endswith("\\"):
                 line = line[:-2].strip() + next(lines, "")
-            Requirement(line)
+            get_requirement(line)
             return
 
 
@@ -205,7 +205,7 @@
 
     if name is not None:
         try:
-            req: Optional[Requirement] = Requirement(name)
+            req: Optional[Requirement] = get_requirement(name)
         except InvalidRequirement as exc:
             raise InstallationError(f"Invalid requirement: {name!r}: {exc}")
     else:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/req/req_install.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/req/req_install.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/req/req_install.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/req/req_install.py	2024-08-15 06:46:07.187821873 -0400
@@ -52,6 +52,7 @@
     redact_auth_from_requirement,
     redact_auth_from_url,
 )
+from pip._internal.utils.packaging import get_requirement
 from pip._internal.utils.subprocess import runner_with_spinner_message
 from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
 from pip._internal.utils.unpacking import unpack_file
@@ -395,7 +396,7 @@
         else:
             op = "==="
 
-        self.req = Requirement(
+        self.req = get_requirement(
             "".join(
                 [
                     self.metadata["Name"],
@@ -421,7 +422,7 @@
             metadata_name,
             self.name,
         )
-        self.req = Requirement(metadata_name)
+        self.req = get_requirement(metadata_name)
 
     def check_if_exists(self, use_user_site: bool) -> None:
         """Find an installed distribution that satisfies or conflicts
@@ -824,6 +825,21 @@
         )
 
         if self.editable and not self.is_wheel:
+            deprecated(
+                reason=(
+                    f"Legacy editable install of {self} (setup.py develop) "
+                    "is deprecated."
+                ),
+                replacement=(
+                    "to add a pyproject.toml or enable --use-pep517, "
+                    "and use setuptools >= 64. "
+                    "If the resulting installation is not behaving as expected, "
+                    "try using --config-settings editable_mode=compat. "
+                    "Please consult the setuptools documentation for more information"
+                ),
+                gone_in="25.0",
+                issue=11457,
+            )
             if self.config_settings:
                 logger.warning(
                     "--config-settings ignored for legacy editable install of %s. "
@@ -909,7 +925,7 @@
             reason="--build-option and --global-option are deprecated.",
             issue=11859,
             replacement="to use --config-settings",
-            gone_in="24.2",
+            gone_in="25.0",
         )
         logger.warning(
             "Implying --no-binary=:all: due to the presence of "
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/factory.py	2024-08-15 06:46:07.188821873 -0400
@@ -121,6 +121,7 @@
         self._extras_candidate_cache: Dict[
             Tuple[int, FrozenSet[NormalizedName]], ExtrasCandidate
         ] = {}
+        self._supported_tags_cache = get_supported()
 
         if not ignore_installed:
             env = get_default_environment()
@@ -608,7 +609,7 @@
         return self._wheel_cache.get_cache_entry(
             link=link,
             package_name=name,
-            supported_tags=get_supported(),
+            supported_tags=self._supported_tags_cache,
         )
 
     def get_dist_to_uninstall(self, candidate: Candidate) -> Optional[BaseDistribution]:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/reporter.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/reporter.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/reporter.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/reporter.py	2024-08-15 06:46:07.188821873 -0400
@@ -66,6 +66,7 @@
 
     def ending_round(self, index: int, state: Any) -> None:
         logger.info("Reporter.ending_round(%r, state)", index)
+        logger.debug("Reporter.ending_round(%r, %r)", index, state)
 
     def ending(self, state: Any) -> None:
         logger.info("Reporter.ending(%r)", state)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/self_outdated_check.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/self_outdated_check.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/self_outdated_check.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/self_outdated_check.py	2024-08-15 06:46:07.190821873 -0400
@@ -232,17 +232,13 @@
     if not installed_dist:
         return
 
-    try:
-        upgrade_prompt = _self_version_check_logic(
-            state=SelfCheckState(cache_dir=options.cache_dir),
-            current_time=datetime.datetime.now(datetime.timezone.utc),
-            local_version=installed_dist.version,
-            get_remote_version=functools.partial(
-                _get_current_remote_pip_version, session, options
-            ),
-        )
-        if upgrade_prompt is not None:
-            logger.warning("%s", upgrade_prompt, extra={"rich": True})
-    except Exception:
-        logger.warning("There was an error checking the latest version of pip.")
-        logger.debug("See below for error", exc_info=True)
+    upgrade_prompt = _self_version_check_logic(
+        state=SelfCheckState(cache_dir=options.cache_dir),
+        current_time=datetime.datetime.now(datetime.timezone.utc),
+        local_version=installed_dist.version,
+        get_remote_version=functools.partial(
+            _get_current_remote_pip_version, session, options
+        ),
+    )
+    if upgrade_prompt is not None:
+        logger.warning("%s", upgrade_prompt, extra={"rich": True})
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/filesystem.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/filesystem.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/filesystem.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/filesystem.py	2024-08-15 06:46:07.191821873 -0400
@@ -7,10 +7,9 @@
 from tempfile import NamedTemporaryFile
 from typing import Any, BinaryIO, Generator, List, Union, cast
 
-from pip._vendor.tenacity import retry, stop_after_delay, wait_fixed
-
 from pip._internal.utils.compat import get_path_uid
 from pip._internal.utils.misc import format_size
+from pip._internal.utils.retry import retry
 
 
 def check_path_owner(path: str) -> bool:
@@ -65,10 +64,7 @@
             os.fsync(result.fileno())
 
 
-# Tenacity raises RetryError by default, explicitly raise the original exception
-_replace_retry = retry(reraise=True, stop=stop_after_delay(1), wait=wait_fixed(0.25))
-
-replace = _replace_retry(os.replace)
+replace = retry(stop_after_delay=1, wait=0.25)(os.replace)
 
 
 # test_writable_dir and _test_writable_dir_win are copied from Flit,
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/glibc.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/glibc.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/glibc.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/glibc.py	2024-08-15 06:46:07.191821873 -0400
@@ -40,7 +40,20 @@
     # manpage says, "If filename is NULL, then the returned handle is for the
     # main program". This way we can let the linker do the work to figure out
     # which libc our process is actually using.
-    process_namespace = ctypes.CDLL(None)
+    #
+    # We must also handle the special case where the executable is not a
+    # dynamically linked executable. This can occur when using musl libc,
+    # for example. In this situation, dlopen() will error, leading to an
+    # OSError. Interestingly, at least in the case of musl, there is no
+    # errno set on the OSError. The single string argument used to construct
+    # OSError comes from libc itself and is therefore not portable to
+    # hard code here. In any case, failure to call dlopen() means we
+    # can't proceed, so we bail on our attempt.
+    try:
+        process_namespace = ctypes.CDLL(None)
+    except OSError:
+        return None
+
     try:
         gnu_get_libc_version = process_namespace.gnu_get_libc_version
     except AttributeError:
@@ -50,7 +63,7 @@
 
     # Call gnu_get_libc_version, which returns a string like "2.5"
     gnu_get_libc_version.restype = ctypes.c_char_p
-    version_str = gnu_get_libc_version()
+    version_str: str = gnu_get_libc_version()
     # py2 / py3 compatibility:
     if not isinstance(version_str, str):
         version_str = version_str.decode("ascii")
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/hashes.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/hashes.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/hashes.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/hashes.py	2024-08-15 06:46:07.191821873 -0400
@@ -33,7 +33,7 @@
         if hashes is not None:
             for alg, keys in hashes.items():
                 # Make sure values are always sorted (to ease equality checks)
-                allowed[alg] = sorted(keys)
+                allowed[alg] = [k.lower() for k in sorted(keys)]
         self._allowed = allowed
 
     def __and__(self, other: "Hashes") -> "Hashes":
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/logging.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/logging.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/logging.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/logging.py	2024-08-15 06:46:07.191821873 -0400
@@ -154,8 +154,8 @@
         style: Optional[Style] = None
 
         # If we are given a diagnostic error to present, present it with indentation.
-        assert isinstance(record.args, tuple)
         if getattr(record, "rich", False):
+            assert isinstance(record.args, tuple)
             (rich_renderable,) = record.args
             assert isinstance(
                 rich_renderable, (ConsoleRenderable, RichCast, str)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/misc.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/misc.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/misc.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/misc.py	2024-08-15 06:46:07.191821873 -0400
@@ -1,7 +1,6 @@
 import errno
 import getpass
 import hashlib
-import io
 import logging
 import os
 import posixpath
@@ -36,12 +35,12 @@
 
 from pip._vendor.packaging.requirements import Requirement
 from pip._vendor.pyproject_hooks import BuildBackendHookCaller
-from pip._vendor.tenacity import retry, stop_after_delay, wait_fixed
 
 from pip import __version__
 from pip._internal.exceptions import CommandError, ExternallyManagedEnvironment
 from pip._internal.locations import get_major_minor_version
 from pip._internal.utils.compat import WINDOWS
+from pip._internal.utils.retry import retry
 from pip._internal.utils.virtualenv import running_under_virtualenv
 
 __all__ = [
@@ -70,6 +69,8 @@
 OnExc = Callable[[FunctionType, Path, BaseException], Any]
 OnErr = Callable[[FunctionType, Path, ExcInfo], Any]
 
+FILE_CHUNK_SIZE = 1024 * 1024
+
 
 def get_pip_version() -> str:
     pip_pkg_dir = os.path.join(os.path.dirname(__file__), "..", "..")
@@ -120,12 +121,9 @@
 
 
 # Retry every half second for up to 3 seconds
-# Tenacity raises RetryError by default, explicitly raise the original exception
-@retry(reraise=True, stop=stop_after_delay(3), wait=wait_fixed(0.5))
+@retry(stop_after_delay=3, wait=0.5)
 def rmtree(
-    dir: str,
-    ignore_errors: bool = False,
-    onexc: Optional[OnExc] = None,
+    dir: str, ignore_errors: bool = False, onexc: Optional[OnExc] = None
 ) -> None:
     if ignore_errors:
         onexc = _onerror_ignore
@@ -149,7 +147,7 @@
 
 
 def _onerror_reraise(*_args: Any) -> None:
-    raise
+    raise  # noqa: PLE0704 - Bare exception used to reraise existing exception
 
 
 def rmtree_errorhandler(
@@ -314,7 +312,7 @@
 
 
 def read_chunks(
-    file: BinaryIO, size: int = io.DEFAULT_BUFFER_SIZE
+    file: BinaryIO, size: int = FILE_CHUNK_SIZE
 ) -> Generator[bytes, None, None]:
     """Yield pieces of data from a file-like object until EOF."""
     while True:
@@ -644,8 +642,7 @@
 
 
 def partition(
-    pred: Callable[[T], bool],
-    iterable: Iterable[T],
+    pred: Callable[[T], bool], iterable: Iterable[T]
 ) -> Tuple[Iterable[T], Iterable[T]]:
     """
     Use a predicate to partition entries into false entries and true entries,
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/packaging.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/packaging.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/packaging.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/packaging.py	2024-08-15 06:46:07.191821873 -0400
@@ -34,7 +34,7 @@
     return python_version in requires_python_specifier
 
 
-@functools.lru_cache(maxsize=512)
+@functools.lru_cache(maxsize=2048)
 def get_requirement(req_string: str) -> Requirement:
     """Construct a packaging.Requirement object with caching"""
     # Parsing requirement strings is expensive, and is also expected to happen
Only in /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils: retry.py
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/temp_dir.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/temp_dir.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_internal/utils/temp_dir.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_internal/utils/temp_dir.py	2024-08-15 06:46:07.191821873 -0400
@@ -208,7 +208,7 @@
 
         if self.ignore_cleanup_errors:
             try:
-                # first try with tenacity; retrying to handle ephemeral errors
+                # first try with @retry; retrying to handle ephemeral errors
                 rmtree(self._path, ignore_errors=False)
             except OSError:
                 # last pass ignore/log all errors
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/certifi/cacert.pem /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/certifi/cacert.pem
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/certifi/cacert.pem	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/certifi/cacert.pem	2024-08-15 06:46:07.175821873 -0400
@@ -3485,46 +3485,6 @@
 +RHUjE7AwWHCFUyqqx0LMV87HOIAl0Qx5v5zli/altP+CAezNIm8BZ/3Hobui3A=
 -----END CERTIFICATE-----
 
-# Issuer: CN=GLOBALTRUST 2020 O=e-commerce monitoring GmbH
-# Subject: CN=GLOBALTRUST 2020 O=e-commerce monitoring GmbH
-# Label: "GLOBALTRUST 2020"
-# Serial: 109160994242082918454945253
-# MD5 Fingerprint: 8a:c7:6f:cb:6d:e3:cc:a2:f1:7c:83:fa:0e:78:d7:e8
-# SHA1 Fingerprint: d0:67:c1:13:51:01:0c:aa:d0:c7:6a:65:37:31:16:26:4f:53:71:a2
-# SHA256 Fingerprint: 9a:29:6a:51:82:d1:d4:51:a2:e3:7f:43:9b:74:da:af:a2:67:52:33:29:f9:0f:9a:0d:20:07:c3:34:e2:3c:9a
------BEGIN CERTIFICATE-----
-MIIFgjCCA2qgAwIBAgILWku9WvtPilv6ZeUwDQYJKoZIhvcNAQELBQAwTTELMAkG
-A1UEBhMCQVQxIzAhBgNVBAoTGmUtY29tbWVyY2UgbW9uaXRvcmluZyBHbWJIMRkw
-FwYDVQQDExBHTE9CQUxUUlVTVCAyMDIwMB4XDTIwMDIxMDAwMDAwMFoXDTQwMDYx
-MDAwMDAwMFowTTELMAkGA1UEBhMCQVQxIzAhBgNVBAoTGmUtY29tbWVyY2UgbW9u
-aXRvcmluZyBHbWJIMRkwFwYDVQQDExBHTE9CQUxUUlVTVCAyMDIwMIICIjANBgkq
-hkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAri5WrRsc7/aVj6B3GyvTY4+ETUWiD59b
-RatZe1E0+eyLinjF3WuvvcTfk0Uev5E4C64OFudBc/jbu9G4UeDLgztzOG53ig9Z
-YybNpyrOVPu44sB8R85gfD+yc/LAGbaKkoc1DZAoouQVBGM+uq/ufF7MpotQsjj3
-QWPKzv9pj2gOlTblzLmMCcpL3TGQlsjMH/1WljTbjhzqLL6FLmPdqqmV0/0plRPw
-yJiT2S0WR5ARg6I6IqIoV6Lr/sCMKKCmfecqQjuCgGOlYx8ZzHyyZqjC0203b+J+
-BlHZRYQfEs4kUmSFC0iAToexIiIwquuuvuAC4EDosEKAA1GqtH6qRNdDYfOiaxaJ
-SaSjpCuKAsR49GiKweR6NrFvG5Ybd0mN1MkGco/PU+PcF4UgStyYJ9ORJitHHmkH
-r96i5OTUawuzXnzUJIBHKWk7buis/UDr2O1xcSvy6Fgd60GXIsUf1DnQJ4+H4xj0
-4KlGDfV0OoIu0G4skaMxXDtG6nsEEFZegB31pWXogvziB4xiRfUg3kZwhqG8k9Me
-dKZssCz3AwyIDMvUclOGvGBG85hqwvG/Q/lwIHfKN0F5VVJjjVsSn8VoxIidrPIw
-q7ejMZdnrY8XD2zHc+0klGvIg5rQmjdJBKuxFshsSUktq6HQjJLyQUp5ISXbY9e2
-nKd+Qmn7OmMCAwEAAaNjMGEwDwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMC
-AQYwHQYDVR0OBBYEFNwuH9FhN3nkq9XVsxJxaD1qaJwiMB8GA1UdIwQYMBaAFNwu
-H9FhN3nkq9XVsxJxaD1qaJwiMA0GCSqGSIb3DQEBCwUAA4ICAQCR8EICaEDuw2jA
-VC/f7GLDw56KoDEoqoOOpFaWEhCGVrqXctJUMHytGdUdaG/7FELYjQ7ztdGl4wJC
-XtzoRlgHNQIw4Lx0SsFDKv/bGtCwr2zD/cuz9X9tAy5ZVp0tLTWMstZDFyySCstd
-6IwPS3BD0IL/qMy/pJTAvoe9iuOTe8aPmxadJ2W8esVCgmxcB9CpwYhgROmYhRZf
-+I/KARDOJcP5YBugxZfD0yyIMaK9MOzQ0MAS8cE54+X1+NZK3TTN+2/BT+MAi1bi
-kvcoskJ3ciNnxz8RFbLEAwW+uxF7Cr+obuf/WEPPm2eggAe2HcqtbepBEX4tdJP7
-wry+UUTF72glJ4DjyKDUEuzZpTcdN3y0kcra1LGWge9oXHYQSa9+pTeAsRxSvTOB
-TI/53WXZFM2KJVj04sWDpQmQ1GwUY7VA3+vA/MRYfg0UFodUJ25W5HCEuGwyEn6C
-MUO+1918oa2u1qsgEu8KwxCMSZY13At1XrFP1U80DhEgB3VDRemjEdqso5nCtnkn
-4rnvyOL2NSl6dPrFf4IFYqYK6miyeUcGbvJXqBUzxvd4Sj1Ce2t+/vdG6tHrju+I
-aFvowdlxfv1k7/9nR4hYJS8+hge9+6jlgqispdNpQ80xiEmEU5LAsTkbOYMBMMTy
-qfrQA71yN2BWHzZ8vTmR9W0Nv3vXkg==
------END CERTIFICATE-----
-
 # Issuer: CN=ANF Secure Server Root CA O=ANF Autoridad de Certificacion OU=ANF CA Raiz
 # Subject: CN=ANF Secure Server Root CA O=ANF Autoridad de Certificacion OU=ANF CA Raiz
 # Label: "ANF Secure Server Root CA"
@@ -4812,3 +4772,27 @@
 ntOoUAw3gi/q4Iqd4Sw5/7W0cwDk90imc6y/st53BIe0o82bNSQ3+pCTE4FCxpgm
 dTdmQRCsu/WU48IxK63nI1bMNSWSs1A=
 -----END CERTIFICATE-----
+
+# Issuer: CN=FIRMAPROFESIONAL CA ROOT-A WEB O=Firmaprofesional SA
+# Subject: CN=FIRMAPROFESIONAL CA ROOT-A WEB O=Firmaprofesional SA
+# Label: "FIRMAPROFESIONAL CA ROOT-A WEB"
+# Serial: 65916896770016886708751106294915943533
+# MD5 Fingerprint: 82:b2:ad:45:00:82:b0:66:63:f8:5f:c3:67:4e:ce:a3
+# SHA1 Fingerprint: a8:31:11:74:a6:14:15:0d:ca:77:dd:0e:e4:0c:5d:58:fc:a0:72:a5
+# SHA256 Fingerprint: be:f2:56:da:f2:6e:9c:69:bd:ec:16:02:35:97:98:f3:ca:f7:18:21:a0:3e:01:82:57:c5:3c:65:61:7f:3d:4a
+-----BEGIN CERTIFICATE-----
+MIICejCCAgCgAwIBAgIQMZch7a+JQn81QYehZ1ZMbTAKBggqhkjOPQQDAzBuMQsw
+CQYDVQQGEwJFUzEcMBoGA1UECgwTRmlybWFwcm9mZXNpb25hbCBTQTEYMBYGA1UE
+YQwPVkFURVMtQTYyNjM0MDY4MScwJQYDVQQDDB5GSVJNQVBST0ZFU0lPTkFMIENB
+IFJPT1QtQSBXRUIwHhcNMjIwNDA2MDkwMTM2WhcNNDcwMzMxMDkwMTM2WjBuMQsw
+CQYDVQQGEwJFUzEcMBoGA1UECgwTRmlybWFwcm9mZXNpb25hbCBTQTEYMBYGA1UE
+YQwPVkFURVMtQTYyNjM0MDY4MScwJQYDVQQDDB5GSVJNQVBST0ZFU0lPTkFMIENB
+IFJPT1QtQSBXRUIwdjAQBgcqhkjOPQIBBgUrgQQAIgNiAARHU+osEaR3xyrq89Zf
+e9MEkVz6iMYiuYMQYneEMy3pA4jU4DP37XcsSmDq5G+tbbT4TIqk5B/K6k84Si6C
+cyvHZpsKjECcfIr28jlgst7L7Ljkb+qbXbdTkBgyVcUgt5SjYzBhMA8GA1UdEwEB
+/wQFMAMBAf8wHwYDVR0jBBgwFoAUk+FDY1w8ndYn81LsF7Kpryz3dvgwHQYDVR0O
+BBYEFJPhQ2NcPJ3WJ/NS7Beyqa8s93b4MA4GA1UdDwEB/wQEAwIBBjAKBggqhkjO
+PQQDAwNoADBlAjAdfKR7w4l1M+E7qUW/Runpod3JIha3RxEL2Jq68cgLcFBTApFw
+hVmpHqTm6iMxoAACMQD94vizrxa5HnPEluPBMBnYfubDl94cT7iJLzPrSA8Z94dG
+XSaQpYXFuXqUPoeovQA=
+-----END CERTIFICATE-----
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/certifi/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/certifi/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/certifi/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/certifi/__init__.py	2024-08-15 06:46:07.175821873 -0400
@@ -1,4 +1,4 @@
 from .core import contents, where
 
 __all__ = ["contents", "where"]
-__version__ = "2024.02.02"
+__version__ = "2024.07.04"
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/__init__.py	2024-08-15 06:46:07.169821873 -0400
@@ -65,10 +65,10 @@
     vendored("packaging")
     vendored("packaging.version")
     vendored("packaging.specifiers")
-    vendored("pep517")
     vendored("pkg_resources")
     vendored("platformdirs")
     vendored("progress")
+    vendored("pyproject_hooks")
     vendored("requests")
     vendored("requests.exceptions")
     vendored("requests.packages")
@@ -110,7 +110,7 @@
     vendored("rich.style")
     vendored("rich.text")
     vendored("rich.traceback")
-    vendored("tenacity")
-    vendored("tomli")
+    if sys.version_info < (3, 11):
+        vendored("tomli")
     vendored("truststore")
     vendored("urllib3")
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pkg_resources/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pkg_resources/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pkg_resources/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pkg_resources/__init__.py	2024-08-15 06:46:07.169821873 -0400
@@ -1,3 +1,6 @@
+# TODO: Add Generic type annotations to initialized collections.
+# For now we'd simply use implicit Any/Unknown which would add redundant annotations
+# mypy: disable-error-code="var-annotated"
 """
 Package resource API
 --------------------
@@ -17,9 +20,11 @@
 :mod:`importlib.metadata` and :pypi:`packaging` instead.
 """
 
+from __future__ import annotations
+
 import sys
 
-if sys.version_info < (3, 8):
+if sys.version_info < (3, 8):  # noqa: UP036 # Check for unsupported versions
     raise RuntimeError("Python 3.8 or later is required")
 
 import os
@@ -27,7 +32,24 @@
 import time
 import re
 import types
-from typing import List, Protocol
+from typing import (
+    Any,
+    Literal,
+    Dict,
+    Iterator,
+    Mapping,
+    MutableSequence,
+    NamedTuple,
+    NoReturn,
+    Tuple,
+    Union,
+    TYPE_CHECKING,
+    Protocol,
+    Callable,
+    Iterable,
+    TypeVar,
+    overload,
+)
 import zipfile
 import zipimport
 import warnings
@@ -46,6 +68,7 @@
 import ntpath
 import posixpath
 import importlib
+import importlib.abc
 import importlib.machinery
 from pkgutil import get_importer
 
@@ -53,6 +76,8 @@
 
 # capture these to bypass sandboxing
 from os import utime
+from os import open as os_open
+from os.path import isdir, split
 
 try:
     from os import mkdir, rename, unlink
@@ -62,49 +87,57 @@
     # no write support, probably under GAE
     WRITE_SUPPORT = False
 
-from os import open as os_open
-from os.path import isdir, split
-
 from pip._internal.utils._jaraco_text import (
     yield_lines,
     drop_comment,
     join_continuation,
 )
+from pip._vendor.packaging import markers as _packaging_markers
+from pip._vendor.packaging import requirements as _packaging_requirements
+from pip._vendor.packaging import utils as _packaging_utils
+from pip._vendor.packaging import version as _packaging_version
+from pip._vendor.platformdirs import user_cache_dir as _user_cache_dir
+
+if TYPE_CHECKING:
+    from _typeshed import BytesPath, StrPath, StrOrBytesPath
+    from pip._vendor.typing_extensions import Self
+
+
+# Patch: Remove deprecation warning from vendored pkg_resources.
+# Setting PYTHONWARNINGS=error to verify builds produce no warnings
+# causes immediate exceptions.
+# See https://github.com/pypa/pip/issues/12243
+
+
+_T = TypeVar("_T")
+_DistributionT = TypeVar("_DistributionT", bound="Distribution")
+# Type aliases
+_NestedStr = Union[str, Iterable[Union[str, Iterable["_NestedStr"]]]]
+_InstallerTypeT = Callable[["Requirement"], "_DistributionT"]
+_InstallerType = Callable[["Requirement"], Union["Distribution", None]]
+_PkgReqType = Union[str, "Requirement"]
+_EPDistType = Union["Distribution", _PkgReqType]
+_MetadataType = Union["IResourceProvider", None]
+_ResolvedEntryPoint = Any  # Can be any attribute in the module
+_ResourceStream = Any  # TODO / Incomplete: A readable file-like object
+# Any object works, but let's indicate we expect something like a module (optionally has __loader__ or __file__)
+_ModuleLike = Union[object, types.ModuleType]
+# Any: Should be _ModuleLike but we end up with issues where _ModuleLike doesn't have _ZipLoaderModule's __loader__
+_ProviderFactoryType = Callable[[Any], "IResourceProvider"]
+_DistFinderType = Callable[[_T, str, bool], Iterable["Distribution"]]
+_NSHandlerType = Callable[[_T, str, str, types.ModuleType], Union[str, None]]
+_AdapterT = TypeVar(
+    "_AdapterT", _DistFinderType[Any], _ProviderFactoryType, _NSHandlerType[Any]
+)
 
-from pip._vendor import platformdirs
-from pip._vendor import packaging
 
-__import__('pip._vendor.packaging.version')
-__import__('pip._vendor.packaging.specifiers')
-__import__('pip._vendor.packaging.requirements')
-__import__('pip._vendor.packaging.markers')
-__import__('pip._vendor.packaging.utils')
-
-# declare some globals that will be defined later to
-# satisfy the linters.
-require = None
-working_set = None
-add_activation_listener = None
-cleanup_resources = None
-resource_stream = None
-set_extraction_path = None
-resource_isdir = None
-resource_string = None
-iter_entry_points = None
-resource_listdir = None
-resource_filename = None
-resource_exists = None
-_distribution_finders = None
-_namespace_handlers = None
-_namespace_packages = None
-
-
-warnings.warn(
-    "pkg_resources is deprecated as an API. "
-    "See https://setuptools.pypa.io/en/latest/pkg_resources.html",
-    DeprecationWarning,
-    stacklevel=2,
-)
+# Use _typeshed.importlib.LoaderProtocol once available https://github.com/python/typeshed/pull/11890
+class _LoaderProtocol(Protocol):
+    def load_module(self, fullname: str, /) -> types.ModuleType: ...
+
+
+class _ZipLoaderModule(Protocol):
+    __loader__: zipimport.zipimporter
 
 
 _PEP440_FALLBACK = re.compile(r"^v?(?P<safe>(?:[0-9]+!)?[0-9]+(?:\.[0-9]+)*)", re.I)
@@ -117,18 +150,18 @@
     """
 
 
-parse_version = packaging.version.Version
+parse_version = _packaging_version.Version
 
 
-_state_vars = {}
+_state_vars: dict[str, str] = {}
 
 
-def _declare_state(vartype, **kw):
-    globals().update(kw)
-    _state_vars.update(dict.fromkeys(kw, vartype))
+def _declare_state(vartype: str, varname: str, initial_value: _T) -> _T:
+    _state_vars[varname] = vartype
+    return initial_value
 
 
-def __getstate__():
+def __getstate__() -> dict[str, Any]:
     state = {}
     g = globals()
     for k, v in _state_vars.items():
@@ -136,7 +169,7 @@
     return state
 
 
-def __setstate__(state):
+def __setstate__(state: dict[str, Any]) -> dict[str, Any]:
     g = globals()
     for k, v in state.items():
         g['_sset_' + _state_vars[k]](k, g[k], v)
@@ -291,17 +324,17 @@
     _template = "{self.dist} is installed but {self.req} is required"
 
     @property
-    def dist(self):
+    def dist(self) -> Distribution:
         return self.args[0]
 
     @property
-    def req(self):
+    def req(self) -> Requirement:
         return self.args[1]
 
     def report(self):
         return self._template.format(**locals())
 
-    def with_context(self, required_by):
+    def with_context(self, required_by: set[Distribution | str]):
         """
         If required_by is non-empty, return a version of self that is a
         ContextualVersionConflict.
@@ -321,7 +354,7 @@
     _template = VersionConflict._template + ' by {self.required_by}'
 
     @property
-    def required_by(self):
+    def required_by(self) -> set[str]:
         return self.args[2]
 
 
@@ -334,11 +367,11 @@
     )
 
     @property
-    def req(self):
+    def req(self) -> Requirement:
         return self.args[0]
 
     @property
-    def requirers(self):
+    def requirers(self) -> set[str] | None:
         return self.args[1]
 
     @property
@@ -358,7 +391,7 @@
     """Distribution doesn't have an "extra feature" of the given name"""
 
 
-_provider_factories = {}
+_provider_factories: dict[type[_ModuleLike], _ProviderFactoryType] = {}
 
 PY_MAJOR = '{}.{}'.format(*sys.version_info)
 EGG_DIST = 3
@@ -368,7 +401,9 @@
 DEVELOP_DIST = -1
 
 
-def register_loader_type(loader_type, provider_factory):
+def register_loader_type(
+    loader_type: type[_ModuleLike], provider_factory: _ProviderFactoryType
+):
     """Register `provider_factory` to make providers for `loader_type`
 
     `loader_type` is the type or class of a PEP 302 ``module.__loader__``,
@@ -378,7 +413,11 @@
     _provider_factories[loader_type] = provider_factory
 
 
-def get_provider(moduleOrReq):
+@overload
+def get_provider(moduleOrReq: str) -> IResourceProvider: ...
+@overload
+def get_provider(moduleOrReq: Requirement) -> Distribution: ...
+def get_provider(moduleOrReq: str | Requirement) -> IResourceProvider | Distribution:
     """Return an IResourceProvider for the named module or requirement"""
     if isinstance(moduleOrReq, Requirement):
         return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]
@@ -440,7 +479,7 @@
 get_platform = get_build_platform
 
 
-def compatible_platforms(provided, required):
+def compatible_platforms(provided: str | None, required: str | None):
     """Can code for the `provided` platform run on the `required` platform?
 
     Returns true if either platform is ``None``, or the platforms are equal.
@@ -489,89 +528,106 @@
     return False
 
 
-def get_distribution(dist):
+@overload
+def get_distribution(dist: _DistributionT) -> _DistributionT: ...
+@overload
+def get_distribution(dist: _PkgReqType) -> Distribution: ...
+def get_distribution(dist: Distribution | _PkgReqType) -> Distribution:
     """Return a current distribution object for a Requirement or string"""
     if isinstance(dist, str):
         dist = Requirement.parse(dist)
     if isinstance(dist, Requirement):
-        dist = get_provider(dist)
+        # Bad type narrowing, dist has to be a Requirement here, so get_provider has to return Distribution
+        dist = get_provider(dist)  # type: ignore[assignment]
     if not isinstance(dist, Distribution):
-        raise TypeError("Expected string, Requirement, or Distribution", dist)
+        raise TypeError("Expected str, Requirement, or Distribution", dist)
     return dist
 
 
-def load_entry_point(dist, group, name):
+def load_entry_point(dist: _EPDistType, group: str, name: str) -> _ResolvedEntryPoint:
     """Return `name` entry point of `group` for `dist` or raise ImportError"""
     return get_distribution(dist).load_entry_point(group, name)
 
 
-def get_entry_map(dist, group=None):
+@overload
+def get_entry_map(
+    dist: _EPDistType, group: None = None
+) -> dict[str, dict[str, EntryPoint]]: ...
+@overload
+def get_entry_map(dist: _EPDistType, group: str) -> dict[str, EntryPoint]: ...
+def get_entry_map(dist: _EPDistType, group: str | None = None):
     """Return the entry point map for `group`, or the full entry map"""
     return get_distribution(dist).get_entry_map(group)
 
 
-def get_entry_info(dist, group, name):
+def get_entry_info(dist: _EPDistType, group: str, name: str):
     """Return the EntryPoint object for `group`+`name`, or ``None``"""
     return get_distribution(dist).get_entry_info(group, name)
 
 
 class IMetadataProvider(Protocol):
-    def has_metadata(self, name) -> bool:
+    def has_metadata(self, name: str) -> bool:
         """Does the package's distribution contain the named metadata?"""
 
-    def get_metadata(self, name):
+    def get_metadata(self, name: str) -> str:
         """The named metadata resource as a string"""
 
-    def get_metadata_lines(self, name):
+    def get_metadata_lines(self, name: str) -> Iterator[str]:
         """Yield named metadata resource as list of non-blank non-comment lines
 
         Leading and trailing whitespace is stripped from each line, and lines
         with ``#`` as the first non-blank character are omitted."""
 
-    def metadata_isdir(self, name) -> bool:
+    def metadata_isdir(self, name: str) -> bool:
         """Is the named metadata a directory?  (like ``os.path.isdir()``)"""
 
-    def metadata_listdir(self, name):
+    def metadata_listdir(self, name: str) -> list[str]:
         """List of metadata names in the directory (like ``os.listdir()``)"""
 
-    def run_script(self, script_name, namespace):
+    def run_script(self, script_name: str, namespace: dict[str, Any]) -> None:
         """Execute the named script in the supplied namespace dictionary"""
 
 
 class IResourceProvider(IMetadataProvider, Protocol):
     """An object that provides access to package resources"""
 
-    def get_resource_filename(self, manager, resource_name):
+    def get_resource_filename(
+        self, manager: ResourceManager, resource_name: str
+    ) -> str:
         """Return a true filesystem path for `resource_name`
 
-        `manager` must be an ``IResourceManager``"""
+        `manager` must be a ``ResourceManager``"""
 
-    def get_resource_stream(self, manager, resource_name):
+    def get_resource_stream(
+        self, manager: ResourceManager, resource_name: str
+    ) -> _ResourceStream:
         """Return a readable file-like object for `resource_name`
 
-        `manager` must be an ``IResourceManager``"""
+        `manager` must be a ``ResourceManager``"""
 
-    def get_resource_string(self, manager, resource_name) -> bytes:
+    def get_resource_string(
+        self, manager: ResourceManager, resource_name: str
+    ) -> bytes:
         """Return the contents of `resource_name` as :obj:`bytes`
 
-        `manager` must be an ``IResourceManager``"""
+        `manager` must be a ``ResourceManager``"""
 
-    def has_resource(self, resource_name):
+    def has_resource(self, resource_name: str) -> bool:
         """Does the package contain the named resource?"""
 
-    def resource_isdir(self, resource_name):
+    def resource_isdir(self, resource_name: str) -> bool:
         """Is the named resource a directory?  (like ``os.path.isdir()``)"""
 
-    def resource_listdir(self, resource_name):
+    def resource_listdir(self, resource_name: str) -> list[str]:
         """List of resource names in the directory (like ``os.listdir()``)"""
 
 
 class WorkingSet:
     """A collection of active distributions on sys.path (or a similar list)"""
 
-    def __init__(self, entries=None):
+    def __init__(self, entries: Iterable[str] | None = None):
         """Create working set from list of path entries (default=sys.path)"""
-        self.entries = []
+        self.entries: list[str] = []
         self.entry_keys = {}
         self.by_key = {}
         self.normalized_to_canonical_keys = {}
@@ -625,7 +681,7 @@
         sys.path[:] = ws.entries
         return ws
 
-    def add_entry(self, entry):
+    def add_entry(self, entry: str):
         """Add a path item to ``.entries``, finding any distributions on it
 
         ``find_distributions(entry, True)`` is used to find distributions
@@ -640,11 +696,11 @@
         for dist in find_distributions(entry, True):
             self.add(dist, entry, False)
 
-    def __contains__(self, dist):
+    def __contains__(self, dist: Distribution) -> bool:
         """True if `dist` is the active distribution for its project"""
         return self.by_key.get(dist.key) == dist
 
-    def find(self, req):
+    def find(self, req: Requirement) -> Distribution | None:
         """Find a distribution matching requirement `req`
 
         If there is an active distribution for the requested project, this
@@ -668,7 +724,7 @@
             raise VersionConflict(dist, req)
         return dist
 
-    def iter_entry_points(self, group, name=None):
+    def iter_entry_points(self, group: str, name: str | None = None):
         """Yield entry point objects from `group` matching `name`
 
         If `name` is None, yields all entry points in `group` from all
@@ -682,7 +738,7 @@
             if name is None or name == entry.name
         )
 
-    def run_script(self, requires, script_name):
+    def run_script(self, requires: str, script_name: str):
         """Locate distribution for `requires` and run `script_name` script"""
         ns = sys._getframe(1).f_globals
         name = ns['__name__']
@@ -690,13 +746,13 @@
         ns['__name__'] = name
         self.require(requires)[0].run_script(script_name, ns)
 
-    def __iter__(self):
+    def __iter__(self) -> Iterator[Distribution]:
         """Yield distributions for non-duplicate projects in the working set
 
         The yield order is the order in which the items' path entries were
         added to the working set.
         """
-        seen = {}
+        seen = set()
         for item in self.entries:
             if item not in self.entry_keys:
                 # workaround a cache issue
@@ -704,10 +760,16 @@
 
             for key in self.entry_keys[item]:
                 if key not in seen:
-                    seen[key] = 1
+                    seen.add(key)
                     yield self.by_key[key]
 
-    def add(self, dist, entry=None, insert=True, replace=False):
+    def add(
+        self,
+        dist: Distribution,
+        entry: str | None = None,
+        insert: bool = True,
+        replace: bool = False,
+    ):
         """Add `dist` to working set, associated with `entry`
 
         If `entry` is unspecified, it defaults to the ``.location`` of `dist`.
@@ -731,7 +793,7 @@
             return
 
         self.by_key[dist.key] = dist
-        normalized_name = packaging.utils.canonicalize_name(dist.key)
+        normalized_name = _packaging_utils.canonicalize_name(dist.key)
         self.normalized_to_canonical_keys[normalized_name] = dist.key
         if dist.key not in keys:
             keys.append(dist.key)
@@ -739,14 +801,42 @@
             keys2.append(dist.key)
         self._added_new(dist)
 
+    @overload
     def resolve(
         self,
-        requirements,
-        env=None,
-        installer=None,
-        replace_conflicting=False,
-        extras=None,
-    ):
+        requirements: Iterable[Requirement],
+        env: Environment | None,
+        installer: _InstallerTypeT[_DistributionT],
+        replace_conflicting: bool = False,
+        extras: tuple[str, ...] | None = None,
+    ) -> list[_DistributionT]: ...
+    @overload
+    def resolve(
+        self,
+        requirements: Iterable[Requirement],
+        env: Environment | None = None,
+        *,
+        installer: _InstallerTypeT[_DistributionT],
+        replace_conflicting: bool = False,
+        extras: tuple[str, ...] | None = None,
+    ) -> list[_DistributionT]: ...
+    @overload
+    def resolve(
+        self,
+        requirements: Iterable[Requirement],
+        env: Environment | None = None,
+        installer: _InstallerType | None = None,
+        replace_conflicting: bool = False,
+        extras: tuple[str, ...] | None = None,
+    ) -> list[Distribution]: ...
+    def resolve(
+        self,
+        requirements: Iterable[Requirement],
+        env: Environment | None = None,
+        installer: _InstallerType | None | _InstallerTypeT[_DistributionT] = None,
+        replace_conflicting: bool = False,
+        extras: tuple[str, ...] | None = None,
+    ) -> list[Distribution] | list[_DistributionT]:
         """List all distributions needed to (recursively) meet `requirements`
 
         `requirements` must be a sequence of ``Requirement`` objects.  `env`,
@@ -774,7 +864,7 @@
         # set up the stack
         requirements = list(requirements)[::-1]
         # set of processed requirements
-        processed = {}
+        processed = set()
         # key -> dist
         best = {}
         to_activate = []
@@ -808,14 +898,14 @@
                 required_by[new_requirement].add(req.project_name)
                 req_extras[new_requirement] = req.extras
 
-            processed[req] = True
+            processed.add(req)
 
         # return list of distros to activate
         return to_activate
 
     def _resolve_dist(
         self, req, best, replace_conflicting, env, installer, required_by, to_activate
-    ):
+    ) -> Distribution:
         dist = best.get(req.key)
         if dist is None:
             # Find the best distribution and add it to the map
@@ -844,7 +934,41 @@
             raise VersionConflict(dist, req).with_context(dependent_req)
         return dist
 
-    def find_plugins(self, plugin_env, full_env=None, installer=None, fallback=True):
+    @overload
+    def find_plugins(
+        self,
+        plugin_env: Environment,
+        full_env: Environment | None,
+        installer: _InstallerTypeT[_DistributionT],
+        fallback: bool = True,
+    ) -> tuple[list[_DistributionT], dict[Distribution, Exception]]: ...
+    @overload
+    def find_plugins(
+        self,
+        plugin_env: Environment,
+        full_env: Environment | None = None,
+        *,
+        installer: _InstallerTypeT[_DistributionT],
+        fallback: bool = True,
+    ) -> tuple[list[_DistributionT], dict[Distribution, Exception]]: ...
+    @overload
+    def find_plugins(
+        self,
+        plugin_env: Environment,
+        full_env: Environment | None = None,
+        installer: _InstallerType | None = None,
+        fallback: bool = True,
+    ) -> tuple[list[Distribution], dict[Distribution, Exception]]: ...
+    def find_plugins(
+        self,
+        plugin_env: Environment,
+        full_env: Environment | None = None,
+        installer: _InstallerType | None | _InstallerTypeT[_DistributionT] = None,
+        fallback: bool = True,
+    ) -> tuple[
+        list[Distribution] | list[_DistributionT],
+        dict[Distribution, Exception],
+    ]:
         """Find all activatable distributions in `plugin_env`
 
         Example usage::
@@ -883,8 +1007,8 @@
         # scan project names in alphabetic order
         plugin_projects.sort()
 
-        error_info = {}
-        distributions = {}
+        error_info: dict[Distribution, Exception] = {}
+        distributions: dict[Distribution, Exception | None] = {}
 
         if full_env is None:
             env = Environment(self.entries)
@@ -920,12 +1044,12 @@
                     # success, no need to try any more versions of this project
                     break
 
-        distributions = list(distributions)
-        distributions.sort()
+        sorted_distributions = list(distributions)
+        sorted_distributions.sort()
 
-        return distributions, error_info
+        return sorted_distributions, error_info
 
-    def require(self, *requirements):
+    def require(self, *requirements: _NestedStr):
         """Ensure that distributions matching `requirements` are activated
 
         `requirements` must be a string or a (possibly-nested) sequence
@@ -941,7 +1065,9 @@
 
         return needed
 
-    def subscribe(self, callback, existing=True):
+    def subscribe(
+        self, callback: Callable[[Distribution], object], existing: bool = True
+    ):
         """Invoke `callback` for all distributions
 
         If `existing=True` (default),
@@ -977,12 +1103,12 @@
         self.callbacks = callbacks[:]
 
 
-class _ReqExtras(dict):
+class _ReqExtras(Dict["Requirement", Tuple[str, ...]]):
     """
     Map each requirement to the extras that demanded it.
     """
 
-    def markers_pass(self, req, extras=None):
+    def markers_pass(self, req: Requirement, extras: tuple[str, ...] | None = None):
         """
         Evaluate markers for req against each extra that
         demanded it.
@@ -1001,7 +1127,10 @@
     """Searchable snapshot of distributions on a search path"""
 
     def __init__(
-        self, search_path=None, platform=get_supported_platform(), python=PY_MAJOR
+        self,
+        search_path: Iterable[str] | None = None,
+        platform: str | None = get_supported_platform(),
+        python: str | None = PY_MAJOR,
     ):
         """Snapshot distributions available on a search path
 
@@ -1024,7 +1153,7 @@
         self.python = python
         self.scan(search_path)
 
-    def can_add(self, dist):
+    def can_add(self, dist: Distribution):
         """Is distribution `dist` acceptable for this environment?
 
         The distribution must match the platform and python version
@@ -1038,11 +1167,11 @@
         )
         return py_compat and compatible_platforms(dist.platform, self.platform)
 
-    def remove(self, dist):
+    def remove(self, dist: Distribution):
         """Remove `dist` from the environment"""
         self._distmap[dist.key].remove(dist)
 
-    def scan(self, search_path=None):
+    def scan(self, search_path: Iterable[str] | None = None):
         """Scan `search_path` for distributions usable in this environment
 
         Any distributions found are added to the environment.
@@ -1057,7 +1186,7 @@
             for dist in find_distributions(item):
                 self.add(dist)
 
-    def __getitem__(self, project_name):
+    def __getitem__(self, project_name: str) -> list[Distribution]:
         """Return a newest-to-oldest list of distributions for `project_name`
 
         Uses case-insensitive `project_name` comparison, assuming all the
@@ -1068,7 +1197,7 @@
         distribution_key = project_name.lower()
         return self._distmap.get(distribution_key, [])
 
-    def add(self, dist):
+    def add(self, dist: Distribution):
         """Add `dist` if we ``can_add()`` it and it has not already been added"""
         if self.can_add(dist) and dist.has_version():
             dists = self._distmap.setdefault(dist.key, [])
@@ -1076,7 +1205,29 @@
                 dists.append(dist)
                 dists.sort(key=operator.attrgetter('hashcmp'), reverse=True)
 
-    def best_match(self, req, working_set, installer=None, replace_conflicting=False):
+    @overload
+    def best_match(
+        self,
+        req: Requirement,
+        working_set: WorkingSet,
+        installer: _InstallerTypeT[_DistributionT],
+        replace_conflicting: bool = False,
+    ) -> _DistributionT: ...
+    @overload
+    def best_match(
+        self,
+        req: Requirement,
+        working_set: WorkingSet,
+        installer: _InstallerType | None = None,
+        replace_conflicting: bool = False,
+    ) -> Distribution | None: ...
+    def best_match(
+        self,
+        req: Requirement,
+        working_set: WorkingSet,
+        installer: _InstallerType | None | _InstallerTypeT[_DistributionT] = None,
+        replace_conflicting: bool = False,
+    ) -> Distribution | None:
         """Find distribution best matching `req` and usable on `working_set`
 
         This calls the ``find(req)`` method of the `working_set` to see if a
@@ -1103,7 +1254,32 @@
         # try to download/install
         return self.obtain(req, installer)
 
-    def obtain(self, requirement, installer=None):
+    @overload
+    def obtain(
+        self,
+        requirement: Requirement,
+        installer: _InstallerTypeT[_DistributionT],
+    ) -> _DistributionT: ...
+    @overload
+    def obtain(
+        self,
+        requirement: Requirement,
+        installer: Callable[[Requirement], None] | None = None,
+    ) -> None: ...
+    @overload
+    def obtain(
+        self,
+        requirement: Requirement,
+        installer: _InstallerType | None = None,
+    ) -> Distribution | None: ...
+    def obtain(
+        self,
+        requirement: Requirement,
+        installer: Callable[[Requirement], None]
+        | _InstallerType
+        | None
+        | _InstallerTypeT[_DistributionT] = None,
+    ) -> Distribution | None:
         """Obtain a distribution matching `requirement` (e.g. via download)
 
         Obtain a distro that matches requirement (e.g. via download).  In the
@@ -1114,13 +1290,13 @@
         to the `installer` argument."""
         return installer(requirement) if installer else None
 
-    def __iter__(self):
+    def __iter__(self) -> Iterator[str]:
         """Yield the unique project names of the available distributions"""
         for key in self._distmap.keys():
             if self[key]:
                 yield key
 
-    def __iadd__(self, other):
+    def __iadd__(self, other: Distribution | Environment):
         """In-place addition of a distribution or environment"""
         if isinstance(other, Distribution):
             self.add(other)
@@ -1132,7 +1308,7 @@
             raise TypeError("Can't add %r to environment" % (other,))
         return self
 
-    def __add__(self, other):
+    def __add__(self, other: Distribution | Environment):
         """Add an environment or distribution to an environment"""
         new = self.__class__([], platform=None, python=None)
         for env in self, other:
@@ -1159,46 +1335,54 @@
         The exception instance that caused extraction to fail
     """
 
+    manager: ResourceManager
+    cache_path: str
+    original_error: BaseException | None
+
 
 class ResourceManager:
     """Manage resource extraction and packages"""
 
-    extraction_path = None
+    extraction_path: str | None = None
 
     def __init__(self):
         self.cached_files = {}
 
-    def resource_exists(self, package_or_requirement, resource_name):
+    def resource_exists(self, package_or_requirement: _PkgReqType, resource_name: str):
         """Does the named resource exist?"""
         return get_provider(package_or_requirement).has_resource(resource_name)
 
-    def resource_isdir(self, package_or_requirement, resource_name):
+    def resource_isdir(self, package_or_requirement: _PkgReqType, resource_name: str):
         """Is the named resource an existing directory?"""
         return get_provider(package_or_requirement).resource_isdir(resource_name)
 
-    def resource_filename(self, package_or_requirement, resource_name):
+    def resource_filename(
+        self, package_or_requirement: _PkgReqType, resource_name: str
+    ):
         """Return a true filesystem path for specified resource"""
         return get_provider(package_or_requirement).get_resource_filename(
             self, resource_name
         )
 
-    def resource_stream(self, package_or_requirement, resource_name):
+    def resource_stream(self, package_or_requirement: _PkgReqType, resource_name: str):
         """Return a readable file-like object for specified resource"""
         return get_provider(package_or_requirement).get_resource_stream(
             self, resource_name
         )
 
-    def resource_string(self, package_or_requirement, resource_name) -> bytes:
+    def resource_string(
+        self, package_or_requirement: _PkgReqType, resource_name: str
+    ) -> bytes:
         """Return specified resource as :obj:`bytes`"""
         return get_provider(package_or_requirement).get_resource_string(
             self, resource_name
         )
 
-    def resource_listdir(self, package_or_requirement, resource_name):
+    def resource_listdir(self, package_or_requirement: _PkgReqType, resource_name: str):
         """List the contents of the named resource directory"""
         return get_provider(package_or_requirement).resource_listdir(resource_name)
 
-    def extraction_error(self):
+    def extraction_error(self) -> NoReturn:
         """Give an error message for problems extracting file(s)"""
 
         old_exc = sys.exc_info()[1]
@@ -1228,7 +1412,7 @@
         err.original_error = old_exc
         raise err
 
-    def get_cache_path(self, archive_name, names=()):
+    def get_cache_path(self, archive_name: str, names: Iterable[StrPath] = ()):
         """Return absolute location in cache for `archive_name` and `names`
 
         The parent directory of the resulting path will be created if it does
@@ -1250,7 +1434,7 @@
 
         self._warn_unsafe_extraction_path(extract_path)
 
-        self.cached_files[target_path] = 1
+        self.cached_files[target_path] = True
         return target_path
 
     @staticmethod
@@ -1280,7 +1464,7 @@
             ).format(**locals())
             warnings.warn(msg, UserWarning)
 
-    def postprocess(self, tempname, filename):
+    def postprocess(self, tempname: StrOrBytesPath, filename: StrOrBytesPath):
         """Perform any platform-specific postprocessing of `tempname`
 
         This is where Mac header rewrites should be done; other platforms don't
@@ -1300,7 +1484,7 @@
             mode = ((os.stat(tempname).st_mode) | 0o555) & 0o7777
             os.chmod(tempname, mode)
 
-    def set_extraction_path(self, path):
+    def set_extraction_path(self, path: str):
         """Set the base path where resources will be extracted to, if needed.
 
         If you do not call this routine before any extractions take place, the
@@ -1324,7 +1508,7 @@
 
         self.extraction_path = path
 
-    def cleanup_resources(self, force=False) -> List[str]:
+    def cleanup_resources(self, force: bool = False) -> list[str]:
         """
         Delete all extracted resource files and directories, returning a list
         of the file and directory names that could not be successfully removed.
@@ -1339,18 +1523,16 @@
         return []
 
 
-def get_default_cache():
+def get_default_cache() -> str:
     """
     Return the ``PYTHON_EGG_CACHE`` environment variable
     or a platform-relevant user cache dir for an app
     named "Python-Eggs".
     """
-    return os.environ.get('PYTHON_EGG_CACHE') or platformdirs.user_cache_dir(
-        appname='Python-Eggs'
-    )
+    return os.environ.get('PYTHON_EGG_CACHE') or _user_cache_dir(appname='Python-Eggs')
 
 
-def safe_name(name):
+def safe_name(name: str):
     """Convert an arbitrary string to a standard distribution name
 
     Any runs of non-alphanumeric/. characters are replaced with a single '-'.
@@ -1358,14 +1540,14 @@
     return re.sub('[^A-Za-z0-9.]+', '-', name)
 
 
-def safe_version(version):
+def safe_version(version: str):
     """
     Convert an arbitrary string to a standard version string
     """
     try:
         # normalize the version
-        return str(packaging.version.Version(version))
-    except packaging.version.InvalidVersion:
+        return str(_packaging_version.Version(version))
+    except _packaging_version.InvalidVersion:
         version = version.replace(' ', '.')
         return re.sub('[^A-Za-z0-9.]+', '-', version)
 
@@ -1402,7 +1584,7 @@
     return re.sub(r'\.[^A-Za-z0-9]+', '.', segment).strip(".-")
 
 
-def safe_extra(extra):
+def safe_extra(extra: str):
     """Convert an arbitrary string to a standard 'extra' name
 
     Any runs of non-alphanumeric characters are replaced with a single '_',
@@ -1411,7 +1593,7 @@
     return re.sub('[^A-Za-z0-9.-]+', '_', extra).lower()
 
 
-def to_filename(name):
+def to_filename(name: str):
     """Convert a project or version name to its filename-escaped form
 
     Any '-' characters are currently replaced with '_'.
@@ -1419,7 +1601,7 @@
     return name.replace('-', '_')
 
 
-def invalid_marker(text):
+def invalid_marker(text: str):
     """
     Validate text as a PEP 508 environment marker; return an exception
     if invalid or False otherwise.
@@ -1433,7 +1615,7 @@
     return False
 
 
-def evaluate_marker(text, extra=None):
+def evaluate_marker(text: str, extra: str | None = None) -> bool:
     """
     Evaluate a PEP 508 environment marker.
     Return a boolean indicating the marker result in this environment.
@@ -1442,46 +1624,48 @@
     This implementation uses the 'pyparsing' module.
     """
     try:
-        marker = packaging.markers.Marker(text)
+        marker = _packaging_markers.Marker(text)
         return marker.evaluate()
-    except packaging.markers.InvalidMarker as e:
+    except _packaging_markers.InvalidMarker as e:
         raise SyntaxError(e) from e
 
 
 class NullProvider:
     """Try to implement resources and metadata for arbitrary PEP 302 loaders"""
 
-    egg_name = None
-    egg_info = None
-    loader = None
+    egg_name: str | None = None
+    egg_info: str | None = None
+    loader: _LoaderProtocol | None = None
 
-    def __init__(self, module):
+    def __init__(self, module: _ModuleLike):
         self.loader = getattr(module, '__loader__', None)
         self.module_path = os.path.dirname(getattr(module, '__file__', ''))
 
-    def get_resource_filename(self, manager, resource_name):
+    def get_resource_filename(self, manager: ResourceManager, resource_name: str):
         return self._fn(self.module_path, resource_name)
 
-    def get_resource_stream(self, manager, resource_name):
+    def get_resource_stream(self, manager: ResourceManager, resource_name: str):
         return io.BytesIO(self.get_resource_string(manager, resource_name))
 
-    def get_resource_string(self, manager, resource_name) -> bytes:
+    def get_resource_string(
+        self, manager: ResourceManager, resource_name: str
+    ) -> bytes:
         return self._get(self._fn(self.module_path, resource_name))
 
-    def has_resource(self, resource_name):
+    def has_resource(self, resource_name: str):
         return self._has(self._fn(self.module_path, resource_name))
 
     def _get_metadata_path(self, name):
         return self._fn(self.egg_info, name)
 
-    def has_metadata(self, name) -> bool:
+    def has_metadata(self, name: str) -> bool:
         if not self.egg_info:
             return False
 
         path = self._get_metadata_path(name)
         return self._has(path)
 
-    def get_metadata(self, name):
+    def get_metadata(self, name: str):
         if not self.egg_info:
             return ""
         path = self._get_metadata_path(name)
@@ -1494,24 +1678,24 @@
             exc.reason += ' in {} file at path: {}'.format(name, path)
             raise
 
-    def get_metadata_lines(self, name):
+    def get_metadata_lines(self, name: str) -> Iterator[str]:
         return yield_lines(self.get_metadata(name))
 
-    def resource_isdir(self, resource_name):
+    def resource_isdir(self, resource_name: str):
         return self._isdir(self._fn(self.module_path, resource_name))
 
-    def metadata_isdir(self, name) -> bool:
+    def metadata_isdir(self, name: str) -> bool:
         return bool(self.egg_info and self._isdir(self._fn(self.egg_info, name)))
 
-    def resource_listdir(self, resource_name):
+    def resource_listdir(self, resource_name: str):
         return self._listdir(self._fn(self.module_path, resource_name))
 
-    def metadata_listdir(self, name):
+    def metadata_listdir(self, name: str) -> list[str]:
         if self.egg_info:
             return self._listdir(self._fn(self.egg_info, name))
         return []
 
-    def run_script(self, script_name, namespace):
+    def run_script(self, script_name: str, namespace: dict[str, Any]):
         script = 'scripts/' + script_name
         if not self.has_metadata(script):
             raise ResolutionError(
@@ -1519,13 +1703,13 @@
                     **locals()
                 ),
             )
+
         script_text = self.get_metadata(script).replace('\r\n', '\n')
         script_text = script_text.replace('\r', '\n')
         script_filename = self._fn(self.egg_info, script)
         namespace['__file__'] = script_filename
         if os.path.exists(script_filename):
-            with open(script_filename) as fid:
-                source = fid.read()
+            source = _read_utf8_with_fallback(script_filename)
             code = compile(source, script_filename, 'exec')
             exec(code, namespace, namespace)
         else:
@@ -1550,12 +1734,16 @@
             "Can't perform this operation for unregistered loader type"
         )
 
-    def _listdir(self, path):
+    def _listdir(self, path) -> list[str]:
         raise NotImplementedError(
             "Can't perform this operation for unregistered loader type"
         )
 
-    def _fn(self, base, resource_name):
+    def _fn(self, base: str | None, resource_name: str):
+        if base is None:
+            raise TypeError(
+                "`base` parameter in `_fn` is `None`. Either override this method or check the parameter first."
+            )
         self._validate_resource_path(resource_name)
         if resource_name:
             return os.path.join(base, *resource_name.split('/'))
@@ -1618,6 +1806,7 @@
             os.path.pardir in path.split(posixpath.sep)
             or posixpath.isabs(path)
             or ntpath.isabs(path)
+            or path.startswith("\\")
         )
         if not invalid:
             return
@@ -1625,7 +1814,7 @@
         msg = "Use of .. or absolute path in a resource path is not allowed."
 
         # Aggressively disallow Windows absolute paths
-        if ntpath.isabs(path) and not posixpath.isabs(path):
+        if (path.startswith("\\") or ntpath.isabs(path)) and not posixpath.isabs(path):
             raise ValueError(msg)
 
         # for compatibility, warn; in future
@@ -1636,8 +1825,9 @@
         )
 
     def _get(self, path) -> bytes:
-        if hasattr(self.loader, 'get_data'):
-            return self.loader.get_data(path)
+        if hasattr(self.loader, 'get_data') and self.loader:
+            # Already checked get_data exists
+            return self.loader.get_data(path)  # type: ignore[attr-defined]
         raise NotImplementedError(
             "Can't perform this operation for loaders without 'get_data()'"
         )
@@ -1660,7 +1850,7 @@
 class EggProvider(NullProvider):
     """Provider based on a virtual filesystem"""
 
-    def __init__(self, module):
+    def __init__(self, module: _ModuleLike):
         super().__init__(module)
         self._setup_prefix()
 
@@ -1671,7 +1861,7 @@
         egg = next(eggs, None)
         egg and self._set_egg(egg)
 
-    def _set_egg(self, path):
+    def _set_egg(self, path: str):
         self.egg_name = os.path.basename(path)
         self.egg_info = os.path.join(path, 'EGG-INFO')
         self.egg_root = path
@@ -1689,7 +1879,7 @@
     def _listdir(self, path):
         return os.listdir(path)
 
-    def get_resource_stream(self, manager, resource_name):
+    def get_resource_stream(self, manager: object, resource_name: str):
         return open(self._fn(self.module_path, resource_name), 'rb')
 
     def _get(self, path) -> bytes:
@@ -1713,7 +1903,8 @@
 class EmptyProvider(NullProvider):
     """Provider that returns nothing for all requests"""
 
-    module_path = None
+    # A special case, we don't want all Providers inheriting from NullProvider to have a potentially None module_path
+    module_path: str | None = None  # type: ignore[assignment]
 
     _isdir = _has = lambda self, path: False
 
@@ -1730,13 +1921,14 @@
 empty_provider = EmptyProvider()
 
 
-class ZipManifests(dict):
+class ZipManifests(Dict[str, "MemoizedZipManifests.manifest_mod"]):
     """
     zip manifest builder
     """
 
+    # `path` could be `StrPath | IO[bytes]` but that violates the LSP for `MemoizedZipManifests.load`
     @classmethod
-    def build(cls, path):
+    def build(cls, path: str):
         """
         Build a dictionary similar to the zipimport directory
         caches, except instead of tuples, store ZipInfo objects.
@@ -1762,9 +1954,11 @@
     Memoized zipfile manifests.
     """
 
-    manifest_mod = collections.namedtuple('manifest_mod', 'manifest mtime')
+    class manifest_mod(NamedTuple):
+        manifest: dict[str, zipfile.ZipInfo]
+        mtime: float
 
-    def load(self, path):
+    def load(self, path: str) -> dict[str, zipfile.ZipInfo]:  # type: ignore[override] # ZipManifests.load is a classmethod
         """
         Load a manifest at path or return a suitable manifest already loaded.
         """
@@ -1781,10 +1975,12 @@
 class ZipProvider(EggProvider):
     """Resource support for zips and eggs"""
 
-    eagers = None
+    eagers: list[str] | None = None
     _zip_manifests = MemoizedZipManifests()
+    # ZipProvider's loader should always be a zipimporter or equivalent
+    loader: zipimport.zipimporter
 
-    def __init__(self, module):
+    def __init__(self, module: _ZipLoaderModule):
         super().__init__(module)
         self.zip_pre = self.loader.archive + os.sep
 
@@ -1810,7 +2006,7 @@
     def zipinfo(self):
         return self._zip_manifests.load(self.loader.archive)
 
-    def get_resource_filename(self, manager, resource_name):
+    def get_resource_filename(self, manager: ResourceManager, resource_name: str):
         if not self.egg_name:
             raise NotImplementedError(
                 "resource_filename() only supported for .egg, not .zip"
@@ -1833,7 +2029,7 @@
         return timestamp, size
 
     # FIXME: 'ZipProvider._extract_resource' is too complex (12)
-    def _extract_resource(self, manager, zip_path):  # noqa: C901
+    def _extract_resource(self, manager: ResourceManager, zip_path) -> str:  # noqa: C901
         if zip_path in self._index():
             for name in self._index()[zip_path]:
                 last = self._extract_resource(manager, os.path.join(zip_path, name))
@@ -1844,9 +2040,13 @@
 
         if not WRITE_SUPPORT:
             raise OSError(
-                '"os.rename" and "os.unlink" are not supported ' 'on this platform'
+                '"os.rename" and "os.unlink" are not supported on this platform'
             )
         try:
+            if not self.egg_name:
+                raise OSError(
+                    '"egg_name" is empty. This likely means no egg could be found from the "module_path".'
+                )
             real_path = manager.get_cache_path(self.egg_name, self._parts(zip_path))
 
             if self._is_current(real_path, zip_path):
@@ -1935,10 +2135,10 @@
     def _listdir(self, fspath):
         return list(self._index().get(self._zipinfo_name(fspath), ()))
 
-    def _eager_to_zip(self, resource_name):
+    def _eager_to_zip(self, resource_name: str):
         return self._zipinfo_name(self._fn(self.egg_root, resource_name))
 
-    def _resource_to_zip(self, resource_name):
+    def _resource_to_zip(self, resource_name: str):
         return self._zipinfo_name(self._fn(self.module_path, resource_name))
 
 
@@ -1957,16 +2157,16 @@
     the provided location.
     """
 
-    def __init__(self, path):
+    def __init__(self, path: StrPath):
         self.path = path
 
     def _get_metadata_path(self, name):
         return self.path
 
-    def has_metadata(self, name) -> bool:
+    def has_metadata(self, name: str) -> bool:
         return name == 'PKG-INFO' and os.path.isfile(self.path)
 
-    def get_metadata(self, name):
+    def get_metadata(self, name: str):
         if name != 'PKG-INFO':
             raise KeyError("No metadata except PKG-INFO is available")
 
@@ -1982,7 +2182,7 @@
             msg = tmpl.format(**locals())
             warnings.warn(msg)
 
-    def get_metadata_lines(self, name):
+    def get_metadata_lines(self, name: str) -> Iterator[str]:
         return yield_lines(self.get_metadata(name))
 
 
@@ -2006,7 +2206,7 @@
         dist = Distribution.from_filename(egg_path, metadata=metadata)
     """
 
-    def __init__(self, path, egg_info):
+    def __init__(self, path: str, egg_info: str):
         self.module_path = path
         self.egg_info = egg_info
 
@@ -2014,7 +2214,7 @@
 class EggMetadata(ZipProvider):
     """Metadata provider for .egg files"""
 
-    def __init__(self, importer):
+    def __init__(self, importer: zipimport.zipimporter):
         """Create a metadata provider from a zipimporter"""
 
         self.zip_pre = importer.archive + os.sep
@@ -2026,10 +2226,12 @@
         self._setup_prefix()
 
 
-_declare_state('dict', _distribution_finders={})
+_distribution_finders: dict[type, _DistFinderType[Any]] = _declare_state(
+    'dict', '_distribution_finders', {}
+)
 
 
-def register_finder(importer_type, distribution_finder):
+def register_finder(importer_type: type[_T], distribution_finder: _DistFinderType[_T]):
     """Register `distribution_finder` to find distributions in sys.path items
 
     `importer_type` is the type or class of a PEP 302 "Importer" (sys.path item
@@ -2039,14 +2241,16 @@
     _distribution_finders[importer_type] = distribution_finder
 
 
-def find_distributions(path_item, only=False):
+def find_distributions(path_item: str, only: bool = False):
     """Yield distributions accessible via `path_item`"""
     importer = get_importer(path_item)
     finder = _find_adapter(_distribution_finders, importer)
     return finder(importer, path_item, only)
 
 
-def find_eggs_in_zip(importer, path_item, only=False):
+def find_eggs_in_zip(
+    importer: zipimport.zipimporter, path_item: str, only: bool = False
+) -> Iterator[Distribution]:
     """
     Find eggs in zip files; possibly multiple nested eggs.
     """
@@ -2075,14 +2279,16 @@
 register_finder(zipimport.zipimporter, find_eggs_in_zip)
 
 
-def find_nothing(importer, path_item, only=False):
+def find_nothing(
+    importer: object | None, path_item: str | None, only: bool | None = False
+):
     return ()
 
 
 register_finder(object, find_nothing)
 
 
-def find_on_path(importer, path_item, only=False):
+def find_on_path(importer: object | None, path_item, only=False):
     """Yield distributions accessible on a sys.path directory"""
     path_item = _normalize_cached(path_item)
 
@@ -2137,7 +2343,7 @@
         return iter(())
 
 
-def safe_listdir(path):
+def safe_listdir(path: StrOrBytesPath):
     """
     Attempt to list contents of path, but suppress some exceptions.
     """
@@ -2153,13 +2359,13 @@
     return ()
 
 
-def distributions_from_metadata(path):
+def distributions_from_metadata(path: str):
     root = os.path.dirname(path)
     if os.path.isdir(path):
         if len(os.listdir(path)) == 0:
             # empty metadata dir; skip
             return
-        metadata = PathMetadata(root, path)
+        metadata: _MetadataType = PathMetadata(root, path)
     else:
         metadata = FileMetadata(path)
     entry = os.path.basename(path)
@@ -2175,11 +2381,10 @@
     """
     Yield non-empty lines from file at path
     """
-    with open(path) as f:
-        for line in f:
-            line = line.strip()
-            if line:
-                yield line
+    for line in _read_utf8_with_fallback(path).splitlines():
+        line = line.strip()
+        if line:
+            yield line
 
 
 def resolve_egg_link(path):
@@ -2200,11 +2405,17 @@
 
 register_finder(importlib.machinery.FileFinder, find_on_path)
 
-_declare_state('dict', _namespace_handlers={})
-_declare_state('dict', _namespace_packages={})
+_namespace_handlers: dict[type, _NSHandlerType[Any]] = _declare_state(
+    'dict', '_namespace_handlers', {}
+)
+_namespace_packages: dict[str | None, list[str]] = _declare_state(
+    'dict', '_namespace_packages', {}
+)
 
 
-def register_namespace_handler(importer_type, namespace_handler):
+def register_namespace_handler(
+    importer_type: type[_T], namespace_handler: _NSHandlerType[_T]
+):
     """Register `namespace_handler` to declare namespace packages
 
     `importer_type` is the type or class of a PEP 302 "Importer" (sys.path item
@@ -2259,7 +2470,7 @@
     return subpath
 
 
-def _rebuild_mod_path(orig_path, package_name, module):
+def _rebuild_mod_path(orig_path, package_name, module: types.ModuleType):
     """
     Rebuild module.__path__ ensuring that all entries are ordered
     corresponding to their sys.path order
@@ -2293,7 +2504,7 @@
         module.__path__ = new_path
 
 
-def declare_namespace(packageName):
+def declare_namespace(packageName: str):
     """Declare that package 'packageName' is a namespace package"""
 
     msg = (
@@ -2310,7 +2521,7 @@
         if packageName in _namespace_packages:
             return
 
-        path = sys.path
+        path: MutableSequence[str] = sys.path
         parent, _, _ = packageName.rpartition('.')
 
         if parent:
@@ -2336,7 +2547,7 @@
         _imp.release_lock()
 
 
-def fixup_namespace_packages(path_item, parent=None):
+def fixup_namespace_packages(path_item: str, parent: str | None = None):
     """Ensure that previously-declared namespace packages include path_item"""
     _imp.acquire_lock()
     try:
@@ -2348,7 +2559,12 @@
         _imp.release_lock()
 
 
-def file_ns_handler(importer, path_item, packageName, module):
+def file_ns_handler(
+    importer: object,
+    path_item: StrPath,
+    packageName: str,
+    module: types.ModuleType,
+):
     """Compute an ns-package subpath for a filesystem or zipfile importer"""
 
     subpath = os.path.join(path_item, packageName.split('.')[-1])
@@ -2368,19 +2584,28 @@
 register_namespace_handler(importlib.machinery.FileFinder, file_ns_handler)
 
 
-def null_ns_handler(importer, path_item, packageName, module):
+def null_ns_handler(
+    importer: object,
+    path_item: str | None,
+    packageName: str | None,
+    module: _ModuleLike | None,
+):
     return None
 
 
 register_namespace_handler(object, null_ns_handler)
 
 
-def normalize_path(filename):
+@overload
+def normalize_path(filename: StrPath) -> str: ...
+@overload
+def normalize_path(filename: BytesPath) -> bytes: ...
+def normalize_path(filename: StrOrBytesPath):
     """Normalize a file/dir name for comparison purposes"""
     return os.path.normcase(os.path.realpath(os.path.normpath(_cygwin_patch(filename))))
 
 
-def _cygwin_patch(filename):  # pragma: nocover
+def _cygwin_patch(filename: StrOrBytesPath):  # pragma: nocover
     """
     Contrary to POSIX 2008, on Cygwin, getcwd (3) contains
     symlink components. Using
@@ -2391,9 +2616,19 @@
     return os.path.abspath(filename) if sys.platform == 'cygwin' else filename
 
 
-@functools.lru_cache(maxsize=None)
-def _normalize_cached(filename):
-    return normalize_path(filename)
+if TYPE_CHECKING:
+    # https://github.com/python/mypy/issues/16261
+    # https://github.com/python/typeshed/issues/6347
+    @overload
+    def _normalize_cached(filename: StrPath) -> str: ...
+    @overload
+    def _normalize_cached(filename: BytesPath) -> bytes: ...
+    def _normalize_cached(filename: StrOrBytesPath) -> str | bytes: ...
+else:
+
+    @functools.lru_cache(maxsize=None)
+    def _normalize_cached(filename):
+        return normalize_path(filename)
 
 
 def _is_egg_path(path):
@@ -2446,7 +2681,14 @@
 class EntryPoint:
     """Object representing an advertised importable object"""
 
-    def __init__(self, name, module_name, attrs=(), extras=(), dist=None):
+    def __init__(
+        self,
+        name: str,
+        module_name: str,
+        attrs: Iterable[str] = (),
+        extras: Iterable[str] = (),
+        dist: Distribution | None = None,
+    ):
         if not MODULE(module_name):
             raise ValueError("Invalid module name", module_name)
         self.name = name
@@ -2466,7 +2708,26 @@
     def __repr__(self):
         return "EntryPoint.parse(%r)" % str(self)
 
-    def load(self, require=True, *args, **kwargs):
+    @overload
+    def load(
+        self,
+        require: Literal[True] = True,
+        env: Environment | None = None,
+        installer: _InstallerType | None = None,
+    ) -> _ResolvedEntryPoint: ...
+    @overload
+    def load(
+        self,
+        require: Literal[False],
+        *args: Any,
+        **kwargs: Any,
+    ) -> _ResolvedEntryPoint: ...
+    def load(
+        self,
+        require: bool = True,
+        *args: Environment | _InstallerType | None,
+        **kwargs: Environment | _InstallerType | None,
+    ) -> _ResolvedEntryPoint:
         """
         Require packages for this EntryPoint, then resolve it.
         """
@@ -2478,10 +2739,12 @@
                 stacklevel=2,
             )
         if require:
-            self.require(*args, **kwargs)
+            # We could pass `env` and `installer` directly,
+            # but keeping `*args` and `**kwargs` for backwards compatibility
+            self.require(*args, **kwargs)  # type: ignore
         return self.resolve()
 
-    def resolve(self):
+    def resolve(self) -> _ResolvedEntryPoint:
         """
         Resolve the entry point from its module and attrs.
         """
@@ -2491,9 +2754,14 @@
         except AttributeError as exc:
             raise ImportError(str(exc)) from exc
 
-    def require(self, env=None, installer=None):
-        if self.extras and not self.dist:
-            raise UnknownExtra("Can't require() without a distribution", self)
+    def require(
+        self,
+        env: Environment | None = None,
+        installer: _InstallerType | None = None,
+    ):
+        if not self.dist:
+            error_cls = UnknownExtra if self.extras else AttributeError
+            raise error_cls("Can't require() without a distribution", self)
 
         # Get the requirements for this entry point with all its extras and
         # then resolve them. We have to pass `extras` along when resolving so
@@ -2514,7 +2782,7 @@
     )
 
     @classmethod
-    def parse(cls, src, dist=None):
+    def parse(cls, src: str, dist: Distribution | None = None):
         """Parse a single entry point from string `src`
 
         Entry point syntax follows the form::
@@ -2539,15 +2807,20 @@
             return ()
         req = Requirement.parse('x' + extras_spec)
         if req.specs:
-            raise ValueError()
+            raise ValueError
         return req.extras
 
     @classmethod
-    def parse_group(cls, group, lines, dist=None):
+    def parse_group(
+        cls,
+        group: str,
+        lines: _NestedStr,
+        dist: Distribution | None = None,
+    ):
         """Parse an entry point group"""
         if not MODULE(group):
             raise ValueError("Invalid group name", group)
-        this = {}
+        this: dict[str, Self] = {}
         for line in yield_lines(lines):
             ep = cls.parse(line, dist)
             if ep.name in this:
@@ -2556,14 +2829,19 @@
         return this
 
     @classmethod
-    def parse_map(cls, data, dist=None):
+    def parse_map(
+        cls,
+        data: str | Iterable[str] | dict[str, str | Iterable[str]],
+        dist: Distribution | None = None,
+    ):
         """Parse a map of entry point groups"""
+        _data: Iterable[tuple[str | None, str | Iterable[str]]]
         if isinstance(data, dict):
-            data = data.items()
+            _data = data.items()
         else:
-            data = split_sections(data)
-        maps = {}
-        for group, lines in data:
+            _data = split_sections(data)
+        maps: dict[str, dict[str, Self]] = {}
+        for group, lines in _data:
             if group is None:
                 if not lines:
                     continue
@@ -2597,13 +2875,13 @@
 
     def __init__(
         self,
-        location=None,
-        metadata=None,
-        project_name=None,
-        version=None,
-        py_version=PY_MAJOR,
-        platform=None,
-        precedence=EGG_DIST,
+        location: str | None = None,
+        metadata: _MetadataType = None,
+        project_name: str | None = None,
+        version: str | None = None,
+        py_version: str | None = PY_MAJOR,
+        platform: str | None = None,
+        precedence: int = EGG_DIST,
     ):
         self.project_name = safe_name(project_name or 'Unknown')
         if version is not None:
@@ -2615,7 +2893,13 @@
         self._provider = metadata or empty_provider
 
     @classmethod
-    def from_location(cls, location, basename, metadata=None, **kw):
+    def from_location(
+        cls,
+        location: str,
+        basename: StrPath,
+        metadata: _MetadataType = None,
+        **kw: int,  # We could set `precedence` explicitly, but keeping this as `**kw` for full backwards and subclassing compatibility
+    ) -> Distribution:
         project_name, version, py_version, platform = [None] * 4
         basename, ext = os.path.splitext(basename)
         if ext.lower() in _distributionImpl:
@@ -2653,25 +2937,25 @@
     def __hash__(self):
         return hash(self.hashcmp)
 
-    def __lt__(self, other):
+    def __lt__(self, other: Distribution):
         return self.hashcmp < other.hashcmp
 
-    def __le__(self, other):
+    def __le__(self, other: Distribution):
         return self.hashcmp <= other.hashcmp
 
-    def __gt__(self, other):
+    def __gt__(self, other: Distribution):
         return self.hashcmp > other.hashcmp
 
-    def __ge__(self, other):
+    def __ge__(self, other: Distribution):
         return self.hashcmp >= other.hashcmp
 
-    def __eq__(self, other):
+    def __eq__(self, other: object):
         if not isinstance(other, self.__class__):
             # It's not a Distribution, so they are not equal
             return False
         return self.hashcmp == other.hashcmp
 
-    def __ne__(self, other):
+    def __ne__(self, other: object):
         return not self == other
 
     # These properties have to be lazy so that we don't have to load any
@@ -2691,12 +2975,12 @@
         if not hasattr(self, "_parsed_version"):
             try:
                 self._parsed_version = parse_version(self.version)
-            except packaging.version.InvalidVersion as ex:
+            except _packaging_version.InvalidVersion as ex:
                 info = f"(package: {self.project_name})"
                 if hasattr(ex, "add_note"):
                     ex.add_note(info)  # PEP 678
                     raise
-                raise packaging.version.InvalidVersion(f"{str(ex)} {info}") from None
+                raise _packaging_version.InvalidVersion(f"{str(ex)} {info}") from None
 
         return self._parsed_version
 
@@ -2704,7 +2988,7 @@
     def _forgiving_parsed_version(self):
         try:
             return self.parsed_version
-        except packaging.version.InvalidVersion as ex:
+        except _packaging_version.InvalidVersion as ex:
             self._parsed_version = parse_version(_forgiving_version(self.version))
 
             notes = "\n".join(getattr(ex, "__notes__", []))  # PEP 678
@@ -2754,14 +3038,14 @@
         return self.__dep_map
 
     @staticmethod
-    def _filter_extras(dm):
+    def _filter_extras(dm: dict[str | None, list[Requirement]]):
         """
         Given a mapping of extras to dependencies, strip off
         environment markers and filter out any dependencies
         not matching the markers.
         """
         for extra in list(filter(None, dm)):
-            new_extra = extra
+            new_extra: str | None = extra
             reqs = dm.pop(extra)
             new_extra, _, marker = extra.partition(':')
             fails_marker = marker and (
@@ -2781,10 +3065,10 @@
                 dm.setdefault(extra, []).extend(parse_requirements(reqs))
         return dm
 
-    def requires(self, extras=()):
+    def requires(self, extras: Iterable[str] = ()):
         """List of Requirements needed for this distro if `extras` are used"""
         dm = self._dep_map
-        deps = []
+        deps: list[Requirement] = []
         deps.extend(dm.get(None, ()))
         for ext in extras:
             try:
@@ -2820,12 +3104,12 @@
         lines = self._get_metadata(self.PKG_INFO)
         return _version_from_file(lines)
 
-    def activate(self, path=None, replace=False):
+    def activate(self, path: list[str] | None = None, replace: bool = False):
         """Ensure distribution is importable on `path` (default=sys.path)"""
         if path is None:
             path = sys.path
         self.insert_on(path, replace=replace)
-        if path is sys.path:
+        if path is sys.path and self.location is not None:
             fixup_namespace_packages(self.location)
             for pkg in self._get_metadata('namespace_packages.txt'):
                 if pkg in sys.modules:
@@ -2870,45 +3154,57 @@
         )
 
     @classmethod
-    def from_filename(cls, filename, metadata=None, **kw):
+    def from_filename(
+        cls,
+        filename: StrPath,
+        metadata: _MetadataType = None,
+        **kw: int,  # We could set `precedence` explicitly, but keeping this as `**kw` for full backwards and subclassing compatibility
+    ):
         return cls.from_location(
             _normalize_cached(filename), os.path.basename(filename), metadata, **kw
         )
 
     def as_requirement(self):
         """Return a ``Requirement`` that matches this distribution exactly"""
-        if isinstance(self.parsed_version, packaging.version.Version):
+        if isinstance(self.parsed_version, _packaging_version.Version):
             spec = "%s==%s" % (self.project_name, self.parsed_version)
         else:
             spec = "%s===%s" % (self.project_name, self.parsed_version)
 
         return Requirement.parse(spec)
 
-    def load_entry_point(self, group, name):
+    def load_entry_point(self, group: str, name: str) -> _ResolvedEntryPoint:
         """Return the `name` entry point of `group` or raise ImportError"""
         ep = self.get_entry_info(group, name)
         if ep is None:
             raise ImportError("Entry point %r not found" % ((group, name),))
         return ep.load()
 
-    def get_entry_map(self, group=None):
+    @overload
+    def get_entry_map(self, group: None = None) -> dict[str, dict[str, EntryPoint]]: ...
+    @overload
+    def get_entry_map(self, group: str) -> dict[str, EntryPoint]: ...
+    def get_entry_map(self, group: str | None = None):
         """Return the entry point map for `group`, or the full entry map"""
-        try:
-            ep_map = self._ep_map
-        except AttributeError:
-            ep_map = self._ep_map = EntryPoint.parse_map(
+        if not hasattr(self, "_ep_map"):
+            self._ep_map = EntryPoint.parse_map(
                 self._get_metadata('entry_points.txt'), self
             )
         if group is not None:
-            return ep_map.get(group, {})
-        return ep_map
+            return self._ep_map.get(group, {})
+        return self._ep_map
 
-    def get_entry_info(self, group, name):
+    def get_entry_info(self, group: str, name: str):
         """Return the EntryPoint object for `group`+`name`, or ``None``"""
         return self.get_entry_map(group).get(name)
 
     # FIXME: 'Distribution.insert_on' is too complex (13)
-    def insert_on(self, path, loc=None, replace=False):  # noqa: C901
+    def insert_on(  # noqa: C901
+        self,
+        path: list[str],
+        loc=None,
+        replace: bool = False,
+    ):
         """Ensure self.location is on path
 
         If replace=False (default):
@@ -3013,13 +3309,14 @@
             return False
         return True
 
-    def clone(self, **kw):
+    def clone(self, **kw: str | int | IResourceProvider | None):
         """Copy this distribution, substituting in any changed keyword args"""
         names = 'project_name version py_version platform location precedence'
         for attr in names.split():
             kw.setdefault(attr, getattr(self, attr, None))
         kw.setdefault('metadata', self._provider)
-        return self.__class__(**kw)
+        # Unsafely unpacking. But keeping **kw for backwards and subclassing compatibility
+        return self.__class__(**kw)  # type:ignore[arg-type]
 
     @property
     def extras(self):
@@ -3072,11 +3369,11 @@
             self.__dep_map = self._compute_dependencies()
             return self.__dep_map
 
-    def _compute_dependencies(self):
+    def _compute_dependencies(self) -> dict[str | None, list[Requirement]]:
         """Recompute this distribution's dependencies."""
-        dm = self.__dep_map = {None: []}
+        self.__dep_map: dict[str | None, list[Requirement]] = {None: []}
 
-        reqs = []
+        reqs: list[Requirement] = []
         # Including any condition expressions
         for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:
             reqs.extend(parse_requirements(req))
@@ -3087,13 +3384,15 @@
                     yield req
 
         common = types.MappingProxyType(dict.fromkeys(reqs_for_extra(None)))
-        dm[None].extend(common)
+        self.__dep_map[None].extend(common)
 
         for extra in self._parsed_pkg_info.get_all('Provides-Extra') or []:
             s_extra = safe_extra(extra.strip())
-            dm[s_extra] = [r for r in reqs_for_extra(extra) if r not in common]
+            self.__dep_map[s_extra] = [
+                r for r in reqs_for_extra(extra) if r not in common
+            ]
 
-        return dm
+        return self.__dep_map
 
 
 _distributionImpl = {
@@ -3116,7 +3415,7 @@
     warnings.warn(stacklevel=level + 1, *args, **kw)
 
 
-def parse_requirements(strs):
+def parse_requirements(strs: _NestedStr):
     """
     Yield ``Requirement`` objects for each specification in `strs`.
 
@@ -3125,19 +3424,20 @@
     return map(Requirement, join_continuation(map(drop_comment, yield_lines(strs))))
 
 
-class RequirementParseError(packaging.requirements.InvalidRequirement):
+class RequirementParseError(_packaging_requirements.InvalidRequirement):
     "Compatibility wrapper for InvalidRequirement"
 
 
-class Requirement(packaging.requirements.Requirement):
-    def __init__(self, requirement_string):
+class Requirement(_packaging_requirements.Requirement):
+    def __init__(self, requirement_string: str):
         """DO NOT CALL THIS UNDOCUMENTED METHOD; use Requirement.parse()!"""
         super().__init__(requirement_string)
         self.unsafe_name = self.name
         project_name = safe_name(self.name)
         self.project_name, self.key = project_name, project_name.lower()
         self.specs = [(spec.operator, spec.version) for spec in self.specifier]
-        self.extras = tuple(map(safe_extra, self.extras))
+        # packaging.requirements.Requirement uses a set for its extras. We use a variable-length tuple
+        self.extras: tuple[str] = tuple(map(safe_extra, self.extras))
         self.hashCmp = (
             self.key,
             self.url,
@@ -3147,13 +3447,13 @@
         )
         self.__hash = hash(self.hashCmp)
 
-    def __eq__(self, other):
+    def __eq__(self, other: object):
         return isinstance(other, Requirement) and self.hashCmp == other.hashCmp
 
     def __ne__(self, other):
         return not self == other
 
-    def __contains__(self, item):
+    def __contains__(self, item: Distribution | str | tuple[str, ...]) -> bool:
         if isinstance(item, Distribution):
             if item.key != self.key:
                 return False
@@ -3172,7 +3472,7 @@
         return "Requirement.parse(%r)" % str(self)
 
     @staticmethod
-    def parse(s):
+    def parse(s: str | Iterable[str]):
         (req,) = parse_requirements(s)
         return req
 
@@ -3187,7 +3487,7 @@
     return classes
 
 
-def _find_adapter(registry, ob):
+def _find_adapter(registry: Mapping[type, _AdapterT], ob: object) -> _AdapterT:
     """Return an adapter factory for `ob` from `registry`"""
     types = _always_object(inspect.getmro(getattr(ob, '__class__', type(ob))))
     for t in types:
@@ -3198,7 +3498,7 @@
     raise TypeError(f"Could not find adapter for {registry} and {ob}")
 
 
-def ensure_directory(path):
+def ensure_directory(path: StrOrBytesPath):
     """Ensure that the parent directory of `path` exists"""
     dirname = os.path.dirname(path)
     os.makedirs(dirname, exist_ok=True)
@@ -3217,7 +3517,7 @@
             pass
 
 
-def split_sections(s):
+def split_sections(s: _NestedStr) -> Iterator[tuple[str | None, list[str]]]:
     """Split a string or iterable thereof into (section, content) pairs
 
     Each ``section`` is a stripped version of the section header ("[section]")
@@ -3261,6 +3561,47 @@
 warnings.filterwarnings("ignore", category=PEP440Warning, append=True)
 
 
+class PkgResourcesDeprecationWarning(Warning):
+    """
+    Base class for warning about deprecations in ``pkg_resources``
+
+    This class is not derived from ``DeprecationWarning``, and as such is
+    visible by default.
+    """
+
+
+# Ported from ``setuptools`` to avoid introducing an import inter-dependency:
+_LOCALE_ENCODING = "locale" if sys.version_info >= (3, 10) else None
+
+
+def _read_utf8_with_fallback(file: str, fallback_encoding=_LOCALE_ENCODING) -> str:
+    """See setuptools.unicode_utils._read_utf8_with_fallback"""
+    try:
+        with open(file, "r", encoding="utf-8") as f:
+            return f.read()
+    except UnicodeDecodeError:  # pragma: no cover
+        msg = f"""\
+        ********************************************************************************
+        `encoding="utf-8"` fails with {file!r}, trying `encoding={fallback_encoding!r}`.
+
+        This fallback behaviour is considered **deprecated** and future versions of
+        `setuptools/pkg_resources` may not implement it.
+
+        Please encode {file!r} with "utf-8" to ensure future builds will succeed.
+
+        If this file was produced by `setuptools` itself, cleaning up the cached files
+        and re-building/re-installing the package with a newer version of `setuptools`
+        (e.g. by updating `build-system.requires` in its `pyproject.toml`)
+        might solve the problem.
+        ********************************************************************************
+        """
+        # TODO: Add a deadline?
+        #       See comment in setuptools.unicode_utils._Utf8EncodingNeeded
+        warnings.warn(msg, PkgResourcesDeprecationWarning, stacklevel=2)
+        with open(file, "r", encoding=fallback_encoding) as f:
+            return f.read()
+
+
 # from jaraco.functools 1.3
 def _call_aside(f, *args, **kwargs):
     f(*args, **kwargs)
@@ -3279,15 +3620,6 @@
     )
 
 
-class PkgResourcesDeprecationWarning(Warning):
-    """
-    Base class for warning about deprecations in ``pkg_resources``
-
-    This class is not derived from ``DeprecationWarning``, and as such is
-    visible by default.
-    """
-
-
 @_call_aside
 def _initialize_master_working_set():
     """
@@ -3301,8 +3633,7 @@
     Invocation by other packages is unsupported and done
     at their own risk.
     """
-    working_set = WorkingSet._build_master()
-    _declare_state('object', working_set=working_set)
+    working_set = _declare_state('object', 'working_set', WorkingSet._build_master())
 
     require = working_set.require
     iter_entry_points = working_set.iter_entry_points
@@ -3323,3 +3654,23 @@
     # match order
     list(map(working_set.add_entry, sys.path))
     globals().update(locals())
+
+
+if TYPE_CHECKING:
+    # All of these are set by the @_call_aside methods above
+    __resource_manager = ResourceManager()  # Won't exist at runtime
+    resource_exists = __resource_manager.resource_exists
+    resource_isdir = __resource_manager.resource_isdir
+    resource_filename = __resource_manager.resource_filename
+    resource_stream = __resource_manager.resource_stream
+    resource_string = __resource_manager.resource_string
+    resource_listdir = __resource_manager.resource_listdir
+    set_extraction_path = __resource_manager.set_extraction_path
+    cleanup_resources = __resource_manager.cleanup_resources
+
+    working_set = WorkingSet()
+    require = working_set.require
+    iter_entry_points = working_set.iter_entry_points
+    add_activation_listener = working_set.subscribe
+    run_script = working_set.run_script
+    run_main = run_script
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/platformdirs/android.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/platformdirs/android.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/platformdirs/android.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/platformdirs/android.py	2024-08-15 06:46:07.171821873 -0400
@@ -6,7 +6,7 @@
 import re
 import sys
 from functools import lru_cache
-from typing import cast
+from typing import TYPE_CHECKING, cast
 
 from .api import PlatformDirsABC
 
@@ -117,20 +117,47 @@
 
 
 @lru_cache(maxsize=1)
-def _android_folder() -> str | None:
+def _android_folder() -> str | None:  # noqa: C901, PLR0912
     """:return: base folder for the Android OS or None if it cannot be found"""
-    try:
-        # First try to get a path to android app via pyjnius
-        from jnius import autoclass  # noqa: PLC0415
-
-        context = autoclass("android.content.Context")
-        result: str | None = context.getFilesDir().getParentFile().getAbsolutePath()
-    except Exception:  # noqa: BLE001
-        # if fails find an android folder looking a path on the sys.path
+    result: str | None = None
+    # type checker isn't happy with our "import android", just don't do this when type checking see
+    # https://stackoverflow.com/a/61394121
+    if not TYPE_CHECKING:
+        try:
+            # First try to get a path to android app using python4android (if available)...
+            from android import mActivity  # noqa: PLC0415
+
+            context = cast("android.content.Context", mActivity.getApplicationContext())  # noqa: F821
+            result = context.getFilesDir().getParentFile().getAbsolutePath()
+        except Exception:  # noqa: BLE001
+            result = None
+    if result is None:
+        try:
+            # ...and fall back to using plain pyjnius, if python4android isn't available or doesn't deliver any useful
+            # result...
+            from jnius import autoclass  # noqa: PLC0415
+
+            context = autoclass("android.content.Context")
+            result = context.getFilesDir().getParentFile().getAbsolutePath()
+        except Exception:  # noqa: BLE001
+            result = None
+    if result is None:
+        # and if that fails, too, find an android folder looking at path on the sys.path
+        # warning: only works for apps installed under /data, not adopted storage etc.
         pattern = re.compile(r"/data/(data|user/\d+)/(.+)/files")
         for path in sys.path:
             if pattern.match(path):
                 result = path.split("/files")[0]
+                break
+        else:
+            result = None
+    if result is None:
+        # one last try: find an android folder looking at path on the sys.path taking adopted storage paths into
+        # account
+        pattern = re.compile(r"/mnt/expand/[a-fA-F0-9-]{36}/(data|user/\d+)/(.+)/files")
+        for path in sys.path:
+            if pattern.match(path):
+                result = path.split("/files")[0]
                 break
         else:
             result = None
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/platformdirs/version.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/platformdirs/version.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/platformdirs/version.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/platformdirs/version.py	2024-08-15 06:46:07.172821873 -0400
@@ -12,5 +12,5 @@
 __version_tuple__: VERSION_TUPLE
 version_tuple: VERSION_TUPLE
 
-__version__ = version = '4.2.1'
-__version_tuple__ = version_tuple = (4, 2, 1)
+__version__ = version = '4.2.2'
+__version_tuple__ = version_tuple = (4, 2, 2)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/cmdline.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/cmdline.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/cmdline.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/cmdline.py	2024-08-15 06:46:07.172821873 -0400
@@ -4,7 +4,7 @@
 
     Command line interface.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -68,19 +68,19 @@
     try:
         if what == 'lexer':
             cls = get_lexer_by_name(name)
-            print("Help on the %s lexer:" % cls.name)
+            print(f"Help on the {cls.name} lexer:")
             print(dedent(cls.__doc__))
         elif what == 'formatter':
             cls = find_formatter_class(name)
-            print("Help on the %s formatter:" % cls.name)
+            print(f"Help on the {cls.name} formatter:")
             print(dedent(cls.__doc__))
         elif what == 'filter':
             cls = find_filter_class(name)
-            print("Help on the %s filter:" % name)
+            print(f"Help on the {name} filter:")
             print(dedent(cls.__doc__))
         return 0
     except (AttributeError, ValueError):
-        print("%s not found!" % what, file=sys.stderr)
+        print(f"{what} not found!", file=sys.stderr)
         return 1
 
 
@@ -97,7 +97,7 @@
             info.append(tup)
         info.sort()
         for i in info:
-            print(('* %s\n    %s %s') % i)
+            print(('* {}\n    {} {}').format(*i))
 
     elif what == 'formatter':
         print()
@@ -112,7 +112,7 @@
             info.append(tup)
         info.sort()
         for i in info:
-            print(('* %s\n    %s %s') % i)
+            print(('* {}\n    {} {}').format(*i))
 
     elif what == 'filter':
         print()
@@ -122,7 +122,7 @@
         for name in get_all_filters():
             cls = find_filter_class(name)
             print("* " + name + ':')
-            print("    %s" % docstring_headline(cls))
+            print(f"    {docstring_headline(cls)}")
 
     elif what == 'style':
         print()
@@ -132,7 +132,7 @@
         for name in get_all_styles():
             cls = get_style_by_name(name)
             print("* " + name + ':')
-            print("    %s" % docstring_headline(cls))
+            print(f"    {docstring_headline(cls)}")
 
 
 def _print_list_as_json(requested_items):
@@ -185,8 +185,8 @@
         return 0
 
     if argns.V:
-        print('Pygments version %s, (c) 2006-2023 by Georg Brandl, Matthäus '
-              'Chajdas and contributors.' % __version__)
+        print(f'Pygments version {__version__}, (c) 2006-2024 by Georg Brandl, Matthäus '
+              'Chajdas and contributors.')
         return 0
 
     def is_only_option(opt):
@@ -659,7 +659,7 @@
         msg = info[-1].strip()
         if len(info) >= 3:
             # extract relevant file and position info
-            msg += '\n   (f%s)' % info[-2].split('\n')[0].strip()[1:]
+            msg += '\n   (f{})'.format(info[-2].split('\n')[0].strip()[1:])
         print(file=sys.stderr)
         print('*** Error while highlighting:', file=sys.stderr)
         print(msg, file=sys.stderr)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/console.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/console.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/console.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/console.py	2024-08-15 06:46:07.172821873 -0400
@@ -4,7 +4,7 @@
 
     Format colored console output.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -27,12 +27,12 @@
                 "brightmagenta", "brightcyan", "white"]
 
 x = 30
-for d, l in zip(dark_colors, light_colors):
-    codes[d] = esc + "%im" % x
-    codes[l] = esc + "%im" % (60 + x)
+for dark, light in zip(dark_colors, light_colors):
+    codes[dark] = esc + "%im" % x
+    codes[light] = esc + "%im" % (60 + x)
     x += 1
 
-del d, l, x
+del dark, light, x
 
 codes["white"] = codes["bold"]
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/filter.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/filter.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/filter.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/filter.py	2024-08-15 06:46:07.172821873 -0400
@@ -4,7 +4,7 @@
 
     Module that implements the default filter.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -62,8 +62,7 @@
 
     def __init__(self, **options):
         if not hasattr(self, 'function'):
-            raise TypeError('%r used without bound function' %
-                            self.__class__.__name__)
+            raise TypeError(f'{self.__class__.__name__!r} used without bound function')
         Filter.__init__(self, **options)
 
     def filter(self, lexer, stream):
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/filters/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/filters/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/filters/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/filters/__init__.py	2024-08-15 06:46:07.173821873 -0400
@@ -5,7 +5,7 @@
     Module containing filter lookup functions and default
     filters.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -39,7 +39,7 @@
     if cls:
         return cls(**options)
     else:
-        raise ClassNotFound('filter %r not found' % filtername)
+        raise ClassNotFound(f'filter {filtername!r} not found')
 
 
 def get_all_filters():
@@ -79,9 +79,9 @@
         Filter.__init__(self, **options)
         tags = get_list_opt(options, 'codetags',
                             ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
-        self.tag_re = re.compile(r'\b(%s)\b' % '|'.join([
+        self.tag_re = re.compile(r'\b({})\b'.format('|'.join([
             re.escape(tag) for tag in tags if tag
-        ]))
+        ])))
 
     def filter(self, lexer, stream):
         regex = self.tag_re
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatter.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatter.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatter.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatter.py	2024-08-15 06:46:07.172821873 -0400
@@ -4,7 +4,7 @@
 
     Base formatter class.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -122,3 +122,8 @@
             # wrap the outfile in a StreamWriter
             outfile = codecs.lookup(self.encoding)[3](outfile)
         return self.format_unencoded(tokensource, outfile)
+
+    # Allow writing Formatter[str] or Formatter[bytes]. That's equivalent to
+    # Formatter. This helps when using third-party type stubs from typeshed.
+    def __class_getitem__(cls, name):
+        return cls
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/bbcode.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/bbcode.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/bbcode.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/bbcode.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     BBcode formatter.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -60,7 +60,7 @@
         for ttype, ndef in self.style:
             start = end = ''
             if ndef['color']:
-                start += '[color=#%s]' % ndef['color']
+                start += '[color=#{}]'.format(ndef['color'])
                 end = '[/color]' + end
             if ndef['bold']:
                 start += '[b]'
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/groff.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/groff.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/groff.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/groff.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     Formatter for groff output.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -63,7 +63,7 @@
         for ttype, ndef in self.style:
             start = end = ''
             if ndef['color']:
-                start += '\\m[%s]' % ndef['color']
+                start += '\\m[{}]'.format(ndef['color'])
                 end = '\\m[]' + end
             if ndef['bold']:
                 start += bold
@@ -72,7 +72,7 @@
                 start += italic
                 end = regular + end
             if ndef['bgcolor']:
-                start += '\\M[%s]' % ndef['bgcolor']
+                start += '\\M[{}]'.format(ndef['bgcolor'])
                 end = '\\M[]' + end
 
             self.styles[ttype] = start, end
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/html.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/html.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/html.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/html.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     Formatter for HTML output.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -62,7 +62,7 @@
 CSSFILE_TEMPLATE = '''\
 /*
 generated by Pygments <https://pygments.org/>
-Copyright 2006-2023 by the Pygments team.
+Copyright 2006-2024 by the Pygments team.
 Licensed under the BSD license, see LICENSE for details.
 */
 %(styledefs)s
@@ -73,7 +73,7 @@
    "http://www.w3.org/TR/html4/strict.dtd">
 <!--
 generated by Pygments <https://pygments.org/>
-Copyright 2006-2023 by the Pygments team.
+Copyright 2006-2024 by the Pygments team.
 Licensed under the BSD license, see LICENSE for details.
 -->
 <html>
@@ -488,7 +488,7 @@
             name = self._get_css_class(ttype)
             style = ''
             if ndef['color']:
-                style += 'color: %s; ' % webify(ndef['color'])
+                style += 'color: {}; '.format(webify(ndef['color']))
             if ndef['bold']:
                 style += 'font-weight: bold; '
             if ndef['italic']:
@@ -496,9 +496,9 @@
             if ndef['underline']:
                 style += 'text-decoration: underline; '
             if ndef['bgcolor']:
-                style += 'background-color: %s; ' % webify(ndef['bgcolor'])
+                style += 'background-color: {}; '.format(webify(ndef['bgcolor']))
             if ndef['border']:
-                style += 'border: 1px solid %s; ' % webify(ndef['border'])
+                style += 'border: 1px solid {}; '.format(webify(ndef['border']))
             if style:
                 t2c[ttype] = name
                 # save len(ttype) to enable ordering the styles by
@@ -530,7 +530,7 @@
         styles.sort()
 
         lines = [
-            '%s { %s } /* %s */' % (prefix(cls), style, repr(ttype)[6:])
+            f'{prefix(cls)} {{ {style} }} /* {repr(ttype)[6:]} */'
             for (level, ttype, cls, style) in styles
         ]
 
@@ -548,24 +548,24 @@
             if Text in self.ttype2class:
                 text_style = ' ' + self.class2style[self.ttype2class[Text]][0]
             lines.insert(
-                0, '%s{ background: %s;%s }' % (
+                0, '{}{{ background: {};{} }}'.format(
                     prefix(''), bg_color, text_style
                 )
             )
         if hl_color is not None:
             lines.insert(
-                0, '%s { background-color: %s }' % (prefix('hll'), hl_color)
+                0, '{} {{ background-color: {} }}'.format(prefix('hll'), hl_color)
             )
 
         return lines
 
     def get_linenos_style_defs(self):
         lines = [
-            'pre { %s }' % self._pre_style,
-            'td.linenos .normal { %s }' % self._linenos_style,
-            'span.linenos { %s }' % self._linenos_style,
-            'td.linenos .special { %s }' % self._linenos_special_style,
-            'span.linenos.special { %s }' % self._linenos_special_style,
+            f'pre {{ {self._pre_style} }}',
+            f'td.linenos .normal {{ {self._linenos_style} }}',
+            f'span.linenos {{ {self._linenos_style} }}',
+            f'td.linenos .special {{ {self._linenos_special_style} }}',
+            f'span.linenos.special {{ {self._linenos_special_style} }}',
         ]
 
         return lines
@@ -594,17 +594,15 @@
 
     @property
     def _linenos_style(self):
-        return 'color: %s; background-color: %s; padding-left: 5px; padding-right: 5px;' % (
-            self.style.line_number_color,
-            self.style.line_number_background_color
-        )
+        color = self.style.line_number_color
+        background_color = self.style.line_number_background_color
+        return f'color: {color}; background-color: {background_color}; padding-left: 5px; padding-right: 5px;'
 
     @property
     def _linenos_special_style(self):
-        return 'color: %s; background-color: %s; padding-left: 5px; padding-right: 5px;' % (
-            self.style.line_number_special_color,
-            self.style.line_number_special_background_color
-        )
+        color = self.style.line_number_special_color
+        background_color = self.style.line_number_special_background_color
+        return f'color: {color}; background-color: {background_color}; padding-left: 5px; padding-right: 5px;'
 
     def _decodeifneeded(self, value):
         if isinstance(value, bytes):
@@ -685,9 +683,9 @@
 
             if nocls:
                 if special_line:
-                    style = ' style="%s"' % self._linenos_special_style
+                    style = f' style="{self._linenos_special_style}"'
                 else:
-                    style = ' style="%s"' % self._linenos_style
+                    style = f' style="{self._linenos_style}"'
             else:
                 if special_line:
                     style = ' class="special"'
@@ -695,7 +693,7 @@
                     style = ' class="normal"'
 
             if style:
-                line = '<span%s>%s</span>' % (style, line)
+                line = f'<span{style}>{line}</span>'
 
             lines.append(line)
 
@@ -744,9 +742,9 @@
 
             if nocls:
                 if special_line:
-                    style = ' style="%s"' % self._linenos_special_style
+                    style = f' style="{self._linenos_special_style}"'
                 else:
-                    style = ' style="%s"' % self._linenos_style
+                    style = f' style="{self._linenos_style}"'
             else:
                 if special_line:
                     style = ' class="linenos special"'
@@ -754,7 +752,7 @@
                     style = ' class="linenos"'
 
             if style:
-                linenos = '<span%s>%s</span>' % (style, line)
+                linenos = f'<span{style}>{line}</span>'
             else:
                 linenos = line
 
@@ -791,13 +789,13 @@
         style = []
         if (self.noclasses and not self.nobackground and
                 self.style.background_color is not None):
-            style.append('background: %s' % (self.style.background_color,))
+            style.append(f'background: {self.style.background_color}')
         if self.cssstyles:
             style.append(self.cssstyles)
         style = '; '.join(style)
 
-        yield 0, ('<div' + (self.cssclass and ' class="%s"' % self.cssclass) +
-                  (style and (' style="%s"' % style)) + '>')
+        yield 0, ('<div' + (self.cssclass and f' class="{self.cssclass}"') +
+                  (style and (f' style="{style}"')) + '>')
         yield from inner
         yield 0, '</div>\n'
 
@@ -814,7 +812,7 @@
 
         # the empty span here is to keep leading empty lines from being
         # ignored by HTML parsers
-        yield 0, ('<pre' + (style and ' style="%s"' % style) + '><span></span>')
+        yield 0, ('<pre' + (style and f' style="{style}"') + '><span></span>')
         yield from inner
         yield 0, '</pre>'
 
@@ -843,18 +841,18 @@
             try:
                 cspan = self.span_element_openers[ttype]
             except KeyError:
-                title = ' title="%s"' % '.'.join(ttype) if self.debug_token_types else ''
+                title = ' title="{}"'.format('.'.join(ttype)) if self.debug_token_types else ''
                 if nocls:
                     css_style = self._get_css_inline_styles(ttype)
                     if css_style:
                         css_style = self.class2style[css_style][0]
-                        cspan = '<span style="%s"%s>' % (css_style, title)
+                        cspan = f'<span style="{css_style}"{title}>'
                     else:
                         cspan = ''
                 else:
                     css_class = self._get_css_classes(ttype)
                     if css_class:
-                        cspan = '<span class="%s"%s>' % (css_class, title)
+                        cspan = f'<span class="{css_class}"{title}>'
                     else:
                         cspan = ''
                 self.span_element_openers[ttype] = cspan
@@ -927,11 +925,10 @@
                 if self.noclasses:
                     style = ''
                     if self.style.highlight_color is not None:
-                        style = (' style="background-color: %s"' %
-                                 (self.style.highlight_color,))
-                    yield 1, '<span%s>%s</span>' % (style, value)
+                        style = (f' style="background-color: {self.style.highlight_color}"')
+                    yield 1, f'<span{style}>{value}</span>'
                 else:
-                    yield 1, '<span class="hll">%s</span>' % value
+                    yield 1, f'<span class="hll">{value}</span>'
             else:
                 yield 1, value
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/img.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/img.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/img.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/img.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     Formatter for Pixmap output.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 import os
@@ -90,7 +90,7 @@
             self._create_nix()
 
     def _get_nix_font_path(self, name, style):
-        proc = subprocess.Popen(['fc-list', "%s:style=%s" % (name, style), 'file'],
+        proc = subprocess.Popen(['fc-list', f"{name}:style={style}", 'file'],
                                 stdout=subprocess.PIPE, stderr=None)
         stdout, _ = proc.communicate()
         if proc.returncode == 0:
@@ -110,8 +110,7 @@
                 self.fonts['NORMAL'] = ImageFont.truetype(path, self.font_size)
                 break
         else:
-            raise FontNotFound('No usable fonts named: "%s"' %
-                               self.font_name)
+            raise FontNotFound(f'No usable fonts named: "{self.font_name}"')
         for style in ('ITALIC', 'BOLD', 'BOLDITALIC'):
             for stylename in STYLES[style]:
                 path = self._get_nix_font_path(self.font_name, stylename)
@@ -142,8 +141,7 @@
                 self.fonts['NORMAL'] = ImageFont.truetype(path, self.font_size)
                 break
         else:
-            raise FontNotFound('No usable fonts named: "%s"' %
-                               self.font_name)
+            raise FontNotFound(f'No usable fonts named: "{self.font_name}"')
         for style in ('ITALIC', 'BOLD', 'BOLDITALIC'):
             for stylename in STYLES[style]:
                 path = self._get_mac_font_path(font_map, self.font_name, stylename)
@@ -160,15 +158,14 @@
         for suffix in ('', ' (TrueType)'):
             for style in styles:
                 try:
-                    valname = '%s%s%s' % (basename, style and ' '+style, suffix)
+                    valname = '{}{}{}'.format(basename, style and ' '+style, suffix)
                     val, _ = _winreg.QueryValueEx(key, valname)
                     return val
                 except OSError:
                     continue
         else:
             if fail:
-                raise FontNotFound('Font %s (%s) not found in registry' %
-                                   (basename, styles[0]))
+                raise FontNotFound(f'Font {basename} ({styles[0]}) not found in registry')
             return None
 
     def _create_win(self):
@@ -633,7 +630,11 @@
                                fill=self.hl_color)
         for pos, value, font, text_fg, text_bg in self.drawables:
             if text_bg:
-                text_size = draw.textsize(text=value, font=font)
+                # see deprecations https://pillow.readthedocs.io/en/stable/releasenotes/9.2.0.html#font-size-and-offset-methods
+                if hasattr(draw, 'textsize'):
+                    text_size = draw.textsize(text=value, font=font)
+                else:
+                    text_size = font.getbbox(value)[2:]
                 draw.rectangle([pos[0], pos[1], pos[0] + text_size[0], pos[1] + text_size[1]], fill=text_bg)
             draw.text(pos, value, font=font, fill=text_fg)
         im.save(outfile, self.image_format.upper())
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/__init__.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     Pygments formatters.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -77,7 +77,7 @@
     """
     cls = find_formatter_class(_alias)
     if cls is None:
-        raise ClassNotFound("no formatter found for name %r" % _alias)
+        raise ClassNotFound(f"no formatter found for name {_alias!r}")
     return cls(**options)
 
 
@@ -103,17 +103,16 @@
             exec(f.read(), custom_namespace)
         # Retrieve the class `formattername` from that namespace
         if formattername not in custom_namespace:
-            raise ClassNotFound('no valid %s class found in %s' %
-                                (formattername, filename))
+            raise ClassNotFound(f'no valid {formattername} class found in {filename}')
         formatter_class = custom_namespace[formattername]
         # And finally instantiate it with the options
         return formatter_class(**options)
     except OSError as err:
-        raise ClassNotFound('cannot read %s: %s' % (filename, err))
+        raise ClassNotFound(f'cannot read {filename}: {err}')
     except ClassNotFound:
         raise
     except Exception as err:
-        raise ClassNotFound('error when loading custom formatter: %s' % err)
+        raise ClassNotFound(f'error when loading custom formatter: {err}')
 
 
 def get_formatter_for_filename(fn, **options):
@@ -135,7 +134,7 @@
         for filename in cls.filenames:
             if _fn_matches(fn, filename):
                 return cls(**options)
-    raise ClassNotFound("no formatter found for file name %r" % fn)
+    raise ClassNotFound(f"no formatter found for file name {fn!r}")
 
 
 class _automodule(types.ModuleType):
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/irc.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/irc.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/irc.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/irc.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     Formatter for IRC output
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/latex.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/latex.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/latex.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/latex.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     Formatter for LaTeX fancyvrb output.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -23,21 +23,21 @@
     return text.replace('\\', '\x00'). \
                 replace('{', '\x01'). \
                 replace('}', '\x02'). \
-                replace('\x00', r'\%sZbs{}' % commandprefix). \
-                replace('\x01', r'\%sZob{}' % commandprefix). \
-                replace('\x02', r'\%sZcb{}' % commandprefix). \
-                replace('^', r'\%sZca{}' % commandprefix). \
-                replace('_', r'\%sZus{}' % commandprefix). \
-                replace('&', r'\%sZam{}' % commandprefix). \
-                replace('<', r'\%sZlt{}' % commandprefix). \
-                replace('>', r'\%sZgt{}' % commandprefix). \
-                replace('#', r'\%sZsh{}' % commandprefix). \
-                replace('%', r'\%sZpc{}' % commandprefix). \
-                replace('$', r'\%sZdl{}' % commandprefix). \
-                replace('-', r'\%sZhy{}' % commandprefix). \
-                replace("'", r'\%sZsq{}' % commandprefix). \
-                replace('"', r'\%sZdq{}' % commandprefix). \
-                replace('~', r'\%sZti{}' % commandprefix)
+                replace('\x00', rf'\{commandprefix}Zbs{{}}'). \
+                replace('\x01', rf'\{commandprefix}Zob{{}}'). \
+                replace('\x02', rf'\{commandprefix}Zcb{{}}'). \
+                replace('^', rf'\{commandprefix}Zca{{}}'). \
+                replace('_', rf'\{commandprefix}Zus{{}}'). \
+                replace('&', rf'\{commandprefix}Zam{{}}'). \
+                replace('<', rf'\{commandprefix}Zlt{{}}'). \
+                replace('>', rf'\{commandprefix}Zgt{{}}'). \
+                replace('#', rf'\{commandprefix}Zsh{{}}'). \
+                replace('%', rf'\{commandprefix}Zpc{{}}'). \
+                replace('$', rf'\{commandprefix}Zdl{{}}'). \
+                replace('-', rf'\{commandprefix}Zhy{{}}'). \
+                replace("'", rf'\{commandprefix}Zsq{{}}'). \
+                replace('"', rf'\{commandprefix}Zdq{{}}'). \
+                replace('~', rf'\{commandprefix}Zti{{}}')
 
 
 DOC_TEMPLATE = r'''
@@ -304,17 +304,14 @@
             if ndef['mono']:
                 cmndef += r'\let\$$@ff=\textsf'
             if ndef['color']:
-                cmndef += (r'\def\$$@tc##1{\textcolor[rgb]{%s}{##1}}' %
-                           rgbcolor(ndef['color']))
+                cmndef += (r'\def\$$@tc##1{{\textcolor[rgb]{{{}}}{{##1}}}}'.format(rgbcolor(ndef['color'])))
             if ndef['border']:
-                cmndef += (r'\def\$$@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}'
-                           r'\fcolorbox[rgb]{%s}{%s}{\strut ##1}}}' %
-                           (rgbcolor(ndef['border']),
+                cmndef += (r'\def\$$@bc##1{{{{\setlength{{\fboxsep}}{{\string -\fboxrule}}'
+                           r'\fcolorbox[rgb]{{{}}}{{{}}}{{\strut ##1}}}}}}'.format(rgbcolor(ndef['border']),
                             rgbcolor(ndef['bgcolor'])))
             elif ndef['bgcolor']:
-                cmndef += (r'\def\$$@bc##1{{\setlength{\fboxsep}{0pt}'
-                           r'\colorbox[rgb]{%s}{\strut ##1}}}' %
-                           rgbcolor(ndef['bgcolor']))
+                cmndef += (r'\def\$$@bc##1{{{{\setlength{{\fboxsep}}{{0pt}}'
+                           r'\colorbox[rgb]{{{}}}{{\strut ##1}}}}}}'.format(rgbcolor(ndef['bgcolor'])))
             if cmndef == '':
                 continue
             cmndef = cmndef.replace('$$', cp)
@@ -329,7 +326,7 @@
         cp = self.commandprefix
         styles = []
         for name, definition in self.cmd2def.items():
-            styles.append(r'\@namedef{%s@tok@%s}{%s}' % (cp, name, definition))
+            styles.append(rf'\@namedef{{{cp}@tok@{name}}}{{{definition}}}')
         return STYLE_TEMPLATE % {'cp': self.commandprefix,
                                  'styles': '\n'.join(styles)}
 
@@ -410,10 +407,10 @@
                 spl = value.split('\n')
                 for line in spl[:-1]:
                     if line:
-                        outfile.write("\\%s{%s}{%s}" % (cp, styleval, line))
+                        outfile.write(f"\\{cp}{{{styleval}}}{{{line}}}")
                     outfile.write('\n')
                 if spl[-1]:
-                    outfile.write("\\%s{%s}{%s}" % (cp, styleval, spl[-1]))
+                    outfile.write(f"\\{cp}{{{styleval}}}{{{spl[-1]}}}")
             else:
                 outfile.write(value)
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/other.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/other.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/other.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/other.py	2024-08-15 06:46:07.174821873 -0400
@@ -4,7 +4,7 @@
 
     Other formatters: NullFormatter, RawTokenFormatter.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -74,8 +74,7 @@
             try:
                 colorize(self.error_color, '')
             except KeyError:
-                raise ValueError("Invalid color %r specified" %
-                                 self.error_color)
+                raise ValueError(f"Invalid color {self.error_color!r} specified")
 
     def format(self, tokensource, outfile):
         try:
@@ -147,7 +146,7 @@
         outbuf = []
         for ttype, value in tokensource:
             rawbuf.append(value)
-            outbuf.append('%s(%s, %r),\n' % (indentation, ttype, value))
+            outbuf.append(f'{indentation}({ttype}, {value!r}),\n')
 
         before = TESTCASE_BEFORE % (''.join(rawbuf),)
         during = ''.join(outbuf)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/pangomarkup.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/pangomarkup.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/pangomarkup.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/pangomarkup.py	2024-08-15 06:46:07.174821873 -0400
@@ -4,7 +4,7 @@
 
     Formatter for Pango markup output.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -45,7 +45,7 @@
             start = ''
             end = ''
             if style['color']:
-                start += '<span fgcolor="#%s">' % style['color']
+                start += '<span fgcolor="#{}">'.format(style['color'])
                 end = '</span>' + end
             if style['bold']:
                 start += '<b>'
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/rtf.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/rtf.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/rtf.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/rtf.py	2024-08-15 06:46:07.174821873 -0400
@@ -4,12 +4,14 @@
 
     A formatter that generates RTF files.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
+from collections import OrderedDict
 from pip._vendor.pygments.formatter import Formatter
-from pip._vendor.pygments.util import get_int_opt, surrogatepair
+from pip._vendor.pygments.style import _ansimap
+from pip._vendor.pygments.util import get_bool_opt, get_int_opt, get_list_opt, surrogatepair
 
 
 __all__ = ['RtfFormatter']
@@ -42,6 +44,59 @@
         default is 24 half-points, giving a size 12 font.
 
         .. versionadded:: 2.0
+
+    `linenos`
+        Turn on line numbering (default: ``False``).
+
+        .. versionadded:: 2.18
+
+    `lineno_fontsize`
+        Font size for line numbers. Size is specified in half points
+        (default: `fontsize`). 
+
+        .. versionadded:: 2.18
+
+    `lineno_padding`
+        Number of spaces between the (inline) line numbers and the
+        source code (default: ``2``).
+
+        .. versionadded:: 2.18
+
+    `linenostart`
+        The line number for the first line (default: ``1``).
+
+        .. versionadded:: 2.18
+
+    `linenostep`
+        If set to a number n > 1, only every nth line number is printed.
+
+        .. versionadded:: 2.18
+
+    `lineno_color`
+        Color for line numbers specified as a hex triplet, e.g. ``'5e5e5e'``. 
+        Defaults to the style's line number color if it is a hex triplet, 
+        otherwise ansi bright black.
+
+        .. versionadded:: 2.18
+
+    `hl_lines`
+        Specify a list of lines to be highlighted, as line numbers separated by
+        spaces, e.g. ``'3 7 8'``. The line numbers are relative to the input 
+        (i.e. the first line is line 1) unless `hl_linenostart` is set.
+
+        .. versionadded:: 2.18
+
+    `hl_color`
+        Color for highlighting the lines specified in `hl_lines`, specified as 
+        a hex triplet (default: style's `highlight_color`).
+
+        .. versionadded:: 2.18
+
+    `hl_linenostart`
+        If set to ``True`` line numbers in `hl_lines` are specified
+        relative to `linenostart` (default ``False``).
+
+        .. versionadded:: 2.18
     """
     name = 'RTF'
     aliases = ['rtf']
@@ -62,6 +117,40 @@
         Formatter.__init__(self, **options)
         self.fontface = options.get('fontface') or ''
         self.fontsize = get_int_opt(options, 'fontsize', 0)
+        self.linenos = get_bool_opt(options, 'linenos', False)
+        self.lineno_fontsize = get_int_opt(options, 'lineno_fontsize',
+                                           self.fontsize)
+        self.lineno_padding = get_int_opt(options, 'lineno_padding', 2)
+        self.linenostart = abs(get_int_opt(options, 'linenostart', 1))
+        self.linenostep = abs(get_int_opt(options, 'linenostep', 1))
+        self.hl_linenostart = get_bool_opt(options, 'hl_linenostart', False)
+
+        self.hl_color = options.get('hl_color', '')
+        if not self.hl_color:
+            self.hl_color = self.style.highlight_color
+
+        self.hl_lines = []
+        for lineno in get_list_opt(options, 'hl_lines', []):
+            try:
+                lineno = int(lineno)
+                if self.hl_linenostart:
+                    lineno = lineno - self.linenostart + 1
+                self.hl_lines.append(lineno)
+            except ValueError:
+                pass
+
+        self.lineno_color = options.get('lineno_color', '')
+        if not self.lineno_color:
+            if  self.style.line_number_color == 'inherit':
+                # style color is the css value 'inherit'
+                # default to ansi bright-black
+                self.lineno_color = _ansimap['ansibrightblack']
+            else:
+                # style color is assumed to be a hex triplet as other
+                # colors in pygments/style.py
+                self.lineno_color = self.style.line_number_color
+
+        self.color_mapping = self._create_color_mapping()
 
     def _escape(self, text):
         return text.replace('\\', '\\\\') \
@@ -90,43 +179,145 @@
                 # Force surrogate pairs
                 buf.append('{\\u%d}{\\u%d}' % surrogatepair(cn))
 
-        return ''.join(buf).replace('\n', '\\par\n')
+        return ''.join(buf).replace('\n', '\\par')
 
-    def format_unencoded(self, tokensource, outfile):
-        # rtf 1.8 header
-        outfile.write('{\\rtf1\\ansi\\uc0\\deff0'
-                      '{\\fonttbl{\\f0\\fmodern\\fprq1\\fcharset0%s;}}'
-                      '{\\colortbl;' % (self.fontface and
-                                        ' ' + self._escape(self.fontface) or
-                                        ''))
+    @staticmethod
+    def hex_to_rtf_color(hex_color):
+        if hex_color[0] == "#":
+            hex_color = hex_color[1:]
+
+        return '\\red%d\\green%d\\blue%d;' % (
+                        int(hex_color[0:2], 16),
+                        int(hex_color[2:4], 16),
+                        int(hex_color[4:6], 16)
+                    )
 
-        # convert colors and save them in a mapping to access them later.
-        color_mapping = {}
+    def _split_tokens_on_newlines(self, tokensource):
+        """
+        Split tokens containing newline characters into multiple token
+        each representing a line of the input file. Needed for numbering
+        lines of e.g. multiline comments.
+        """
+        for ttype, value in tokensource:
+            if value == '\n':
+                yield (ttype, value)
+            elif "\n" in value:
+                lines = value.split("\n")
+                for line in lines[:-1]:
+                    yield (ttype, line+"\n")
+                if lines[-1]:
+                    yield (ttype, lines[-1])
+            else:
+                yield (ttype, value)
+
+    def _create_color_mapping(self):
+        """
+        Create a mapping of style hex colors to index/offset in
+        the RTF color table.
+        """
+        color_mapping = OrderedDict()
         offset = 1
+
+        if self.linenos:
+            color_mapping[self.lineno_color] = offset
+            offset += 1
+
+        if self.hl_lines:
+            color_mapping[self.hl_color] = offset
+            offset += 1
+
         for _, style in self.style:
             for color in style['color'], style['bgcolor'], style['border']:
                 if color and color not in color_mapping:
                     color_mapping[color] = offset
-                    outfile.write('\\red%d\\green%d\\blue%d;' % (
-                        int(color[0:2], 16),
-                        int(color[2:4], 16),
-                        int(color[4:6], 16)
-                    ))
                     offset += 1
-        outfile.write('}\\f0 ')
+
+        return color_mapping
+
+    @property
+    def _lineno_template(self):
+        if self.lineno_fontsize != self.fontsize:
+            return '{{\\fs{} \\cf{} %s{}}}'.format(self.lineno_fontsize,
+                          self.color_mapping[self.lineno_color],
+                          " " * self.lineno_padding)
+
+        return '{{\\cf{} %s{}}}'.format(self.color_mapping[self.lineno_color],
+                      " " * self.lineno_padding)
+
+    @property
+    def _hl_open_str(self):
+        return rf'{{\highlight{self.color_mapping[self.hl_color]} '
+
+    @property
+    def _rtf_header(self):
+        lines = []
+        # rtf 1.8 header
+        lines.append('{\\rtf1\\ansi\\uc0\\deff0'
+                     '{\\fonttbl{\\f0\\fmodern\\fprq1\\fcharset0%s;}}'
+                     % (self.fontface and ' '
+                        + self._escape(self.fontface) or ''))
+
+        # color table
+        lines.append('{\\colortbl;')
+        for color, _ in self.color_mapping.items():
+            lines.append(self.hex_to_rtf_color(color))
+        lines.append('}')
+
+        # font and fontsize
+        lines.append('\\f0\\sa0')
         if self.fontsize:
-            outfile.write('\\fs%d' % self.fontsize)
+            lines.append('\\fs%d' % self.fontsize)
+
+        # ensure Libre Office Writer imports and renders consecutive
+        # space characters the same width, needed for line numbering.
+        # https://bugs.documentfoundation.org/show_bug.cgi?id=144050
+        lines.append('\\dntblnsbdb')
+
+        return lines
+
+    def format_unencoded(self, tokensource, outfile):
+        for line in self._rtf_header:
+            outfile.write(line + "\n")
+
+        tokensource = self._split_tokens_on_newlines(tokensource)
+
+        # first pass of tokens to count lines, needed for line numbering
+        if self.linenos:
+            line_count = 0
+            tokens = [] # for copying the token source generator
+            for ttype, value in tokensource:
+                tokens.append((ttype, value))
+                if value.endswith("\n"):
+                    line_count += 1
+
+            # width of line number strings (for padding with spaces)
+            linenos_width = len(str(line_count+self.linenostart-1))
+
+            tokensource = tokens
 
         # highlight stream
+        lineno = 1
+        start_new_line = True
         for ttype, value in tokensource:
+            if start_new_line and lineno in self.hl_lines:
+                outfile.write(self._hl_open_str)
+
+            if start_new_line and self.linenos:
+                if (lineno-self.linenostart+1)%self.linenostep == 0:
+                    current_lineno = lineno + self.linenostart - 1
+                    lineno_str = str(current_lineno).rjust(linenos_width)
+                else:
+                    lineno_str = "".rjust(linenos_width)
+                outfile.write(self._lineno_template % lineno_str)
+
             while not self.style.styles_token(ttype) and ttype.parent:
                 ttype = ttype.parent
             style = self.style.style_for_token(ttype)
             buf = []
             if style['bgcolor']:
-                buf.append('\\cb%d' % color_mapping[style['bgcolor']])
+                buf.append('\\cb%d' % self.color_mapping[style['bgcolor']])
             if style['color']:
-                buf.append('\\cf%d' % color_mapping[style['color']])
+                buf.append('\\cf%d' % self.color_mapping[style['color']])
             if style['bold']:
                 buf.append('\\b')
             if style['italic']:
@@ -135,12 +326,24 @@
                 buf.append('\\ul')
             if style['border']:
                 buf.append('\\chbrdr\\chcfpat%d' %
-                           color_mapping[style['border']])
+                           self.color_mapping[style['border']])
             start = ''.join(buf)
             if start:
-                outfile.write('{%s ' % start)
+                outfile.write(f'{{{start} ')
             outfile.write(self._escape_text(value))
             if start:
                 outfile.write('}')
+            start_new_line = False
+
+            # complete line of input
+            if value.endswith("\n"):
+                # close line highlighting
+                if lineno in self.hl_lines:
+                    outfile.write('}')
+                # newline in RTF file after closing }
+                outfile.write("\n")
+
+                start_new_line = True
+                lineno += 1
 
-        outfile.write('}')
+        outfile.write('}\n')
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/svg.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/svg.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/svg.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/svg.py	2024-08-15 06:46:07.174821873 -0400
@@ -4,7 +4,7 @@
 
     Formatter for SVG output.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -60,11 +60,11 @@
 
     `linenostep`
         If set to a number n > 1, only every nth line number is printed.
-        
+
     `linenowidth`
         Maximum width devoted to line numbers (default: ``3*ystep``, sufficient
-        for up to 4-digit line numbers. Increase width for longer code blocks).  
-        
+        for up to 4-digit line numbers. Increase width for longer code blocks).
+
     `xoffset`
         Starting offset in X direction, defaults to ``0``.
 
@@ -97,10 +97,11 @@
         self.fontsize = options.get('fontsize', '14px')
         self.xoffset = get_int_opt(options, 'xoffset', 0)
         fs = self.fontsize.strip()
-        if fs.endswith('px'): fs = fs[:-2].strip()
+        if fs.endswith('px'):
+            fs = fs[:-2].strip()
         try:
             int_fs = int(fs)
-        except:
+        except ValueError:
             int_fs = 20
         self.yoffset = get_int_opt(options, 'yoffset', int_fs)
         self.ystep = get_int_opt(options, 'ystep', int_fs + 5)
@@ -122,30 +123,27 @@
         y = self.yoffset
         if not self.nowrap:
             if self.encoding:
-                outfile.write('<?xml version="1.0" encoding="%s"?>\n' %
-                              self.encoding)
+                outfile.write(f'<?xml version="1.0" encoding="{self.encoding}"?>\n')
             else:
                 outfile.write('<?xml version="1.0"?>\n')
             outfile.write('<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.0//EN" '
                           '"http://www.w3.org/TR/2001/REC-SVG-20010904/DTD/'
                           'svg10.dtd">\n')
             outfile.write('<svg xmlns="http://www.w3.org/2000/svg">\n')
-            outfile.write('<g font-family="%s" font-size="%s">\n' %
-                          (self.fontfamily, self.fontsize))
-        
-        counter = self.linenostart 
+            outfile.write(f'<g font-family="{self.fontfamily}" font-size="{self.fontsize}">\n')
+
+        counter = self.linenostart
         counter_step = self.linenostep
         counter_style = self._get_style(Comment)
         line_x = x
-        
+
         if self.linenos:
             if counter % counter_step == 0:
-                outfile.write('<text x="%s" y="%s" %s text-anchor="end">%s</text>' %
-                    (x+self.linenowidth,y,counter_style,counter))
+                outfile.write(f'<text x="{x+self.linenowidth}" y="{y}" {counter_style} text-anchor="end">{counter}</text>')
             line_x += self.linenowidth + self.ystep
             counter += 1
 
-        outfile.write('<text x="%s" y="%s" xml:space="preserve">' % (line_x, y))
+        outfile.write(f'<text x="{line_x}" y="{y}" xml:space="preserve">')
         for ttype, value in tokensource:
             style = self._get_style(ttype)
             tspan = style and '<tspan' + style + '>' or ''
@@ -159,11 +157,10 @@
                 y += self.ystep
                 outfile.write('</text>\n')
                 if self.linenos and counter % counter_step == 0:
-                    outfile.write('<text x="%s" y="%s" text-anchor="end" %s>%s</text>' %
-                        (x+self.linenowidth,y,counter_style,counter))
-                
+                    outfile.write(f'<text x="{x+self.linenowidth}" y="{y}" text-anchor="end" {counter_style}>{counter}</text>')
+
                 counter += 1
-                outfile.write('<text x="%s" y="%s" ' 'xml:space="preserve">' % (line_x,y))
+                outfile.write(f'<text x="{line_x}" y="{y}" ' 'xml:space="preserve">')
             outfile.write(tspan + parts[-1] + tspanend)
         outfile.write('</text>')
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/terminal256.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/terminal256.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/terminal256.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/terminal256.py	2024-08-15 06:46:07.174821873 -0400
@@ -10,7 +10,7 @@
 
     Formatter version 1.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/terminal.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/terminal.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/terminal.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/formatters/terminal.py	2024-08-15 06:46:07.174821873 -0400
@@ -4,7 +4,7 @@
 
     Formatter for terminal output with ANSI sequences.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/__init__.py	2024-08-15 06:46:07.172821873 -0400
@@ -21,12 +21,12 @@
     .. _Pygments master branch:
        https://github.com/pygments/pygments/archive/master.zip#egg=Pygments-dev
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 from io import StringIO, BytesIO
 
-__version__ = '2.17.2'
+__version__ = '2.18.0'
 __docformat__ = 'restructuredtext'
 
 __all__ = ['lex', 'format', 'highlight']
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/lexer.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/lexer.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/lexer.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/lexer.py	2024-08-15 06:46:07.172821873 -0400
@@ -4,7 +4,7 @@
 
     Base lexer classes.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -67,10 +67,12 @@
        :no-value:
     .. autoattribute:: priority
 
-    Lexers included in Pygments should have an additional attribute:
+    Lexers included in Pygments should have two additional attributes:
 
     .. autoattribute:: url
        :no-value:
+    .. autoattribute:: version_added
+       :no-value:
 
     Lexers included in Pygments may have additional attributes:
 
@@ -130,9 +132,12 @@
     priority = 0
 
     #: URL of the language specification/definition. Used in the Pygments
-    #: documentation.
+    #: documentation. Set to an empty string to disable.
     url = None
 
+    #: Version of Pygments in which the lexer was added.
+    version_added = None
+
     #: Example file name. Relative to the ``tests/examplefiles`` directory.
     #: This is used by the documentation generator to show an example.
     _example = None
@@ -169,10 +174,9 @@
 
     def __repr__(self):
         if self.options:
-            return '<pygments.lexers.%s with %r>' % (self.__class__.__name__,
-                                                     self.options)
+            return f'<pygments.lexers.{self.__class__.__name__} with {self.options!r}>'
         else:
-            return '<pygments.lexers.%s>' % self.__class__.__name__
+            return f'<pygments.lexers.{self.__class__.__name__}>'
 
     def add_filter(self, filter_, **options):
         """
@@ -508,7 +512,7 @@
     def _process_token(cls, token):
         """Preprocess the token component of a token definition."""
         assert type(token) is _TokenType or callable(token), \
-            'token type must be simple type or callable, not %r' % (token,)
+            f'token type must be simple type or callable, not {token!r}'
         return token
 
     def _process_new_state(cls, new_state, unprocessed, processed):
@@ -524,14 +528,14 @@
             elif new_state[:5] == '#pop:':
                 return -int(new_state[5:])
             else:
-                assert False, 'unknown new state %r' % new_state
+                assert False, f'unknown new state {new_state!r}'
         elif isinstance(new_state, combined):
             # combine a new state from existing ones
             tmp_state = '_tmp_%d' % cls._tmpname
             cls._tmpname += 1
             itokens = []
             for istate in new_state:
-                assert istate != new_state, 'circular state ref %r' % istate
+                assert istate != new_state, f'circular state ref {istate!r}'
                 itokens.extend(cls._process_state(unprocessed,
                                                   processed, istate))
             processed[tmp_state] = itokens
@@ -544,12 +548,12 @@
                     'unknown new state ' + istate
             return new_state
         else:
-            assert False, 'unknown new state def %r' % new_state
+            assert False, f'unknown new state def {new_state!r}'
 
     def _process_state(cls, unprocessed, processed, state):
         """Preprocess a single state definition."""
-        assert type(state) is str, "wrong state name %r" % state
-        assert state[0] != '#', "invalid state name %r" % state
+        assert isinstance(state, str), f"wrong state name {state!r}"
+        assert state[0] != '#', f"invalid state name {state!r}"
         if state in processed:
             return processed[state]
         tokens = processed[state] = []
@@ -557,7 +561,7 @@
         for tdef in unprocessed[state]:
             if isinstance(tdef, include):
                 # it's a state reference
-                assert tdef != state, "circular state reference %r" % state
+                assert tdef != state, f"circular state reference {state!r}"
                 tokens.extend(cls._process_state(unprocessed, processed,
                                                  str(tdef)))
                 continue
@@ -571,13 +575,12 @@
                 tokens.append((re.compile('').match, None, new_state))
                 continue
 
-            assert type(tdef) is tuple, "wrong rule def %r" % tdef
+            assert type(tdef) is tuple, f"wrong rule def {tdef!r}"
 
             try:
                 rex = cls._process_regex(tdef[0], rflags, state)
             except Exception as err:
-                raise ValueError("uncompilable regex %r in state %r of %r: %s" %
-                                 (tdef[0], state, cls, err)) from err
+                raise ValueError(f"uncompilable regex {tdef[0]!r} in state {state!r} of {cls!r}: {err}") from err
 
             token = cls._process_token(tdef[1])
 
@@ -738,7 +741,7 @@
                         elif new_state == '#push':
                             statestack.append(statestack[-1])
                         else:
-                            assert False, "wrong state def: %r" % new_state
+                            assert False, f"wrong state def: {new_state!r}"
                         statetokens = tokendefs[statestack[-1]]
                     break
             else:
@@ -770,8 +773,7 @@
         self.stack = stack or ['root']
 
     def __repr__(self):
-        return 'LexerContext(%r, %r, %r)' % (
-            self.text, self.pos, self.stack)
+        return f'LexerContext({self.text!r}, {self.pos!r}, {self.stack!r})'
 
 
 class ExtendedRegexLexer(RegexLexer):
@@ -826,7 +828,7 @@
                         elif new_state == '#push':
                             ctx.stack.append(ctx.stack[-1])
                         else:
-                            assert False, "wrong state def: %r" % new_state
+                            assert False, f"wrong state def: {new_state!r}"
                         statetokens = tokendefs[ctx.stack[-1]]
                     break
             else:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/__init__.py	2024-08-15 06:46:07.174821873 -0400
@@ -4,7 +4,7 @@
 
     Pygments lexers.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -93,7 +93,7 @@
     .. versionadded:: 2.2
     """
     if not _alias:
-        raise ClassNotFound('no lexer for alias %r found' % _alias)
+        raise ClassNotFound(f'no lexer for alias {_alias!r} found')
     # lookup builtin lexers
     for module_name, name, aliases, _, _ in LEXERS.values():
         if _alias.lower() in aliases:
@@ -104,7 +104,7 @@
     for cls in find_plugin_lexers():
         if _alias.lower() in cls.aliases:
             return cls
-    raise ClassNotFound('no lexer for alias %r found' % _alias)
+    raise ClassNotFound(f'no lexer for alias {_alias!r} found')
 
 
 def get_lexer_by_name(_alias, **options):
@@ -117,7 +117,7 @@
     found.
     """
     if not _alias:
-        raise ClassNotFound('no lexer for alias %r found' % _alias)
+        raise ClassNotFound(f'no lexer for alias {_alias!r} found')
 
     # lookup builtin lexers
     for module_name, name, aliases, _, _ in LEXERS.values():
@@ -129,7 +129,7 @@
     for cls in find_plugin_lexers():
         if _alias.lower() in cls.aliases:
             return cls(**options)
-    raise ClassNotFound('no lexer for alias %r found' % _alias)
+    raise ClassNotFound(f'no lexer for alias {_alias!r} found')
 
 
 def load_lexer_from_file(filename, lexername="CustomLexer", **options):
@@ -154,17 +154,16 @@
             exec(f.read(), custom_namespace)
         # Retrieve the class `lexername` from that namespace
         if lexername not in custom_namespace:
-            raise ClassNotFound('no valid %s class found in %s' %
-                                (lexername, filename))
+            raise ClassNotFound(f'no valid {lexername} class found in {filename}')
         lexer_class = custom_namespace[lexername]
         # And finally instantiate it with the options
         return lexer_class(**options)
     except OSError as err:
-        raise ClassNotFound('cannot read %s: %s' % (filename, err))
+        raise ClassNotFound(f'cannot read {filename}: {err}')
     except ClassNotFound:
         raise
     except Exception as err:
-        raise ClassNotFound('error when loading custom lexer: %s' % err)
+        raise ClassNotFound(f'error when loading custom lexer: {err}')
 
 
 def find_lexer_class_for_filename(_fn, code=None):
@@ -225,7 +224,7 @@
     """
     res = find_lexer_class_for_filename(_fn, code)
     if not res:
-        raise ClassNotFound('no lexer for filename %r found' % _fn)
+        raise ClassNotFound(f'no lexer for filename {_fn!r} found')
     return res(**options)
 
 
@@ -245,7 +244,7 @@
     for cls in find_plugin_lexers():
         if _mime in cls.mimetypes:
             return cls(**options)
-    raise ClassNotFound('no lexer for mimetype %r found' % _mime)
+    raise ClassNotFound(f'no lexer for mimetype {_mime!r} found')
 
 
 def _iter_lexerclasses(plugins=True):
@@ -280,7 +279,7 @@
                 matching_lexers.add(lexer)
                 primary[lexer] = False
     if not matching_lexers:
-        raise ClassNotFound('no lexer for filename %r found' % fn)
+        raise ClassNotFound(f'no lexer for filename {fn!r} found')
     if len(matching_lexers) == 1:
         return matching_lexers.pop()(**options)
     result = []
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/_mapping.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/_mapping.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/_mapping.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/_mapping.py	2024-08-15 06:46:07.174821873 -0400
@@ -46,7 +46,7 @@
     'BSTLexer': ('pip._vendor.pygments.lexers.bibtex', 'BST', ('bst', 'bst-pybtex'), ('*.bst',), ()),
     'BareLexer': ('pip._vendor.pygments.lexers.bare', 'BARE', ('bare',), ('*.bare',), ()),
     'BaseMakefileLexer': ('pip._vendor.pygments.lexers.make', 'Base Makefile', ('basemake',), (), ()),
-    'BashLexer': ('pip._vendor.pygments.lexers.shell', 'Bash', ('bash', 'sh', 'ksh', 'zsh', 'shell'), ('*.sh', '*.ksh', '*.bash', '*.ebuild', '*.eclass', '*.exheres-0', '*.exlib', '*.zsh', '.bashrc', 'bashrc', '.bash_*', 'bash_*', 'zshrc', '.zshrc', '.kshrc', 'kshrc', 'PKGBUILD'), ('application/x-sh', 'application/x-shellscript', 'text/x-shellscript')),
+    'BashLexer': ('pip._vendor.pygments.lexers.shell', 'Bash', ('bash', 'sh', 'ksh', 'zsh', 'shell', 'openrc'), ('*.sh', '*.ksh', '*.bash', '*.ebuild', '*.eclass', '*.exheres-0', '*.exlib', '*.zsh', '.bashrc', 'bashrc', '.bash_*', 'bash_*', 'zshrc', '.zshrc', '.kshrc', 'kshrc', 'PKGBUILD'), ('application/x-sh', 'application/x-shellscript', 'text/x-shellscript')),
     'BashSessionLexer': ('pip._vendor.pygments.lexers.shell', 'Bash Session', ('console', 'shell-session'), ('*.sh-session', '*.shell-session'), ('application/x-shell-session', 'application/x-sh-session')),
     'BatchLexer': ('pip._vendor.pygments.lexers.shell', 'Batchfile', ('batch', 'bat', 'dosbatch', 'winbatch'), ('*.bat', '*.cmd'), ('application/x-dos-batch',)),
     'BddLexer': ('pip._vendor.pygments.lexers.bdd', 'Bdd', ('bdd',), ('*.feature',), ('text/x-bdd',)),
@@ -128,7 +128,7 @@
     'DaxLexer': ('pip._vendor.pygments.lexers.dax', 'Dax', ('dax',), ('*.dax',), ()),
     'DebianControlLexer': ('pip._vendor.pygments.lexers.installers', 'Debian Control file', ('debcontrol', 'control'), ('control',), ()),
     'DelphiLexer': ('pip._vendor.pygments.lexers.pascal', 'Delphi', ('delphi', 'pas', 'pascal', 'objectpascal'), ('*.pas', '*.dpr'), ('text/x-pascal',)),
-    'DesktopLexer': ('pip._vendor.pygments.lexers.configs', 'Desktop file', ('desktop',), ('*.desktop',), ()),
+    'DesktopLexer': ('pip._vendor.pygments.lexers.configs', 'Desktop file', ('desktop',), ('*.desktop',), ('application/x-desktop',)),
     'DevicetreeLexer': ('pip._vendor.pygments.lexers.devicetree', 'Devicetree', ('devicetree', 'dts'), ('*.dts', '*.dtsi'), ('text/x-c',)),
     'DgLexer': ('pip._vendor.pygments.lexers.python', 'dg', ('dg',), ('*.dg',), ('text/x-dg',)),
     'DiffLexer': ('pip._vendor.pygments.lexers.diff', 'Diff', ('diff', 'udiff'), ('*.diff', '*.patch'), ('text/x-diff', 'text/x-patch')),
@@ -216,8 +216,8 @@
     'HtmlSmartyLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Smarty', ('html+smarty',), (), ('text/html+smarty',)),
     'HttpLexer': ('pip._vendor.pygments.lexers.textfmts', 'HTTP', ('http',), (), ()),
     'HxmlLexer': ('pip._vendor.pygments.lexers.haxe', 'Hxml', ('haxeml', 'hxml'), ('*.hxml',), ()),
-    'HyLexer': ('pip._vendor.pygments.lexers.lisp', 'Hy', ('hylang',), ('*.hy',), ('text/x-hy', 'application/x-hy')),
-    'HybrisLexer': ('pip._vendor.pygments.lexers.scripting', 'Hybris', ('hybris', 'hy'), ('*.hy', '*.hyb'), ('text/x-hybris', 'application/x-hybris')),
+    'HyLexer': ('pip._vendor.pygments.lexers.lisp', 'Hy', ('hylang', 'hy'), ('*.hy',), ('text/x-hy', 'application/x-hy')),
+    'HybrisLexer': ('pip._vendor.pygments.lexers.scripting', 'Hybris', ('hybris',), ('*.hyb',), ('text/x-hybris', 'application/x-hybris')),
     'IDLLexer': ('pip._vendor.pygments.lexers.idl', 'IDL', ('idl',), ('*.pro',), ('text/idl',)),
     'IconLexer': ('pip._vendor.pygments.lexers.unicon', 'Icon', ('icon',), ('*.icon', '*.ICON'), ()),
     'IdrisLexer': ('pip._vendor.pygments.lexers.haskell', 'Idris', ('idris', 'idr'), ('*.idr',), ('text/x-idris',)),
@@ -234,6 +234,7 @@
     'JMESPathLexer': ('pip._vendor.pygments.lexers.jmespath', 'JMESPath', ('jmespath', 'jp'), ('*.jp',), ()),
     'JSLTLexer': ('pip._vendor.pygments.lexers.jslt', 'JSLT', ('jslt',), ('*.jslt',), ('text/x-jslt',)),
     'JagsLexer': ('pip._vendor.pygments.lexers.modeling', 'JAGS', ('jags',), ('*.jag', '*.bug'), ()),
+    'JanetLexer': ('pip._vendor.pygments.lexers.lisp', 'Janet', ('janet',), ('*.janet', '*.jdn'), ('text/x-janet', 'application/x-janet')),
     'JasminLexer': ('pip._vendor.pygments.lexers.jvm', 'Jasmin', ('jasmin', 'jasminxt'), ('*.j',), ()),
     'JavaLexer': ('pip._vendor.pygments.lexers.jvm', 'Java', ('java',), ('*.java',), ('text/x-java',)),
     'JavascriptDjangoLexer': ('pip._vendor.pygments.lexers.templates', 'JavaScript+Django/Jinja', ('javascript+django', 'js+django', 'javascript+jinja', 'js+jinja'), ('*.js.j2', '*.js.jinja2'), ('application/x-javascript+django', 'application/x-javascript+jinja', 'text/x-javascript+django', 'text/x-javascript+jinja', 'text/javascript+django', 'text/javascript+jinja')),
@@ -271,6 +272,7 @@
     'LdaprcLexer': ('pip._vendor.pygments.lexers.ldap', 'LDAP configuration file', ('ldapconf', 'ldaprc'), ('.ldaprc', 'ldaprc', 'ldap.conf'), ('text/x-ldapconf',)),
     'LdifLexer': ('pip._vendor.pygments.lexers.ldap', 'LDIF', ('ldif',), ('*.ldif',), ('text/x-ldif',)),
     'Lean3Lexer': ('pip._vendor.pygments.lexers.lean', 'Lean', ('lean', 'lean3'), ('*.lean',), ('text/x-lean', 'text/x-lean3')),
+    'Lean4Lexer': ('pip._vendor.pygments.lexers.lean', 'Lean4', ('lean4',), ('*.lean',), ('text/x-lean4',)),
     'LessCssLexer': ('pip._vendor.pygments.lexers.css', 'LessCss', ('less',), ('*.less',), ('text/x-less-css',)),
     'LighttpdConfLexer': ('pip._vendor.pygments.lexers.configs', 'Lighttpd configuration file', ('lighttpd', 'lighty'), ('lighttpd.conf',), ('text/x-lighttpd-conf',)),
     'LilyPondLexer': ('pip._vendor.pygments.lexers.lilypond', 'LilyPond', ('lilypond',), ('*.ly',), ()),
@@ -287,6 +289,7 @@
     'LogosLexer': ('pip._vendor.pygments.lexers.objective', 'Logos', ('logos',), ('*.x', '*.xi', '*.xm', '*.xmi'), ('text/x-logos',)),
     'LogtalkLexer': ('pip._vendor.pygments.lexers.prolog', 'Logtalk', ('logtalk',), ('*.lgt', '*.logtalk'), ('text/x-logtalk',)),
     'LuaLexer': ('pip._vendor.pygments.lexers.scripting', 'Lua', ('lua',), ('*.lua', '*.wlua'), ('text/x-lua', 'application/x-lua')),
+    'LuauLexer': ('pip._vendor.pygments.lexers.scripting', 'Luau', ('luau',), ('*.luau',), ()),
     'MCFunctionLexer': ('pip._vendor.pygments.lexers.minecraft', 'MCFunction', ('mcfunction', 'mcf'), ('*.mcfunction',), ('text/mcfunction',)),
     'MCSchemaLexer': ('pip._vendor.pygments.lexers.minecraft', 'MCSchema', ('mcschema',), ('*.mcschema',), ('text/mcschema',)),
     'MIMELexer': ('pip._vendor.pygments.lexers.mime', 'MIME', ('mime',), (), ('multipart/mixed', 'multipart/related', 'multipart/alternative')),
@@ -314,6 +317,7 @@
     'ModelicaLexer': ('pip._vendor.pygments.lexers.modeling', 'Modelica', ('modelica',), ('*.mo',), ('text/x-modelica',)),
     'Modula2Lexer': ('pip._vendor.pygments.lexers.modula2', 'Modula-2', ('modula2', 'm2'), ('*.def', '*.mod'), ('text/x-modula2',)),
     'MoinWikiLexer': ('pip._vendor.pygments.lexers.markup', 'MoinMoin/Trac Wiki markup', ('trac-wiki', 'moin'), (), ('text/x-trac-wiki',)),
+    'MojoLexer': ('pip._vendor.pygments.lexers.mojo', 'Mojo', ('mojo', '🔥'), ('*.mojo', '*.🔥'), ('text/x-mojo', 'application/x-mojo')),
     'MonkeyLexer': ('pip._vendor.pygments.lexers.basic', 'Monkey', ('monkey',), ('*.monkey',), ('text/x-monkey',)),
     'MonteLexer': ('pip._vendor.pygments.lexers.monte', 'Monte', ('monte',), ('*.mt',), ()),
     'MoonScriptLexer': ('pip._vendor.pygments.lexers.scripting', 'MoonScript', ('moonscript', 'moon'), ('*.moon',), ('text/x-moonscript', 'application/x-moonscript')),
@@ -362,6 +366,7 @@
     'OpaLexer': ('pip._vendor.pygments.lexers.ml', 'Opa', ('opa',), ('*.opa',), ('text/x-opa',)),
     'OpenEdgeLexer': ('pip._vendor.pygments.lexers.business', 'OpenEdge ABL', ('openedge', 'abl', 'progress'), ('*.p', '*.cls'), ('text/x-openedge', 'application/x-openedge')),
     'OpenScadLexer': ('pip._vendor.pygments.lexers.openscad', 'OpenSCAD', ('openscad',), ('*.scad',), ('application/x-openscad',)),
+    'OrgLexer': ('pip._vendor.pygments.lexers.markup', 'Org Mode', ('org', 'orgmode', 'org-mode'), ('*.org',), ('text/org',)),
     'OutputLexer': ('pip._vendor.pygments.lexers.special', 'Text output', ('output',), (), ()),
     'PacmanConfLexer': ('pip._vendor.pygments.lexers.configs', 'PacmanConf', ('pacmanconf',), ('pacman.conf',), ()),
     'PanLexer': ('pip._vendor.pygments.lexers.dsls', 'Pan', ('pan',), ('*.pan',), ()),
@@ -390,6 +395,7 @@
     'ProcfileLexer': ('pip._vendor.pygments.lexers.procfile', 'Procfile', ('procfile',), ('Procfile',), ()),
     'PrologLexer': ('pip._vendor.pygments.lexers.prolog', 'Prolog', ('prolog',), ('*.ecl', '*.prolog', '*.pro', '*.pl'), ('text/x-prolog',)),
     'PromQLLexer': ('pip._vendor.pygments.lexers.promql', 'PromQL', ('promql',), ('*.promql',), ()),
+    'PromelaLexer': ('pip._vendor.pygments.lexers.c_like', 'Promela', ('promela',), ('*.pml', '*.prom', '*.prm', '*.promela', '*.pr', '*.pm'), ('text/x-promela',)),
     'PropertiesLexer': ('pip._vendor.pygments.lexers.configs', 'Properties', ('properties', 'jproperties'), ('*.properties',), ('text/x-java-properties',)),
     'ProtoBufLexer': ('pip._vendor.pygments.lexers.dsls', 'Protocol Buffer', ('protobuf', 'proto'), ('*.proto',), ()),
     'PrqlLexer': ('pip._vendor.pygments.lexers.prql', 'PRQL', ('prql',), ('*.prql',), ('application/prql', 'application/x-prql')),
@@ -400,7 +406,7 @@
     'PyPyLogLexer': ('pip._vendor.pygments.lexers.console', 'PyPy Log', ('pypylog', 'pypy'), ('*.pypylog',), ('application/x-pypylog',)),
     'Python2Lexer': ('pip._vendor.pygments.lexers.python', 'Python 2.x', ('python2', 'py2'), (), ('text/x-python2', 'application/x-python2')),
     'Python2TracebackLexer': ('pip._vendor.pygments.lexers.python', 'Python 2.x Traceback', ('py2tb',), ('*.py2tb',), ('text/x-python2-traceback',)),
-    'PythonConsoleLexer': ('pip._vendor.pygments.lexers.python', 'Python console session', ('pycon',), (), ('text/x-python-doctest',)),
+    'PythonConsoleLexer': ('pip._vendor.pygments.lexers.python', 'Python console session', ('pycon', 'python-console'), (), ('text/x-python-doctest',)),
     'PythonLexer': ('pip._vendor.pygments.lexers.python', 'Python', ('python', 'py', 'sage', 'python3', 'py3', 'bazel', 'starlark'), ('*.py', '*.pyw', '*.pyi', '*.jy', '*.sage', '*.sc', 'SConstruct', 'SConscript', '*.bzl', 'BUCK', 'BUILD', 'BUILD.bazel', 'WORKSPACE', '*.tac'), ('text/x-python', 'application/x-python', 'text/x-python3', 'application/x-python3')),
     'PythonTracebackLexer': ('pip._vendor.pygments.lexers.python', 'Python Traceback', ('pytb', 'py3tb'), ('*.pytb', '*.py3tb'), ('text/x-python-traceback', 'text/x-python3-traceback')),
     'PythonUL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'Python+UL4', ('py+ul4',), ('*.pyul4',), ()),
@@ -473,6 +479,7 @@
     'SnobolLexer': ('pip._vendor.pygments.lexers.snobol', 'Snobol', ('snobol',), ('*.snobol',), ('text/x-snobol',)),
     'SnowballLexer': ('pip._vendor.pygments.lexers.dsls', 'Snowball', ('snowball',), ('*.sbl',), ()),
     'SolidityLexer': ('pip._vendor.pygments.lexers.solidity', 'Solidity', ('solidity',), ('*.sol',), ()),
+    'SoongLexer': ('pip._vendor.pygments.lexers.soong', 'Soong', ('androidbp', 'bp', 'soong'), ('Android.bp',), ()),
     'SophiaLexer': ('pip._vendor.pygments.lexers.sophia', 'Sophia', ('sophia',), ('*.aes',), ()),
     'SourcePawnLexer': ('pip._vendor.pygments.lexers.pawn', 'SourcePawn', ('sp',), ('*.sp',), ('text/x-sourcepawn',)),
     'SourcesListLexer': ('pip._vendor.pygments.lexers.installers', 'Debian Sourcelist', ('debsources', 'sourceslist', 'sources.list'), ('sources.list',), ()),
@@ -494,6 +501,7 @@
     'TAPLexer': ('pip._vendor.pygments.lexers.testing', 'TAP', ('tap',), ('*.tap',), ()),
     'TNTLexer': ('pip._vendor.pygments.lexers.tnt', 'Typographic Number Theory', ('tnt',), ('*.tnt',), ()),
     'TOMLLexer': ('pip._vendor.pygments.lexers.configs', 'TOML', ('toml',), ('*.toml', 'Pipfile', 'poetry.lock'), ('application/toml',)),
+    'TactLexer': ('pip._vendor.pygments.lexers.tact', 'Tact', ('tact',), ('*.tact',), ()),
     'Tads3Lexer': ('pip._vendor.pygments.lexers.int_fiction', 'TADS 3', ('tads3',), ('*.t',), ()),
     'TalLexer': ('pip._vendor.pygments.lexers.tal', 'Tal', ('tal', 'uxntal'), ('*.tal',), ('text/x-uxntal',)),
     'TasmLexer': ('pip._vendor.pygments.lexers.asm', 'TASM', ('tasm',), ('*.asm', '*.ASM', '*.tasm'), ('text/x-tasm',)),
@@ -523,6 +531,7 @@
     'TypoScriptCssDataLexer': ('pip._vendor.pygments.lexers.typoscript', 'TypoScriptCssData', ('typoscriptcssdata',), (), ()),
     'TypoScriptHtmlDataLexer': ('pip._vendor.pygments.lexers.typoscript', 'TypoScriptHtmlData', ('typoscripthtmldata',), (), ()),
     'TypoScriptLexer': ('pip._vendor.pygments.lexers.typoscript', 'TypoScript', ('typoscript',), ('*.typoscript',), ('text/x-typoscript',)),
+    'TypstLexer': ('pip._vendor.pygments.lexers.typst', 'Typst', ('typst',), ('*.typ',), ('text/x-typst',)),
     'UL4Lexer': ('pip._vendor.pygments.lexers.ul4', 'UL4', ('ul4',), ('*.ul4',), ()),
     'UcodeLexer': ('pip._vendor.pygments.lexers.unicon', 'ucode', ('ucode',), ('*.u', '*.u1', '*.u2'), ()),
     'UniconLexer': ('pip._vendor.pygments.lexers.unicon', 'Unicon', ('unicon',), ('*.icn',), ('text/unicon',)),
@@ -537,7 +546,7 @@
     'VGLLexer': ('pip._vendor.pygments.lexers.dsls', 'VGL', ('vgl',), ('*.rpf',), ()),
     'ValaLexer': ('pip._vendor.pygments.lexers.c_like', 'Vala', ('vala', 'vapi'), ('*.vala', '*.vapi'), ('text/x-vala',)),
     'VbNetAspxLexer': ('pip._vendor.pygments.lexers.dotnet', 'aspx-vb', ('aspx-vb',), ('*.aspx', '*.asax', '*.ascx', '*.ashx', '*.asmx', '*.axd'), ()),
-    'VbNetLexer': ('pip._vendor.pygments.lexers.dotnet', 'VB.net', ('vb.net', 'vbnet', 'lobas', 'oobas', 'sobas'), ('*.vb', '*.bas'), ('text/x-vbnet', 'text/x-vba')),
+    'VbNetLexer': ('pip._vendor.pygments.lexers.dotnet', 'VB.net', ('vb.net', 'vbnet', 'lobas', 'oobas', 'sobas', 'visual-basic', 'visualbasic'), ('*.vb', '*.bas'), ('text/x-vbnet', 'text/x-vba')),
     'VelocityHtmlLexer': ('pip._vendor.pygments.lexers.templates', 'HTML+Velocity', ('html+velocity',), (), ('text/html+velocity',)),
     'VelocityLexer': ('pip._vendor.pygments.lexers.templates', 'Velocity', ('velocity',), ('*.vm', '*.fhtml'), ()),
     'VelocityXmlLexer': ('pip._vendor.pygments.lexers.templates', 'XML+Velocity', ('xml+velocity',), (), ('application/xml+velocity',)),
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/python.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/python.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/python.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/lexers/python.py	2024-08-15 06:46:07.174821873 -0400
@@ -4,15 +4,14 @@
 
     Lexers for Python and related languages.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
-import re
 import keyword
 
-from pip._vendor.pygments.lexer import DelegatingLexer, Lexer, RegexLexer, include, \
-    bygroups, using, default, words, combined, do_insertions, this, line_re
+from pip._vendor.pygments.lexer import DelegatingLexer, RegexLexer, include, \
+    bygroups, using, default, words, combined, this
 from pip._vendor.pygments.util import get_bool_opt, shebang_matches
 from pip._vendor.pygments.token import Text, Comment, Operator, Keyword, Name, String, \
     Number, Punctuation, Generic, Other, Error, Whitespace
@@ -27,8 +26,6 @@
     """
     For Python source code (version 3.x).
 
-    .. versionadded:: 0.10
-
     .. versionchanged:: 2.5
        This is now the default ``PythonLexer``.  It is still available as the
        alias ``Python3Lexer``.
@@ -61,8 +58,9 @@
     ]
     mimetypes = ['text/x-python', 'application/x-python',
                  'text/x-python3', 'application/x-python3']
+    version_added = '0.10'
 
-    uni_name = "[%s][%s]*" % (uni.xid_start, uni.xid_continue)
+    uni_name = f"[{uni.xid_start}][{uni.xid_continue}]*"
 
     def innerstring_rules(ttype):
         return [
@@ -224,7 +222,8 @@
              r'(match|case)\b'         # a possible keyword
              r'(?![ \t]*(?:'           # not followed by...
              r'[:,;=^&|@~)\]}]|(?:' +  # characters and keywords that mean this isn't
-             r'|'.join(keyword.kwlist) + r')\b))',                 # pattern matching
+                                       # pattern matching (but None/True/False is ok)
+             r'|'.join(k for k in keyword.kwlist if k[0].islower()) + r')\b))',
              bygroups(Text, Keyword), 'soft-keywords-inner'),
         ],
         'soft-keywords-inner': [
@@ -429,6 +428,7 @@
     aliases = ['python2', 'py2']
     filenames = []  # now taken over by PythonLexer (3.x)
     mimetypes = ['text/x-python2', 'application/x-python2']
+    version_added = ''
 
     def innerstring_rules(ttype):
         return [
@@ -637,7 +637,7 @@
 
 class _PythonConsoleLexerBase(RegexLexer):
     name = 'Python console session'
-    aliases = ['pycon']
+    aliases = ['pycon', 'python-console']
     mimetypes = ['text/x-python-doctest']
 
     """Auxiliary lexer for `PythonConsoleLexer`.
@@ -696,8 +696,10 @@
     """
 
     name = 'Python console session'
-    aliases = ['pycon']
+    aliases = ['pycon', 'python-console']
     mimetypes = ['text/x-python-doctest']
+    url = 'https://python.org'
+    version_added = ''
 
     def __init__(self, **options):
         python3 = get_bool_opt(options, 'python3', True)
@@ -721,8 +723,6 @@
     """
     For Python 3.x tracebacks, with support for chained exceptions.
 
-    .. versionadded:: 1.0
-
     .. versionchanged:: 2.5
        This is now the default ``PythonTracebackLexer``.  It is still available
        as the alias ``Python3TracebackLexer``.
@@ -732,6 +732,8 @@
     aliases = ['pytb', 'py3tb']
     filenames = ['*.pytb', '*.py3tb']
     mimetypes = ['text/x-python-traceback', 'text/x-python3-traceback']
+    url = 'https://python.org'
+    version_added = '1.0'
 
     tokens = {
         'root': [
@@ -778,8 +780,6 @@
     """
     For Python tracebacks.
 
-    .. versionadded:: 0.7
-
     .. versionchanged:: 2.5
        This class has been renamed from ``PythonTracebackLexer``.
        ``PythonTracebackLexer`` now refers to the Python 3 variant.
@@ -789,6 +789,8 @@
     aliases = ['py2tb']
     filenames = ['*.py2tb']
     mimetypes = ['text/x-python2-traceback']
+    url = 'https://python.org'
+    version_added = '0.7'
 
     tokens = {
         'root': [
@@ -825,8 +827,6 @@
 class CythonLexer(RegexLexer):
     """
     For Pyrex and Cython source code.
-
-    .. versionadded:: 1.1
     """
 
     name = 'Cython'
@@ -834,6 +834,7 @@
     aliases = ['cython', 'pyx', 'pyrex']
     filenames = ['*.pyx', '*.pxd', '*.pxi']
     mimetypes = ['text/x-cython', 'application/x-cython']
+    version_added = '1.1'
 
     tokens = {
         'root': [
@@ -1007,13 +1008,13 @@
     Lexer for dg,
     a functional and object-oriented programming language
     running on the CPython 3 VM.
-
-    .. versionadded:: 1.6
     """
     name = 'dg'
     aliases = ['dg']
     filenames = ['*.dg']
     mimetypes = ['text/x-dg']
+    url = 'http://pyos.github.io/dg'
+    version_added = '1.6'
 
     tokens = {
         'root': [
@@ -1104,13 +1105,12 @@
 class NumPyLexer(PythonLexer):
     """
     A Python lexer recognizing Numerical Python builtins.
-
-    .. versionadded:: 0.10
     """
 
     name = 'NumPy'
     url = 'https://numpy.org/'
     aliases = ['numpy']
+    version_added = '0.10'
 
     # override the mimetypes to not inherit them from python
     mimetypes = []
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/__main__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/__main__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/__main__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/__main__.py	2024-08-15 06:46:07.172821873 -0400
@@ -4,7 +4,7 @@
 
     Main entry point for ``python -m pygments``.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/modeline.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/modeline.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/modeline.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/modeline.py	2024-08-15 06:46:07.172821873 -0400
@@ -4,7 +4,7 @@
 
     A simple modeline parser (based on pymodeline).
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -19,7 +19,7 @@
 ''', re.VERBOSE)
 
 
-def get_filetype_from_line(l):
+def get_filetype_from_line(l): # noqa: E741
     m = modeline_re.search(l)
     if m:
         return m.group(1)
@@ -30,8 +30,8 @@
     Scan the buffer for modelines and return filetype if one is found.
     """
     lines = buf.splitlines()
-    for l in lines[-1:-max_lines-1:-1]:
-        ret = get_filetype_from_line(l)
+    for line in lines[-1:-max_lines-1:-1]:
+        ret = get_filetype_from_line(line)
         if ret:
             return ret
     for i in range(max_lines, -1, -1):
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/plugin.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/plugin.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/plugin.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/plugin.py	2024-08-15 06:46:07.172821873 -0400
@@ -2,12 +2,7 @@
     pygments.plugin
     ~~~~~~~~~~~~~~~
 
-    Pygments plugin interface. By default, this tries to use
-    ``importlib.metadata``, which is in the Python standard
-    library since Python 3.8, or its ``importlib_metadata``
-    backport for earlier versions of Python. It falls back on
-    ``pkg_resources`` if not found. Finally, if ``pkg_resources``
-    is not found either, no plugins are loaded at all.
+    Pygments plugin interface.
 
     lexer plugins::
 
@@ -34,9 +29,10 @@
         yourfilter = yourfilter:YourFilter
 
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
+from importlib.metadata import entry_points
 
 LEXER_ENTRY_POINT = 'pygments.lexers'
 FORMATTER_ENTRY_POINT = 'pygments.formatters'
@@ -45,18 +41,6 @@
 
 
 def iter_entry_points(group_name):
-    try:
-        from importlib.metadata import entry_points
-    except ImportError:
-        try:
-            from importlib_metadata import entry_points
-        except ImportError:
-            try:
-                from pip._vendor.pkg_resources import iter_entry_points
-            except (ImportError, OSError):
-                return []
-            else:
-                return iter_entry_points(group_name)
     groups = entry_points()
     if hasattr(groups, 'select'):
         # New interface in Python 3.10 and newer versions of the
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/regexopt.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/regexopt.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/regexopt.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/regexopt.py	2024-08-15 06:46:07.172821873 -0400
@@ -5,7 +5,7 @@
     An algorithm that generates optimized regexes for matching long lists of
     literal strings.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/scanner.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/scanner.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/scanner.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/scanner.py	2024-08-15 06:46:07.173821873 -0400
@@ -11,7 +11,7 @@
     Have a look at the `DelphiLexer` to get an idea of how to use
     this scanner.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 import re
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/sphinxext.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/sphinxext.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/sphinxext.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/sphinxext.py	2024-08-15 06:46:07.173821873 -0400
@@ -5,7 +5,7 @@
     Sphinx extension to generate automatic documentation of lexers,
     formatters and filters.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -33,6 +33,8 @@
 
     %s
 
+    %s
+
 '''
 
 FMTERDOC = '''
@@ -119,11 +121,11 @@
         def write_row(*columns):
             """Format a table row"""
             out = []
-            for l, c in zip(column_lengths, columns):
-                if c:
-                    out.append(c.ljust(l))
+            for length, col in zip(column_lengths, columns):
+                if col:
+                    out.append(col.ljust(length))
                 else:
-                    out.append(' '*l)
+                    out.append(' '*length)
 
             return ' '.join(out)
 
@@ -160,7 +162,7 @@
             self.filenames.add(mod.__file__)
             cls = getattr(mod, classname)
             if not cls.__doc__:
-                print("Warning: %s does not have a docstring." % classname)
+                print(f"Warning: {classname} does not have a docstring.")
             docstring = cls.__doc__
             if isinstance(docstring, bytes):
                 docstring = docstring.decode('utf8')
@@ -182,12 +184,18 @@
                     for line in content.splitlines():
                         docstring += f'          {line}\n'
 
+            if cls.version_added:
+                version_line = f'.. versionadded:: {cls.version_added}'
+            else:
+                version_line = ''
+
             modules.setdefault(module, []).append((
                 classname,
                 ', '.join(data[2]) or 'None',
                 ', '.join(data[3]).replace('*', '\\*').replace('_', '\\') or 'None',
                 ', '.join(data[4]) or 'None',
-                docstring))
+                docstring,
+                version_line))
             if module not in moduledocstrings:
                 moddoc = mod.__doc__
                 if isinstance(moddoc, bytes):
@@ -196,7 +204,7 @@
 
         for module, lexers in sorted(modules.items(), key=lambda x: x[0]):
             if moduledocstrings[module] is None:
-                raise Exception("Missing docstring for %s" % (module,))
+                raise Exception(f"Missing docstring for {module}")
             heading = moduledocstrings[module].splitlines()[4].strip().rstrip('.')
             out.append(MODULEDOC % (module, heading, '-'*len(heading)))
             for data in lexers:
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/style.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/style.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/style.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/style.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     Basic style object.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -76,7 +76,7 @@
                 return ''
             elif text.startswith('var') or text.startswith('calc'):
                 return text
-            assert False, "wrong color format %r" % text
+            assert False, f"wrong color format {text!r}"
 
         _styles = obj._styles = {}
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/styles/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/styles/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/styles/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/styles/__init__.py	2024-08-15 06:46:07.174821873 -0400
@@ -4,7 +4,7 @@
 
     Contains built-in styles.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -44,13 +44,13 @@
     try:
         mod = __import__(mod, None, None, [cls])
     except ImportError:
-        raise ClassNotFound("Could not find style module %r" % mod +
+        raise ClassNotFound(f"Could not find style module {mod!r}" +
                             (builtin and ", though it should be builtin")
                             + ".")
     try:
         return getattr(mod, cls)
     except AttributeError:
-        raise ClassNotFound("Could not find style class %r in style module." % cls)
+        raise ClassNotFound(f"Could not find style class {cls!r} in style module.")
 
 
 def get_all_styles():
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/styles/_mapping.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/styles/_mapping.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/styles/_mapping.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/styles/_mapping.py	2024-08-15 06:46:07.174821873 -0400
@@ -9,6 +9,7 @@
     'AutumnStyle': ('pygments.styles.autumn', 'autumn', ()),
     'BlackWhiteStyle': ('pygments.styles.bw', 'bw', ()),
     'BorlandStyle': ('pygments.styles.borland', 'borland', ()),
+    'CoffeeStyle': ('pygments.styles.coffee', 'coffee', ()),
     'ColorfulStyle': ('pygments.styles.colorful', 'colorful', ()),
     'DefaultStyle': ('pygments.styles.default', 'default', ()),
     'DraculaStyle': ('pygments.styles.dracula', 'dracula', ()),
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/token.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/token.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/token.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/token.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     Basic token types and the standard tokens.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/unistring.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/unistring.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/unistring.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/unistring.py	2024-08-15 06:46:07.173821873 -0400
@@ -7,7 +7,7 @@
 
     Inspired by chartypes_create.py from the MoinMoin project.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -104,7 +104,7 @@
         if a == b:
             yield a
         else:
-            yield '%s-%s' % (a, b)
+            yield f'{a}-{b}'
 
 
 if __name__ == '__main__':  # pragma: no cover
@@ -141,13 +141,13 @@
 
         for cat in sorted(categories):
             val = ''.join(_handle_runs(categories[cat]))
-            fp.write('%s = %a\n\n' % (cat, val))
+            fp.write(f'{cat} = {val!a}\n\n')
 
         cats = sorted(categories)
         cats.remove('xid_start')
         cats.remove('xid_continue')
-        fp.write('cats = %r\n\n' % cats)
+        fp.write(f'cats = {cats!r}\n\n')
 
-        fp.write('# Generated from unidata %s\n\n' % (unicodedata.unidata_version,))
+        fp.write(f'# Generated from unidata {unicodedata.unidata_version}\n\n')
 
         fp.write(footer)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/util.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/util.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/pygments/util.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/pygments/util.py	2024-08-15 06:46:07.173821873 -0400
@@ -4,7 +4,7 @@
 
     Utility functions.
 
-    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
+    :copyright: Copyright 2006-2024 by the Pygments team, see AUTHORS.
     :license: BSD, see LICENSE for details.
 """
 
@@ -46,8 +46,7 @@
     if normcase:
         string = string.lower()
     if string not in allowed:
-        raise OptionError('Value for option %s must be one of %s' %
-                          (optname, ', '.join(map(str, allowed))))
+        raise OptionError('Value for option {} must be one of {}'.format(optname, ', '.join(map(str, allowed))))
     return string
 
 
@@ -69,17 +68,15 @@
     elif isinstance(string, int):
         return bool(string)
     elif not isinstance(string, str):
-        raise OptionError('Invalid type %r for option %s; use '
-                          '1/0, yes/no, true/false, on/off' % (
-                              string, optname))
+        raise OptionError(f'Invalid type {string!r} for option {optname}; use '
+                          '1/0, yes/no, true/false, on/off')
     elif string.lower() in ('1', 'yes', 'true', 'on'):
         return True
     elif string.lower() in ('0', 'no', 'false', 'off'):
         return False
     else:
-        raise OptionError('Invalid value %r for option %s; use '
-                          '1/0, yes/no, true/false, on/off' % (
-                              string, optname))
+        raise OptionError(f'Invalid value {string!r} for option {optname}; use '
+                          '1/0, yes/no, true/false, on/off')
 
 
 def get_int_opt(options, optname, default=None):
@@ -88,13 +85,11 @@
     try:
         return int(string)
     except TypeError:
-        raise OptionError('Invalid type %r for option %s; you '
-                          'must give an integer value' % (
-                              string, optname))
+        raise OptionError(f'Invalid type {string!r} for option {optname}; you '
+                          'must give an integer value')
     except ValueError:
-        raise OptionError('Invalid value %r for option %s; you '
-                          'must give an integer value' % (
-                              string, optname))
+        raise OptionError(f'Invalid value {string!r} for option {optname}; you '
+                          'must give an integer value')
 
 def get_list_opt(options, optname, default=None):
     """
@@ -108,9 +103,8 @@
     elif isinstance(val, (list, tuple)):
         return list(val)
     else:
-        raise OptionError('Invalid type %r for option %s; you '
-                          'must give a list value' % (
-                              val, optname))
+        raise OptionError(f'Invalid type {val!r} for option {optname}; you '
+                          'must give a list value')
 
 
 def docstring_headline(obj):
@@ -181,7 +175,7 @@
                      if x and not x.startswith('-')][-1]
         except IndexError:
             return False
-        regex = re.compile(r'^%s(\.(exe|cmd|bat|bin))?$' % regex, re.IGNORECASE)
+        regex = re.compile(rf'^{regex}(\.(exe|cmd|bat|bin))?$', re.IGNORECASE)
         if regex.search(found) is not None:
             return True
     return False
Only in /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor: tenacity
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/typing_extensions.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/typing_extensions.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/typing_extensions.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/typing_extensions.py	2024-08-15 06:46:07.169821873 -0400
@@ -1,6 +1,7 @@
 import abc
 import collections
 import collections.abc
+import contextlib
 import functools
 import inspect
 import operator
@@ -116,6 +117,7 @@
     'MutableMapping',
     'MutableSequence',
     'MutableSet',
+    'NoDefault',
     'Optional',
     'Pattern',
     'Reversible',
@@ -134,6 +136,7 @@
 # for backward compatibility
 PEP_560 = True
 GenericMeta = type
+_PEP_696_IMPLEMENTED = sys.version_info >= (3, 13, 0, "beta")
 
 # The functions below are modified copies of typing internal helpers.
 # They are needed by _ProtocolMeta and they provide support for PEP 646.
@@ -406,17 +409,96 @@
 AsyncIterable = typing.AsyncIterable
 AsyncIterator = typing.AsyncIterator
 Deque = typing.Deque
-ContextManager = typing.ContextManager
-AsyncContextManager = typing.AsyncContextManager
 DefaultDict = typing.DefaultDict
 OrderedDict = typing.OrderedDict
 Counter = typing.Counter
 ChainMap = typing.ChainMap
-AsyncGenerator = typing.AsyncGenerator
 Text = typing.Text
 TYPE_CHECKING = typing.TYPE_CHECKING
 
 
+if sys.version_info >= (3, 13, 0, "beta"):
+    from typing import AsyncContextManager, AsyncGenerator, ContextManager, Generator
+else:
+    def _is_dunder(attr):
+        return attr.startswith('__') and attr.endswith('__')
+
+    # Python <3.9 doesn't have typing._SpecialGenericAlias
+    _special_generic_alias_base = getattr(
+        typing, "_SpecialGenericAlias", typing._GenericAlias
+    )
+
+    class _SpecialGenericAlias(_special_generic_alias_base, _root=True):
+        def __init__(self, origin, nparams, *, inst=True, name=None, defaults=()):
+            if _special_generic_alias_base is typing._GenericAlias:
+                # Python <3.9
+                self.__origin__ = origin
+                self._nparams = nparams
+                super().__init__(origin, nparams, special=True, inst=inst, name=name)
+            else:
+                # Python >= 3.9
+                super().__init__(origin, nparams, inst=inst, name=name)
+            self._defaults = defaults
+
+        def __setattr__(self, attr, val):
+            allowed_attrs = {'_name', '_inst', '_nparams', '_defaults'}
+            if _special_generic_alias_base is typing._GenericAlias:
+                # Python <3.9
+                allowed_attrs.add("__origin__")
+            if _is_dunder(attr) or attr in allowed_attrs:
+                object.__setattr__(self, attr, val)
+            else:
+                setattr(self.__origin__, attr, val)
+
+        @typing._tp_cache
+        def __getitem__(self, params):
+            if not isinstance(params, tuple):
+                params = (params,)
+            msg = "Parameters to generic types must be types."
+            params = tuple(typing._type_check(p, msg) for p in params)
+            if (
+                self._defaults
+                and len(params) < self._nparams
+                and len(params) + len(self._defaults) >= self._nparams
+            ):
+                params = (*params, *self._defaults[len(params) - self._nparams:])
+            actual_len = len(params)
+
+            if actual_len != self._nparams:
+                if self._defaults:
+                    expected = f"at least {self._nparams - len(self._defaults)}"
+                else:
+                    expected = str(self._nparams)
+                if not self._nparams:
+                    raise TypeError(f"{self} is not a generic class")
+                raise TypeError(
+                    f"Too {'many' if actual_len > self._nparams else 'few'}"
+                    f" arguments for {self};"
+                    f" actual {actual_len}, expected {expected}"
+                )
+            return self.copy_with(params)
+
+    _NoneType = type(None)
+    Generator = _SpecialGenericAlias(
+        collections.abc.Generator, 3, defaults=(_NoneType, _NoneType)
+    )
+    AsyncGenerator = _SpecialGenericAlias(
+        collections.abc.AsyncGenerator, 2, defaults=(_NoneType,)
+    )
+    ContextManager = _SpecialGenericAlias(
+        contextlib.AbstractContextManager,
+        2,
+        name="ContextManager",
+        defaults=(typing.Optional[bool],)
+    )
+    AsyncContextManager = _SpecialGenericAlias(
+        contextlib.AbstractAsyncContextManager,
+        2,
+        name="AsyncContextManager",
+        defaults=(typing.Optional[bool],)
+    )
+
+
 _PROTO_ALLOWLIST = {
     'collections.abc': [
         'Callable', 'Awaitable', 'Iterable', 'Iterator', 'AsyncIterable',
@@ -427,23 +509,11 @@
 }
 
 
-_EXCLUDED_ATTRS = {
-    "__abstractmethods__", "__annotations__", "__weakref__", "_is_protocol",
-    "_is_runtime_protocol", "__dict__", "__slots__", "__parameters__",
-    "__orig_bases__", "__module__", "_MutableMapping__marker", "__doc__",
-    "__subclasshook__", "__orig_class__", "__init__", "__new__",
-    "__protocol_attrs__", "__non_callable_proto_members__",
-    "__match_args__",
+_EXCLUDED_ATTRS = frozenset(typing.EXCLUDED_ATTRIBUTES) | {
+    "__match_args__", "__protocol_attrs__", "__non_callable_proto_members__",
+    "__final__",
 }
 
-if sys.version_info >= (3, 9):
-    _EXCLUDED_ATTRS.add("__class_getitem__")
-
-if sys.version_info >= (3, 12):
-    _EXCLUDED_ATTRS.add("__type_params__")
-
-_EXCLUDED_ATTRS = frozenset(_EXCLUDED_ATTRS)
-
 
 def _get_protocol_attrs(cls):
     attrs = set()
@@ -669,13 +739,18 @@
         not their type signatures!
         """
         if not issubclass(cls, typing.Generic) or not getattr(cls, '_is_protocol', False):
-            raise TypeError('@runtime_checkable can be only applied to protocol classes,'
-                            ' got %r' % cls)
+            raise TypeError(f'@runtime_checkable can be only applied to protocol classes,'
+                            f' got {cls!r}')
         cls._is_runtime_protocol = True
 
-        # Only execute the following block if it's a typing_extensions.Protocol class.
-        # typing.Protocol classes don't need it.
-        if isinstance(cls, _ProtocolMeta):
+        # typing.Protocol classes on <=3.11 break if we execute this block,
+        # because typing.Protocol classes on <=3.11 don't have a
+        # `__protocol_attrs__` attribute, and this block relies on the
+        # `__protocol_attrs__` attribute. Meanwhile, typing.Protocol classes on 3.12.2+
+        # break if we *don't* execute this block, because *they* assume that all
+        # protocol classes have a `__non_callable_proto_members__` attribute
+        # (which this block sets)
+        if isinstance(cls, _ProtocolMeta) or sys.version_info >= (3, 12, 2):
             # PEP 544 prohibits using issubclass()
             # with protocols that have non-method members.
             # See gh-113320 for why we compute this attribute here,
@@ -867,7 +942,13 @@
                 tp_dict.__orig_bases__ = bases
 
             annotations = {}
-            own_annotations = ns.get('__annotations__', {})
+            if "__annotations__" in ns:
+                own_annotations = ns["__annotations__"]
+            elif "__annotate__" in ns:
+                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
+                own_annotations = ns["__annotate__"](1)
+            else:
+                own_annotations = {}
             msg = "TypedDict('Name', {f0: t0, f1: t1, ...}); each t must be a type"
             if _TAKES_MODULE:
                 own_annotations = {
@@ -1190,7 +1271,7 @@
 
         def __reduce__(self):
             return operator.getitem, (
-                Annotated, (self.__origin__,) + self.__metadata__
+                Annotated, (self.__origin__, *self.__metadata__)
             )
 
         def __eq__(self, other):
@@ -1316,7 +1397,7 @@
             get_args(Callable[[], T][int]) == ([], int)
         """
         if isinstance(tp, _AnnotatedAlias):
-            return (tp.__origin__,) + tp.__metadata__
+            return (tp.__origin__, *tp.__metadata__)
         if isinstance(tp, (typing._GenericAlias, _typing_GenericAlias)):
             if getattr(tp, "_special", False):
                 return ()
@@ -1362,17 +1443,37 @@
     )
 
 
+if hasattr(typing, "NoDefault"):
+    NoDefault = typing.NoDefault
+else:
+    class NoDefaultTypeMeta(type):
+        def __setattr__(cls, attr, value):
+            # TypeError is consistent with the behavior of NoneType
+            raise TypeError(
+                f"cannot set {attr!r} attribute of immutable type {cls.__name__!r}"
+            )
+
+    class NoDefaultType(metaclass=NoDefaultTypeMeta):
+        """The type of the NoDefault singleton."""
+
+        __slots__ = ()
+
+        def __new__(cls):
+            return globals().get("NoDefault") or object.__new__(cls)
+
+        def __repr__(self):
+            return "typing_extensions.NoDefault"
+
+        def __reduce__(self):
+            return "NoDefault"
+
+    NoDefault = NoDefaultType()
+    del NoDefaultType, NoDefaultTypeMeta
+
+
 def _set_default(type_param, default):
-    if isinstance(default, (tuple, list)):
-        type_param.__default__ = tuple((typing._type_check(d, "Default must be a type")
-                                        for d in default))
-    elif default != _marker:
-        if isinstance(type_param, ParamSpec) and default is ...:  # ... not valid <3.11
-            type_param.__default__ = default
-        else:
-            type_param.__default__ = typing._type_check(default, "Default must be a type")
-    else:
-        type_param.__default__ = None
+    type_param.has_default = lambda: default is not NoDefault
+    type_param.__default__ = default
 
 
 def _set_module(typevarlike):
@@ -1395,32 +1496,46 @@
         return isinstance(__instance, cls._backported_typevarlike)
 
 
-# Add default and infer_variance parameters from PEP 696 and 695
-class TypeVar(metaclass=_TypeVarLikeMeta):
-    """Type variable."""
-
-    _backported_typevarlike = typing.TypeVar
-
-    def __new__(cls, name, *constraints, bound=None,
-                covariant=False, contravariant=False,
-                default=_marker, infer_variance=False):
-        if hasattr(typing, "TypeAliasType"):
-            # PEP 695 implemented (3.12+), can pass infer_variance to typing.TypeVar
-            typevar = typing.TypeVar(name, *constraints, bound=bound,
-                                     covariant=covariant, contravariant=contravariant,
-                                     infer_variance=infer_variance)
-        else:
-            typevar = typing.TypeVar(name, *constraints, bound=bound,
-                                     covariant=covariant, contravariant=contravariant)
-            if infer_variance and (covariant or contravariant):
-                raise ValueError("Variance cannot be specified with infer_variance.")
-            typevar.__infer_variance__ = infer_variance
-        _set_default(typevar, default)
-        _set_module(typevar)
-        return typevar
+if _PEP_696_IMPLEMENTED:
+    from typing import TypeVar
+else:
+    # Add default and infer_variance parameters from PEP 696 and 695
+    class TypeVar(metaclass=_TypeVarLikeMeta):
+        """Type variable."""
+
+        _backported_typevarlike = typing.TypeVar
+
+        def __new__(cls, name, *constraints, bound=None,
+                    covariant=False, contravariant=False,
+                    default=NoDefault, infer_variance=False):
+            if hasattr(typing, "TypeAliasType"):
+                # PEP 695 implemented (3.12+), can pass infer_variance to typing.TypeVar
+                typevar = typing.TypeVar(name, *constraints, bound=bound,
+                                         covariant=covariant, contravariant=contravariant,
+                                         infer_variance=infer_variance)
+            else:
+                typevar = typing.TypeVar(name, *constraints, bound=bound,
+                                         covariant=covariant, contravariant=contravariant)
+                if infer_variance and (covariant or contravariant):
+                    raise ValueError("Variance cannot be specified with infer_variance.")
+                typevar.__infer_variance__ = infer_variance
 
-    def __init_subclass__(cls) -> None:
-        raise TypeError(f"type '{__name__}.TypeVar' is not an acceptable base type")
+            _set_default(typevar, default)
+            _set_module(typevar)
+
+            def _tvar_prepare_subst(alias, args):
+                if (
+                    typevar.has_default()
+                    and alias.__parameters__.index(typevar) == len(args)
+                ):
+                    args += (typevar.__default__,)
+                return args
+
+            typevar.__typing_prepare_subst__ = _tvar_prepare_subst
+            return typevar
+
+        def __init_subclass__(cls) -> None:
+            raise TypeError(f"type '{__name__}.TypeVar' is not an acceptable base type")
 
 
 # Python 3.10+ has PEP 612
@@ -1485,8 +1600,12 @@
                 return NotImplemented
             return self.__origin__ == other.__origin__
 
+
+if _PEP_696_IMPLEMENTED:
+    from typing import ParamSpec
+
 # 3.10+
-if hasattr(typing, 'ParamSpec'):
+elif hasattr(typing, 'ParamSpec'):
 
     # Add default parameter - PEP 696
     class ParamSpec(metaclass=_TypeVarLikeMeta):
@@ -1496,7 +1615,7 @@
 
         def __new__(cls, name, *, bound=None,
                     covariant=False, contravariant=False,
-                    infer_variance=False, default=_marker):
+                    infer_variance=False, default=NoDefault):
             if hasattr(typing, "TypeAliasType"):
                 # PEP 695 implemented, can pass infer_variance to typing.TypeVar
                 paramspec = typing.ParamSpec(name, bound=bound,
@@ -1511,6 +1630,24 @@
 
             _set_default(paramspec, default)
             _set_module(paramspec)
+
+            def _paramspec_prepare_subst(alias, args):
+                params = alias.__parameters__
+                i = params.index(paramspec)
+                if i == len(args) and paramspec.has_default():
+                    args = [*args, paramspec.__default__]
+                if i >= len(args):
+                    raise TypeError(f"Too few arguments for {alias}")
+                # Special case where Z[[int, str, bool]] == Z[int, str, bool] in PEP 612.
+                if len(params) == 1 and not typing._is_param_expr(args[0]):
+                    assert i == 0
+                    args = (args,)
+                # Convert lists to tuples to help other libraries cache the results.
+                elif isinstance(args[i], list):
+                    args = (*args[:i], tuple(args[i]), *args[i + 1:])
+                return args
+
+            paramspec.__typing_prepare_subst__ = _paramspec_prepare_subst
             return paramspec
 
         def __init_subclass__(cls) -> None:
@@ -1579,8 +1716,8 @@
             return ParamSpecKwargs(self)
 
         def __init__(self, name, *, bound=None, covariant=False, contravariant=False,
-                     infer_variance=False, default=_marker):
-            super().__init__([self])
+                     infer_variance=False, default=NoDefault):
+            list.__init__(self, [self])
             self.__name__ = name
             self.__covariant__ = bool(covariant)
             self.__contravariant__ = bool(contravariant)
@@ -1674,7 +1811,7 @@
 # 3.10+
 if hasattr(typing, 'Concatenate'):
     Concatenate = typing.Concatenate
-    _ConcatenateGenericAlias = typing._ConcatenateGenericAlias  # noqa: F811
+    _ConcatenateGenericAlias = typing._ConcatenateGenericAlias
 # 3.9
 elif sys.version_info[:2] >= (3, 9):
     @_ExtensionsSpecialForm
@@ -2209,6 +2346,17 @@
     class _UnpackAlias(typing._GenericAlias, _root=True):
         __class__ = typing.TypeVar
 
+        @property
+        def __typing_unpacked_tuple_args__(self):
+            assert self.__origin__ is Unpack
+            assert len(self.__args__) == 1
+            arg, = self.__args__
+            if isinstance(arg, (typing._GenericAlias, _types.GenericAlias)):
+                if arg.__origin__ is not tuple:
+                    raise TypeError("Unpack[...] must be used with a tuple type")
+                return arg.__args__
+            return None
+
     @_UnpackSpecialForm
     def Unpack(self, parameters):
         item = typing._type_check(parameters, f'{self._name} accepts only a single type.')
@@ -2233,7 +2381,20 @@
         return isinstance(obj, _UnpackAlias)
 
 
-if hasattr(typing, "TypeVarTuple"):  # 3.11+
+if _PEP_696_IMPLEMENTED:
+    from typing import TypeVarTuple
+
+elif hasattr(typing, "TypeVarTuple"):  # 3.11+
+
+    def _unpack_args(*args):
+        newargs = []
+        for arg in args:
+            subargs = getattr(arg, '__typing_unpacked_tuple_args__', None)
+            if subargs is not None and not (subargs and subargs[-1] is ...):
+                newargs.extend(subargs)
+            else:
+                newargs.append(arg)
+        return newargs
 
     # Add default parameter - PEP 696
     class TypeVarTuple(metaclass=_TypeVarLikeMeta):
@@ -2241,10 +2402,57 @@
 
         _backported_typevarlike = typing.TypeVarTuple
 
-        def __new__(cls, name, *, default=_marker):
+        def __new__(cls, name, *, default=NoDefault):
             tvt = typing.TypeVarTuple(name)
             _set_default(tvt, default)
             _set_module(tvt)
+
+            def _typevartuple_prepare_subst(alias, args):
+                params = alias.__parameters__
+                typevartuple_index = params.index(tvt)
+                for param in params[typevartuple_index + 1:]:
+                    if isinstance(param, TypeVarTuple):
+                        raise TypeError(
+                            f"More than one TypeVarTuple parameter in {alias}"
+                        )
+
+                alen = len(args)
+                plen = len(params)
+                left = typevartuple_index
+                right = plen - typevartuple_index - 1
+                var_tuple_index = None
+                fillarg = None
+                for k, arg in enumerate(args):
+                    if not isinstance(arg, type):
+                        subargs = getattr(arg, '__typing_unpacked_tuple_args__', None)
+                        if subargs and len(subargs) == 2 and subargs[-1] is ...:
+                            if var_tuple_index is not None:
+                                raise TypeError(
+                                    "More than one unpacked "
+                                    "arbitrary-length tuple argument"
+                                )
+                            var_tuple_index = k
+                            fillarg = subargs[0]
+                if var_tuple_index is not None:
+                    left = min(left, var_tuple_index)
+                    right = min(right, alen - var_tuple_index - 1)
+                elif left + right > alen:
+                    raise TypeError(f"Too few arguments for {alias};"
+                                    f" actual {alen}, expected at least {plen - 1}")
+                if left == alen - right and tvt.has_default():
+                    replacement = _unpack_args(tvt.__default__)
+                else:
+                    replacement = args[left: alen - right]
+
+                return (
+                    *args[:left],
+                    *([fillarg] * (typevartuple_index - left)),
+                    replacement,
+                    *([fillarg] * (plen - right - left - typevartuple_index - 1)),
+                    *args[alen - right:],
+                )
+
+            tvt.__typing_prepare_subst__ = _typevartuple_prepare_subst
             return tvt
 
         def __init_subclass__(self, *args, **kwds):
@@ -2301,7 +2509,7 @@
         def __iter__(self):
             yield self.__unpacked__
 
-        def __init__(self, name, *, default=_marker):
+        def __init__(self, name, *, default=NoDefault):
             self.__name__ = name
             _DefaultMixin.__init__(self, default)
 
@@ -2352,6 +2560,12 @@
         return obj
 
 
+if hasattr(typing, "_ASSERT_NEVER_REPR_MAX_LENGTH"):  # 3.11+
+    _ASSERT_NEVER_REPR_MAX_LENGTH = typing._ASSERT_NEVER_REPR_MAX_LENGTH
+else:  # <=3.10
+    _ASSERT_NEVER_REPR_MAX_LENGTH = 100
+
+
 if hasattr(typing, "assert_never"):  # 3.11+
     assert_never = typing.assert_never
 else:  # <=3.10
@@ -2375,7 +2589,10 @@
         At runtime, this throws an exception when called.
 
         """
-        raise AssertionError("Expected code to be unreachable")
+        value = repr(arg)
+        if len(value) > _ASSERT_NEVER_REPR_MAX_LENGTH:
+            value = value[:_ASSERT_NEVER_REPR_MAX_LENGTH] + '...'
+        raise AssertionError(f"Expected code to be unreachable, but got: {value}")
 
 
 if sys.version_info >= (3, 12):  # 3.12+
@@ -2677,11 +2894,14 @@
                 if alen < elen:
                     # since we validate TypeVarLike default in _collect_type_vars
                     # or _collect_parameters we can safely check parameters[alen]
-                    if getattr(parameters[alen], '__default__', None) is not None:
+                    if (
+                        getattr(parameters[alen], '__default__', NoDefault)
+                        is not NoDefault
+                    ):
                         return
 
-                    num_default_tv = sum(getattr(p, '__default__', None)
-                                         is not None for p in parameters)
+                    num_default_tv = sum(getattr(p, '__default__', NoDefault)
+                                         is not NoDefault for p in parameters)
 
                     elen -= num_default_tv
 
@@ -2711,11 +2931,14 @@
                 if alen < elen:
                     # since we validate TypeVarLike default in _collect_type_vars
                     # or _collect_parameters we can safely check parameters[alen]
-                    if getattr(parameters[alen], '__default__', None) is not None:
+                    if (
+                        getattr(parameters[alen], '__default__', NoDefault)
+                        is not NoDefault
+                    ):
                         return
 
-                    num_default_tv = sum(getattr(p, '__default__', None)
-                                         is not None for p in parameters)
+                    num_default_tv = sum(getattr(p, '__default__', NoDefault)
+                                         is not NoDefault for p in parameters)
 
                     elen -= num_default_tv
 
@@ -2724,7 +2947,42 @@
             raise TypeError(f"Too {'many' if alen > elen else 'few'} arguments"
                             f" for {cls}; actual {alen}, expected {expect_val}")
 
-typing._check_generic = _check_generic
+if not _PEP_696_IMPLEMENTED:
+    typing._check_generic = _check_generic
+
+
+def _has_generic_or_protocol_as_origin() -> bool:
+    try:
+        frame = sys._getframe(2)
+    # - Catch AttributeError: not all Python implementations have sys._getframe()
+    # - Catch ValueError: maybe we're called from an unexpected module
+    #   and the call stack isn't deep enough
+    except (AttributeError, ValueError):
+        return False  # err on the side of leniency
+    else:
+        # If we somehow get invoked from outside typing.py,
+        # also err on the side of leniency
+        if frame.f_globals.get("__name__") != "typing":
+            return False
+        origin = frame.f_locals.get("origin")
+        # Cannot use "in" because origin may be an object with a buggy __eq__ that
+        # throws an error.
+        return origin is typing.Generic or origin is Protocol or origin is typing.Protocol
+
+
+_TYPEVARTUPLE_TYPES = {TypeVarTuple, getattr(typing, "TypeVarTuple", None)}
+
+
+def _is_unpacked_typevartuple(x) -> bool:
+    if get_origin(x) is not Unpack:
+        return False
+    args = get_args(x)
+    return (
+        bool(args)
+        and len(args) == 1
+        and type(args[0]) in _TYPEVARTUPLE_TYPES
+    )
+
 
 # Python 3.11+ _collect_type_vars was renamed to _collect_parameters
 if hasattr(typing, '_collect_type_vars'):
@@ -2737,19 +2995,29 @@
         if typevar_types is None:
             typevar_types = typing.TypeVar
         tvars = []
-        # required TypeVarLike cannot appear after TypeVarLike with default
+
+        # A required TypeVarLike cannot appear after a TypeVarLike with a default
+        # if it was a direct call to `Generic[]` or `Protocol[]`
+        enforce_default_ordering = _has_generic_or_protocol_as_origin()
         default_encountered = False
+
+        # Also, a TypeVarLike with a default cannot appear after a TypeVarTuple
+        type_var_tuple_encountered = False
+
         for t in types:
-            if (
-                isinstance(t, typevar_types) and
-                t not in tvars and
-                not _is_unpack(t)
-            ):
-                if getattr(t, '__default__', None) is not None:
-                    default_encountered = True
-                elif default_encountered:
-                    raise TypeError(f'Type parameter {t!r} without a default'
-                                    ' follows type parameter with a default')
+            if _is_unpacked_typevartuple(t):
+                type_var_tuple_encountered = True
+            elif isinstance(t, typevar_types) and t not in tvars:
+                if enforce_default_ordering:
+                    has_default = getattr(t, '__default__', NoDefault) is not NoDefault
+                    if has_default:
+                        if type_var_tuple_encountered:
+                            raise TypeError('Type parameter with a default'
+                                            ' follows TypeVarTuple')
+                        default_encountered = True
+                    elif default_encountered:
+                        raise TypeError(f'Type parameter {t!r} without a default'
+                                        ' follows type parameter with a default')
 
                 tvars.append(t)
             if _should_collect_from_parameters(t):
@@ -2767,8 +3035,15 @@
             assert _collect_parameters((T, Callable[P, T])) == (T, P)
         """
         parameters = []
-        # required TypeVarLike cannot appear after TypeVarLike with default
+
+        # A required TypeVarLike cannot appear after a TypeVarLike with default
+        # if it was a direct call to `Generic[]` or `Protocol[]`
+        enforce_default_ordering = _has_generic_or_protocol_as_origin()
         default_encountered = False
+
+        # Also, a TypeVarLike with a default cannot appear after a TypeVarTuple
+        type_var_tuple_encountered = False
+
         for t in args:
             if isinstance(t, type):
                 # We don't want __parameters__ descriptor of a bare Python class.
@@ -2782,21 +3057,33 @@
                             parameters.append(collected)
             elif hasattr(t, '__typing_subst__'):
                 if t not in parameters:
-                    if getattr(t, '__default__', None) is not None:
-                        default_encountered = True
-                    elif default_encountered:
-                        raise TypeError(f'Type parameter {t!r} without a default'
-                                        ' follows type parameter with a default')
+                    if enforce_default_ordering:
+                        has_default = (
+                            getattr(t, '__default__', NoDefault) is not NoDefault
+                        )
+
+                        if type_var_tuple_encountered and has_default:
+                            raise TypeError('Type parameter with a default'
+                                            ' follows TypeVarTuple')
+
+                        if has_default:
+                            default_encountered = True
+                        elif default_encountered:
+                            raise TypeError(f'Type parameter {t!r} without a default'
+                                            ' follows type parameter with a default')
 
                     parameters.append(t)
             else:
+                if _is_unpacked_typevartuple(t):
+                    type_var_tuple_encountered = True
                 for x in getattr(t, '__parameters__', ()):
                     if x not in parameters:
                         parameters.append(x)
 
         return tuple(parameters)
 
-    typing._collect_parameters = _collect_parameters
+    if not _PEP_696_IMPLEMENTED:
+        typing._collect_parameters = _collect_parameters
 
 # Backport typing.NamedTuple as it exists in Python 3.13.
 # In 3.11, the ability to define generic `NamedTuple`s was supported.
@@ -2830,7 +3117,13 @@
                     raise TypeError(
                         'can only inherit from a NamedTuple type and Generic')
             bases = tuple(tuple if base is _NamedTuple else base for base in bases)
-            types = ns.get('__annotations__', {})
+            if "__annotations__" in ns:
+                types = ns["__annotations__"]
+            elif "__annotate__" in ns:
+                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
+                types = ns["__annotate__"](1)
+            else:
+                types = {}
             default_names = []
             for field_name in types:
                 if field_name in ns:
@@ -2962,7 +3255,7 @@
 if hasattr(collections.abc, "Buffer"):
     Buffer = collections.abc.Buffer
 else:
-    class Buffer(abc.ABC):
+    class Buffer(abc.ABC):  # noqa: B024
         """Base class for classes that implement the buffer protocol.
 
         The buffer protocol allows Python objects to expose a low-level
@@ -3289,6 +3582,23 @@
             return self.documentation == other.documentation
 
 
+_CapsuleType = getattr(_types, "CapsuleType", None)
+
+if _CapsuleType is None:
+    try:
+        import _socket
+    except ImportError:
+        pass
+    else:
+        _CAPI = getattr(_socket, "CAPI", None)
+        if _CAPI is not None:
+            _CapsuleType = type(_CAPI)
+
+if _CapsuleType is not None:
+    CapsuleType = _CapsuleType
+    __all__.append("CapsuleType")
+
+
 # Aliases for items that have always been in typing.
 # Explicitly assign these (rather than using `from typing import *` at the top),
 # so that we get a CI error if one of these is deleted from typing.py
@@ -3302,7 +3612,6 @@
 Dict = typing.Dict
 ForwardRef = typing.ForwardRef
 FrozenSet = typing.FrozenSet
-Generator = typing.Generator
 Generic = typing.Generic
 Hashable = typing.Hashable
 IO = typing.IO
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/vendor.txt /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/vendor.txt
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/pip/_vendor/vendor.txt	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/pip/_vendor/vendor.txt	2024-08-15 06:46:07.169821873 -0400
@@ -3,17 +3,16 @@
 distro==1.9.0
 msgpack==1.0.8
 packaging==24.1
-platformdirs==4.2.1
+platformdirs==4.2.2
 pyproject-hooks==1.0.0
 requests==2.32.3
-    certifi==2024.2.2
+    certifi==2024.7.4
     idna==3.7
     urllib3==1.26.18
 rich==13.7.1
-    pygments==2.17.2
-    typing_extensions==4.11.0
+    pygments==2.18.0
+    typing_extensions==4.12.2
 resolvelib==1.0.1
-setuptools==69.5.1
-tenacity==8.2.3
+setuptools==70.3.0
 tomli==2.0.1
 truststore==0.9.1
Only in /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages: pip-24.1.2.dist-info
Only in /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages: pip-24.2.dist-info
Only in /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages: PyYAML-6.0.1.dist-info
Only in /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages: PyYAML-6.0.2.dist-info
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/tomlkit/api.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/tomlkit/api.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/tomlkit/api.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/tomlkit/api.py	2024-08-15 06:46:07.164821873 -0400
@@ -75,6 +75,11 @@
 
     :param data: a dict-like object to dump
     :param sort_keys: if true, sort the keys in alphabetic order
+
+    :Example:
+
+    >>> with open("output.toml", "w") as fp:
+    ...     tomlkit.dump(data, fp)
     """
     fp.write(dumps(data, sort_keys=sort_keys))
 
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/tomlkit/container.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/tomlkit/container.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/tomlkit/container.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/tomlkit/container.py	2024-08-15 06:46:07.164821873 -0400
@@ -814,7 +814,7 @@
                 table_idx = len(self._tables) - 1
                 for k, v in item.value.body:
                     self._internal_container._raw_append(k, v)
-                    self._tables_map[k] = table_idx
+                    self._tables_map.setdefault(k, []).append(table_idx)
                     if k is not None:
                         dict.__setitem__(self, k.key, v)
 
@@ -835,8 +835,12 @@
 
     def __setitem__(self, key: Key | str, item: Any) -> None:
         if key in self._tables_map:
-            table = self._tables[self._tables_map[key]]
-            table[key] = item
+            # Overwrite the first table and remove others
+            indices = self._tables_map[key]
+            while len(indices) > 1:
+                table = self._tables[indices.pop()]
+                self._remove_table(table)
+            self._tables[indices[0]][key] = item
         elif self._tables:
             table = self._tables[0]
             table[key] = item
@@ -856,15 +860,16 @@
                 break
 
     def __delitem__(self, key: Key | str) -> None:
-        if key in self._tables_map:
-            table = self._tables[self._tables_map[key]]
+        if key not in self._tables_map:
+            raise NonExistentKey(key)
+
+        for i in reversed(self._tables_map[key]):
+            table = self._tables[i]
             del table[key]
             if not table and len(self._tables) > 1:
                 self._remove_table(table)
-            del self._tables_map[key]
-        else:
-            raise NonExistentKey(key)
 
+        del self._tables_map[key]
         del self._internal_container[key]
         if key is not None:
             dict.__delitem__(self, key)
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/tomlkit/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/tomlkit/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/tomlkit/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/tomlkit/__init__.py	2024-08-15 06:46:07.164821873 -0400
@@ -27,7 +27,7 @@
 from tomlkit.api import ws
 
 
-__version__ = "0.13.0"
+__version__ = "0.13.2"
 __all__ = [
     "aot",
     "array",
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/tomlkit/items.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/tomlkit/items.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/tomlkit/items.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/tomlkit/items.py	2024-08-15 06:46:07.164821873 -0400
@@ -1621,11 +1621,23 @@
         If true, it won't appear in the TOML representation."""
         if self._is_super_table is not None:
             return self._is_super_table
-        # If the table has only one child and that child is a table, then it is a super table.
-        if len(self) != 1:
+        if not self:
             return False
-        only_child = next(iter(self.values()))
-        return isinstance(only_child, (Table, AoT))
+        # If the table has children and all children are tables, then it is a super table.
+        for k, child in self.items():
+            if not isinstance(k, Key):
+                k = SingleKey(k)
+            index = self.value._map[k]
+            if isinstance(index, tuple):
+                return False
+            real_key = self.value.body[index][0]
+            if (
+                not isinstance(child, (Table, AoT))
+                or real_key is None
+                or real_key.is_dotted()
+            ):
+                return False
+        return True
 
     def as_string(self) -> str:
         return self._value.as_string()
Only in /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages: tomlkit-0.13.0.dist-info
Only in /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages: tomlkit-0.13.2.dist-info
diff --suppress-common-lines -u -r -x '*.pyc' -x installed-files.txt /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/yaml/__init__.py /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/yaml/__init__.py
--- /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/yaml/__init__.py	2024-07-10 18:24:08.000000000 -0400
+++ /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/yaml/__init__.py	2024-08-15 06:46:07.159821873 -0400
@@ -8,7 +8,7 @@
 from .loader import *
 from .dumper import *
 
-__version__ = '6.0.1'
+__version__ = '6.0.2'
 try:
     from .cyaml import *
     __with_libyaml__ = True
Binary files /tmp/tmp.PTAN8QOIRy/lib/python3.11/site-packages/yaml/_yaml.cpython-311-x86_64-linux-gnu.so and /tmp/tmp.vSyF58mbqy/lib/python3.11/site-packages/yaml/_yaml.cpython-311-x86_64-linux-gnu.so differ
***** END DIFF
DIFF START *****
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/ansible__ansible-demo/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/ansible__ansible-demo/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/ansible__ansible-demo/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/ansible__ansible-demo/meta.yaml	2024-08-15 06:46:08.711821873 -0400
@@ -7,7 +7,7 @@
   - Molecule
 icon: /images/type-ansible.svg
 links:
-  v2: https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/ansible__ansible-demo/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/ansible__ansible-demo/devworkspace-che-code-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/external_images_by_devfile.txt /tmp/tmp.ZvDREHm0Dk/devfiles/external_images_by_devfile.txt
--- /tmp/tmp.R3ZACG29dI/devfiles/external_images_by_devfile.txt	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/external_images_by_devfile.txt	2024-08-15 06:46:08.710821873 -0400
@@ -1,44 +1,44 @@
-ghcr.io/ansible/ansible-workspace-env-reference@sha256:03d7f0fe6caaae62ff2266906b63d67ebd9cf6e4a056c7c0a0c1320e6cfbebce	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-ghcr.io/ansible/ansible-workspace-env-reference@sha256:03d7f0fe6caaae62ff2266906b63d67ebd9cf6e4a056c7c0a0c1320e6cfbebce	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
-registry.redhat.io/rhscl/mongodb-36-rhel7:1-50	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
-registry.redhat.io/rhscl/mongodb-36-rhel7:1-50	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+ghcr.io/ansible/ansible-workspace-env-reference@sha256:03d7f0fe6caaae62ff2266906b63d67ebd9cf6e4a056c7c0a0c1320e6cfbebce	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+ghcr.io/ansible/ansible-workspace-env-reference@sha256:03d7f0fe6caaae62ff2266906b63d67ebd9cf6e4a056c7c0a0c1320e6cfbebce	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/code-rhel8:3.16	https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/idea-rhel8:3.16	https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/devspaces/udi-rhel8:3.16	https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
+registry.redhat.io/rhscl/mongodb-36-rhel7:1-50	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-code-latest.yaml
+registry.redhat.io/rhscl/mongodb-36-rhel7:1-50	https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3.16-rhel-8/devfile.yaml	devworkspace-che-idea-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/index.json /tmp/tmp.ZvDREHm0Dk/devfiles/index.json
--- /tmp/tmp.R3ZACG29dI/devfiles/index.json	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/index.json	2024-08-15 06:46:08.710821873 -0400
@@ -9,7 +9,7 @@
     ],
     "icon": "/images/type-ansible.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/ansible-devspaces-demo/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/ansible__ansible-demo/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/ansible__ansible-demo/devworkspace-che-code-latest.yaml"
@@ -28,7 +28,7 @@
     ],
     "icon": "/images/type-lombok.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/java-maven-lombok__lombok-project-sample/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/java-maven-lombok__lombok-project-sample/devworkspace-che-code-latest.yaml"
@@ -47,7 +47,7 @@
     ],
     "icon": "/images/type-quarkus.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/java-maven-quarkus__quarkus-quickstarts/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/java-maven-quarkus__quarkus-quickstarts/devworkspace-che-code-latest.yaml"
@@ -66,7 +66,7 @@
     ],
     "icon": "/images/type-node.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/nodejs__nodejs-mongodb-sample/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/nodejs__nodejs-mongodb-sample/devworkspace-che-code-latest.yaml"
@@ -84,7 +84,7 @@
     ],
     "icon": "/images/type-node.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/nodejs__web-nodejs-sample/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/nodejs__web-nodejs-sample/devworkspace-che-code-latest.yaml"
@@ -101,7 +101,7 @@
     ],
     "icon": "/images/type-python.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/python__python-hello-world/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/python__python-hello-world/devworkspace-che-code-latest.yaml"
@@ -124,7 +124,7 @@
     ],
     "icon": "/images/type-cpp.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/TP__cpp__c-plus-plus/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/TP__cpp__c-plus-plus/devworkspace-che-code-latest.yaml"
@@ -133,7 +133,7 @@
   },
   {
     "displayName": ".NET",
-    "description": ".NET stack with .NET Core SDK 7, Runtime, C# Language Support and Debugger",
+    "description": ".NET stack with .NET Core SDK 8, Runtime, C# Language Support and Debugger",
     "tags": [
       "Tech-Preview",
       ".NET",
@@ -146,7 +146,7 @@
     ],
     "icon": "/images/type-dotnet.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/TP__dotnet__dotnet-web-simple/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/TP__dotnet__dotnet-web-simple/devworkspace-che-code-latest.yaml"
@@ -164,7 +164,7 @@
     ],
     "icon": "/images/type-go.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/TP__go__golang-health-check/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/TP__go__golang-health-check/devworkspace-che-code-latest.yaml"
@@ -181,7 +181,7 @@
     ],
     "icon": "/images/type-php.svg",
     "links": {
-      "v2": "https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3-rhel-8",
+      "v2": "https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3.16-rhel-8",
       "devWorkspaces": {
         "che-incubator/che-idea/latest": "/devfiles/TP__php__php-hello-world/devworkspace-che-idea-latest.yaml",
         "che-incubator/che-code/latest": "/devfiles/TP__php__php-hello-world/devworkspace-che-code-latest.yaml"
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/java-maven-lombok__lombok-project-sample/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/java-maven-lombok__lombok-project-sample/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/java-maven-lombok__lombok-project-sample/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/java-maven-lombok__lombok-project-sample/meta.yaml	2024-08-15 06:46:08.711821873 -0400
@@ -8,7 +8,7 @@
   - UBI8
 icon: /images/type-lombok.svg
 links:
-  v2: https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/lombok-project-sample/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/java-maven-lombok__lombok-project-sample/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/java-maven-lombok__lombok-project-sample/devworkspace-che-code-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/java-maven-quarkus__quarkus-quickstarts/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/java-maven-quarkus__quarkus-quickstarts/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/java-maven-quarkus__quarkus-quickstarts/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/java-maven-quarkus__quarkus-quickstarts/meta.yaml	2024-08-15 06:46:08.710821873 -0400
@@ -8,7 +8,7 @@
   - UBI8
 icon: /images/type-quarkus.svg
 links:
-  v2: https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/quarkus-quickstarts/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/java-maven-quarkus__quarkus-quickstarts/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/java-maven-quarkus__quarkus-quickstarts/devworkspace-che-code-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/nodejs__nodejs-mongodb-sample/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/nodejs__nodejs-mongodb-sample/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/nodejs__nodejs-mongodb-sample/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/nodejs__nodejs-mongodb-sample/meta.yaml	2024-08-15 06:46:08.710821873 -0400
@@ -8,7 +8,7 @@
   - UBI8
 icon: /images/type-node.svg
 links:
-  v2: https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/nodejs-mongodb-sample/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/nodejs__nodejs-mongodb-sample/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/nodejs__nodejs-mongodb-sample/devworkspace-che-code-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/nodejs__web-nodejs-sample/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/nodejs__web-nodejs-sample/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/nodejs__web-nodejs-sample/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/nodejs__web-nodejs-sample/meta.yaml	2024-08-15 06:46:08.710821873 -0400
@@ -7,7 +7,7 @@
   - UBI8
 icon: /images/type-node.svg
 links:
-  v2: https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/web-nodejs-sample/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/nodejs__web-nodejs-sample/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/nodejs__web-nodejs-sample/devworkspace-che-code-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/python__python-hello-world/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/python__python-hello-world/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/python__python-hello-world/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/python__python-hello-world/meta.yaml	2024-08-15 06:46:08.710821873 -0400
@@ -6,7 +6,7 @@
   - UBI8
 icon: /images/type-python.svg
 links:
-  v2: https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/python-hello-world/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/python__python-hello-world/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/python__python-hello-world/devworkspace-che-code-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/TP__cpp__c-plus-plus/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/TP__cpp__c-plus-plus/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/TP__cpp__c-plus-plus/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/TP__cpp__c-plus-plus/meta.yaml	2024-08-15 06:46:08.711821873 -0400
@@ -12,7 +12,7 @@
   - UBI8
 icon: /images/type-cpp.svg
 links:
-  v2: https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/c-plus-plus/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/TP__cpp__c-plus-plus/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/TP__cpp__c-plus-plus/devworkspace-che-code-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/TP__dotnet__dotnet-web-simple/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/TP__dotnet__dotnet-web-simple/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/TP__dotnet__dotnet-web-simple/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/TP__dotnet__dotnet-web-simple/meta.yaml	2024-08-15 06:46:08.711821873 -0400
@@ -1,5 +1,5 @@
 displayName: .NET
-description: .NET stack with .NET Core SDK 7, Runtime, C# Language Support and Debugger
+description: .NET stack with .NET Core SDK 8, Runtime, C# Language Support and Debugger
 tags:
   - Tech-Preview
   - .NET
@@ -11,7 +11,7 @@
   - UBI8
 icon: /images/type-dotnet.svg
 links:
-  v2: https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/dotnet-web-simple/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/TP__dotnet__dotnet-web-simple/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/TP__dotnet__dotnet-web-simple/devworkspace-che-code-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/TP__go__golang-health-check/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/TP__go__golang-health-check/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/TP__go__golang-health-check/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/TP__go__golang-health-check/meta.yaml	2024-08-15 06:46:08.711821873 -0400
@@ -7,7 +7,7 @@
   - UBI8
 icon: /images/type-go.svg
 links:
-  v2: https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/golang-health-check/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/TP__go__golang-health-check/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/TP__go__golang-health-check/devworkspace-che-code-latest.yaml
diff --suppress-common-lines -u -r /tmp/tmp.R3ZACG29dI/devfiles/TP__php__php-hello-world/meta.yaml /tmp/tmp.ZvDREHm0Dk/devfiles/TP__php__php-hello-world/meta.yaml
--- /tmp/tmp.R3ZACG29dI/devfiles/TP__php__php-hello-world/meta.yaml	2024-06-26 20:28:52.000000000 -0400
+++ /tmp/tmp.ZvDREHm0Dk/devfiles/TP__php__php-hello-world/meta.yaml	2024-08-15 06:46:08.711821873 -0400
@@ -6,7 +6,7 @@
   - UBI8
 icon: /images/type-php.svg
 links:
-  v2: https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3-rhel-8
+  v2: https://github.com/devspaces-samples/php-hello-world/tree/devspaces-3.16-rhel-8
   devWorkspaces:
     che-incubator/che-idea/latest: /devfiles/TP__php__php-hello-world/devworkspace-che-idea-latest.yaml
     che-incubator/che-code/latest: /devfiles/TP__php__php-hello-world/devworkspace-che-code-latest.yaml
Binary files /tmp/tmp.R3ZACG29dI/resources/v2/ansible-devspaces-demo.zip and /tmp/tmp.ZvDREHm0Dk/resources/v2/ansible-devspaces-demo.zip differ
Binary files /tmp/tmp.R3ZACG29dI/resources/v2/dotnet-web-simple.zip and /tmp/tmp.ZvDREHm0Dk/resources/v2/dotnet-web-simple.zip differ
***** END DIFF
Untagged: localhost/devfileregistry:tmp
Deleted: 5b78eabb2c11a83f300202235497515cceb40000f675e7ee5aadbc7ef2c93fcb
Deleted: 8416468124f3f142457bf8938a813972e76594fe178cec46d8dba39d0ac9a7d8
Deleted: 91554abefdb1858b56df5c403c8b079f1102358cd9df2b0dc718c54cc0290ce4
Deleted: afa6fed70da6eda2c2f61a35d0058d4f40d7e882794de3925b962dfe876e209e
Deleted: 920c879c54115ce16fde7a3f3775152d95f8c7e26ebceb72f2d4529ba4dc640d
Deleted: b72f3c617cf625992d7eac7fa45aeb772cede07f55a7c552607d511679ec14c7
Deleted: 95b03acf59662eaa1e46c629018f435fdc3263c4e3dd12bfb0d4e30ba9373051
Deleted: e7187d5334e6a9d90ba611bd9f3241a3ac7d7597faaadad5454475f81f94a582
Deleted: ecd2d964e15b0501f52fed020b1919d4a9292fcbe0752ceef3a60be4b291adfd
Deleted: 9a21729481d52185af1565d5f5246fd57567b9d52c4c00c4f35ab67ba5878e49
Deleted: ef121cee24683cf8d906cf581f768287c22f2b4be6c243b4333c697521700534
Deleted: d8f1ae254a891dc4cd1bb4488907a20ace4f6d419192cc85d5b091274fa25df1
Deleted: 59ea1037657d2364bd1210a16ac4c9d147074da0fc2882de9ee516827b87c9e5
Deleted: 7bf13d5698248c1313251b8970077c48b448f436093e750f4fd6648aed825c03
Deleted: 3a0dcad6987358050c6eb6a4db81fab23f7e7124af5c203a30d695b5597d3472
Deleted: ac1fee2ca5b2f0a1d23c1f9fd5f2b0180255fe267f8f6525668a591cec690279
Deleted: ea4a8fd527d66da22634c992d7cb7d8566fc1be399ea9423f5bc3818bf87e779
Deleted: fef1d806d87d4be79c3473cfd0918b96e590276ceea9adf9476d0b56c8e2e644
Deleted: 6a61322aa5c088a21fba8af8feb38e896134840127d056fdbbcaa30dcf690d64
Deleted: 186690d62d6f186d42355b17cb1a5b6b57651e70c08f0ad35b5c54309366c8b3
Deleted: b72fb07a6de6039938de03e50bdff5d40c5217c1dbaf25dcb71c989d4685b086
Deleted: 65dc24c7dc7e7394b50e872cedd5153b7d70803d0a3dc7d52d172f45e966d5d4
Uploading: root-local.tgz to https://pkgs.devel.redhat.com/lookaside/upload.cgi
Uploading: root-local.tgz
Uploading: resources.tgz to https://pkgs.devel.redhat.com/lookaside/upload.cgi
Uploading: resources.tgz
Source upload succeeded. Don't forget to commit the sources file
rm 'resources.tgz'
rm 'root-local.tgz'
